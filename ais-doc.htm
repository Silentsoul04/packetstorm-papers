<HTML>

<! Document Number:  >

<HEAD>
	<TITLE>Automated Information Systems Security Policy</TITLE>
</HEAD>

<BODY BACKGROUND="images/backgnd.jpg" BGCOLOR=#FFFFFF TEXT=#000000 LINK=blue VLINK=red>
<IMG SRC="images/bar1.gif">
<H2>Automated Information Systems Security Policy</H2>
<IMG SRC="images/bar1.gif">
<P>
<h3>	Foreword</h3>

<p>

<p>

The U.S. Customs Service, Office of Information and Technology Automated Information
Systems (AIS) Security Policy Manual is intended for those who use Customs AIS services and
systems.  Information throughout the manual supports the Customs mission by providing direction
and guidance to protect AIS resources.  It establishes uniform policies, responsibilities, and
authorities for carrying out the Customs AIS Security Program.   Security is provided for
information that is collected, processed, transmitted, stored, or distributed for all other agencies
utilizing Customs general support systems and major applications.  <p>

<p>

This high-level policy manual supplements the AIS security policies established by the U.S.
Department of the Treasury, and is consistent with government-wide policies, standards, and
procedures issued by the Office of Management and Budget, the Department of Commerce, the
General Services Administration, and the Office of Personnel Management.  Additional detailed
and specific procedural guidelines, particular to Customs needs and requirements, will be issued in
an iterative fashion, as appropriate.  Prior releases of this manual (CIS HB 1400-04) are
superseded.<p>

<p>

Additional copies may be obtained by submitting Customs Form CF 262.  Please include your street 
address, the number of publications you want, and either your Fed Ex, UPS, or RPS account number 
to pay for the shipping costs (publications are free) to:   U.S. Customs Service National Distribution 
Center, PO Box 68912, Indianapolis, IN 46268.  Non-Customs Federal and civil agencies, organizations, 
and members of the trade community may contact their Customs representative, or obtain the manual 
via the Internet from Customs World Wide Web (WWW) page on the National Technical Information 
Service (NTIS) FedWorld, at <b>http://fedworld.gov</b>, as available.<p>

<p>

The U.S. Customs Service wishes to extend special thanks to the Federal Bureau of Investigation,
Information Systems Security Unit, for valuable input which provided the basis for the
development of this document, to the National Security Agency for their review and suggestions,
and to the U.S. Department of the Treasury, Office of Information Systems Security, for their
oversight and guidance.<p>

<p>

<p>

<p>

<p>

						(original signd by George J. Weise)<p>

							Commissioner<p>

<p>

<p>

Distribution:  G-25<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<center></center>
<p>

<p>

<center>Contents<BR>
<IMG SRC="images/bar1.gif">
</center>
<PRE>
INTRODUCTION..................................................................1-1
    1.1 PURPOSE...............................................................1-1
    1.2 REFERENCES............................................................1-1
    1.3 DEFINITIONS...........................................................1-1
    1.4 SCOPE.................................................................1-1
    1.5 BACKGROUND............................................................1-2
    1.6 INFORMATION SECURITY POLICY AND GUIDANCE HIERARCHY....................1-6

GENERAL POLICY................................................................2-1
    2.1 GENERAL POLICY STATEMENT..............................................2-1
    2.2 ROLES AND RESPONSIBILITIES............................................2-1

AIS SECURITY LIFE CYCLE.......................................................3-1
    3.1 SECURITY PLANNING.....................................................3-1
        3.1.1 Approvals.......................................................3-1
        3.1.2 AIS Security Plan...............................................3-2
        3.1.3 Disaster Recovery and Contingency Operations Planning ..........3-3
    3.2 SECURITY REQUIREMENTS ................................................3-4
        3.2.1 Policy Derived Requirements ....................................3-4
        3.2.2 Risk Management ................................................3-5
    3.3 DEVELOPMENT ..........................................................3-6
    3.4 CERTIFICATION AND ACCREDITATION ......................................3-6
        3.4.1 Certification...................................................3-7
        3.4.2 Accreditation...................................................3-8
    3.5 PROCEDURES AND PRACTICES..............................................3-10
    3.6 EDUCATION, TRAINING, AND AWARENESS....................................3-10
    3.7 SECURITY OVERSIGHT....................................................3-11

MINIMUM SECURITY REQUIREMENTS.................................................4-1
    4.1 FACILITY SECURITY.....................................................4-1
        4.1.1 Physical........................................................4-1
        4.1.2 Environmental...................................................4-2
    4.2 PERSONNEL SECURITY....................................................4-2
    4.3 AUTOMATED SECURITY....................................................4-3
        4.3.1 Minimum Security Requirements...................................4-3
        4.3.2 Security Assurances.............................................4-5
        4.3.3 Desirable Security Features.....................................4-7
    4.4 ADMINISTRATIVE SECURITY...............................................4-7
        4.4.1 Accountability and Access Control Criteria......................4-7
        4.4.2 Software and Data Security......................................4-8
        4.4.3 Technical Support and Maintenance...............................4-9
        4.4.4 Portable Computer Equipment.....................................4-10
        4.4.5 Classification and Controls.....................................4-10
        4.4.6 External Labels.................................................4-11
        4.4.7 Customs Work Performed at non-Customs Locations.................4-11
        4.4.8 Use of Non-Customs Owned AISs...................................4-12
    4.5 TELECOMMUNICATIONS SECURITY...........................................4-12
        4.5.1 Information System Standards....................................4-12
        4.5.2 Network Connections.............................................4-12
        4.5.4 Electronic Mail (E-Mail)........................................4-13
        4.5.5 Facsimile (FAX).................................................4-13
        4.5.6 PBX and Voice Mail Systems......................................4-14
        4.5.7 Communications Security (COMSEC)................................4-14

SECURITY INCIDENTS AND VIOLATIONS.............................................5-1

GLOSSARY......................................................................Glos-1

BIBLIOGRAPHY..................................................................Bib-1
    Selected Readings.........................................................Bib-5

APPENDIX A
    Abbreviations and Acronyms................................................A-1

APPENDIX B
    Good Security Practices...................................................B-1

APPENDIX C
    Controlled Access Protection (C2) Outline.................................C-1

APPENDIX D
    Security Plan Format...................................................D-1

APPENDIX E
    Computer Security Training.............................................E-1

APPENDIX F
    Security Requirements Methodology......................................F-1

APPENDIX G
    OMB Circulars..........................................................G-1
    OMB Circular No. A-123, Introduction & Comments........................G-1
    Circular No. A-123,  Revised...........................................G-7
    OMB Circular No. A-130, Appendix III,  Revised.........................G-16

INDEX......................................................................Index-1

Reader's Comment Form......................................................Comment-1

</PRE>
<p>
<p>

	CHAPTER 1<p>

	<i>INTRODUCTION</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

<b>1.1	PURPOSE</b><p>

<p>

	This document establishes uniform policies, responsibilities, and authorities for implementing the U.S.
Customs Service, from now on called <b>Customs</b>, Automated Information Systems (AIS) Security
Program.  It promotes the Customs mission and provides guidance to protect Customs AIS resources
and assure adequate security for all agency information collected, processed, transmitted, stored, or
disseminated in its general support systems and major applications.<p>

<p>

	Customs AIS security policies are consistent with government-wide policies, standards, and
procedures issued by the Office of Management and Budget (OMB), the Department of Commerce,
the General Services Administration and the Office of Personnel Management (OPM).  At a
minimum, the Customs AIS Security Program includes the set of controls established by OMB
Circular A-130, Appendix III, <u>Security of Federal Automated Information Resources</u>, dated February
8, 1996.<p>

<p>

<b>1.2	REFERENCES</b><p>

<p>

	The Bibliography contains specific reference citations used in the AIS Security Policy Manual, and
Selected Reading references which support the policies.<p>

<p>

<b>1.3	DEFINITIONS</b><p>

<p>

	Appear in the Glossary.<p>

<p>

<b>1.4	SCOPE</b><p>

<p>

	This policy manual supplements the AIS security policies established by the U.S. Treasury
Department and presented in the <u>Treasury Security Manual</u>, TD P 71-10.<p>

<p>

	(1)	<u>Inclusions</u>: Policy provisions apply to all Customs personnel, contractors acting for Customs,
and all authorized users who access Customs AISs, networks, and support facilities.  Policy
provisions also apply to non-Customs organizations, or their representatives, who are granted
access to Customs AIS resources, including other government agencies and members of the
trade community.<p>

<p>

	(2)	<u>Exclusions</u>: Microprocessors embedded in or dedicated to production or process control
equipment (e.g., test and laboratory equipment) are not covered by these policy provisions.<p>

<p>

	(3)	<u>Point-of-contact</u>: Direct questions concerning this policy manual to the Director, AIS Security
Division, Office of Information and Technology, via the web <A HREF="/log.htm"> feedback</A> button.<p>

<b>1.5	BACKGROUND</b><p>

<p>

	<b>Customs Mission</b>:  [USCS 96PLAN; USCS IRMPLAN]<p>

<p>

	Ensure that all goods and persons entering or exiting the United States do so in compliance
with all the United States laws and regulation.<p>

	Protect the public against violations which threaten the national economy and health and
safety.<p>

	Be the national resource for information on goods and persons crossing our borders.<p>

<p>

	Customs is committed to carry out its mission with increasing effectiveness and efficiency using
information technology as an essential supporting element.  Customs employees worldwide use AISs
for all facets of Customs operations and to support law enforcement, government agencies, and the
commercial trade community.  These activities facilitate enforcement of United States laws, and the
control and generation of significant financial revenue to the U.S. Treasury.<p>

<p>

	(1)	AIS Security Program goals:<p>

<p>

		"All Federal applications require some level of protection.  Certain applications,  because of
the sensitive information in them, however, require special management oversight and should
be treated as major.  Adequate security for other applications should be provided by security
of the systems in which they operate."  [OMB A-130,AIII]<p>

<p>

		(a)	Establish and maintain adequate and effective AIS security safeguards
(countermeasures) to ensure data confidentiality, integrity, and operational
availability of all Customs AISs that process, store, or transmit non-sensitive, and
sensitive but unclassified (SBU, from now on called "sensitive") information.  <p>

<p>

		(b)	The security program is designed to protect AIS processed information by:<p>

<p>

			(i)	denying unauthorized AIS access;<p>

<p>

			(ii)	restricting legitimate users to data or processes for which they are
authorized; and<p>

<p>

			(iii)	controlling access because of inadequate security design, implementation, or
operation.<p>

<p>

		(c)	AIS security safeguards will preserve information processing integrity, reliability and
availability to ensure that the data are accurate and relevant to provide law
enforcement and investigative support, help achieve Customs revenue collections,
and meet commercial and administrative requirements.  The application of Customs
AIS security policies is evolutionary.  When fully implemented, security programs
will conform to an acceptable level of mandated Federal requirements.<p>

<p>

		(d)	Within operational constraints, AIS security controls will allow required AIS services
to be available to authorized users while denying these services to unauthorized
users.<p>

<p>

	(2)	Security classification:<p>

<p>

		(a)	All Federal data, applications, and AISs must be afforded <u>adequate security</u>.<p>

			[OMB A-130,AIII]<p>

<p>

		(b)	Unless otherwise designated, Customs general support systems and major
applications are considered to contain sensitive information.<p>

<p>

.		(c)	Classified (national security) information policy and procedures are addressed in
<u>Safeguarding Classified Information Handbook</u>, CIS HB 1400-03.<p>

<p>

	(3)	Information release:<p>

<p>

		The public release of information is controlled by statutes (Freedom of Information Act
(FOIA), Privacy Act (PA), Electronic Communications Privacy Act, etc...). Regulations also
control the release of such information, as do interagency agreements.<p>

		[OMB A-130; TD P 25-04; TD P 25-05]<p>

<p>

	(4)	Policy application:<p>

<p>

		AIS security includes applicable security life-cycle requirements.  Additional related
programs are incorporated in this document by reference and should be considered when
establishing and reviewing AIS security requirements. Their applicable policies and
procedures may be obtained via the appropriate program managers.<p>

<p>

		(a)	<b>Office of Information and Technology (OIT)</b><p>

<p>

			The Office of Information and Technology is responsible for the design,
development, programming, testing, implementation, and maintenance of Customs
automated information systems, and oversight and management of the research and
development and communications functions of the Customs Service.  The Office is
responsible for management of all Customs computer facilities, hardware, software,
data and voice telecommunications, and related financial resources.  It is responsible
for identifying and evaluating new technologies for application to Customs automated
systems; developing and maintaining all operational aspects of Customs computer
security program; establishing requirements for computer-to-computer interfaces
between Customs and various trade groups and government agencies; representing
Customs on matters related to automated import processing and systems
development; and implementing a viable Information Resources Management (IRM)
program.<p>

<p>

		(b)	<b>Applications Development Division</b><p>

<p>

			The Applications Development Division is responsible for the design, development,
programming, testing, implementation and maintenance of Customs automated
information systems.  The Division, in conjunction with the ADP Steering
Committee, is responsible for approving project initiation.  Specifically, this
organization will be responsible for:  providing system-specific support for users on
existing applications during the transition to new integrated systems; change control
and software release; and correcting system problems that arise after implementation. 
In addition, the project teams operating out of this Division are assigned full
responsibility for development of new systems and major enhancements to existing
systems.  They are multi-functional and integrated to address both systems
development efforts and new technologies.<p>

<p>

		(c)	<b>User Support Services Division</b> <p>

<p>

			The User Support Services Division is responsible for functions that deal directly
with field users on a daily basis, including training activities supporting mainframe
and distributed/PC/LAN applications, support of field equipment, including
installation of PCs, LANs and peripheral equipment, data and voice communication
lines and circuits; providing user assistance, including LAN administration; operation
of the Customs Help Desk; and supporting all users of Customs automated systems. <p>

<p>

		(b)	<b>AIS Security Division (AISS)</b><p>

<p>

			(i)	Develops security policies and standards.<p>

<p>

			(ii)	Provides liaison activities for AIS security-related policies, issues, and
products:<p>

			 	within Customs,<p>

				to the Department of Treasury and outside agencies,<p>

				to the trade community,<p>

				to other law enforcement agencies, and<p>

				to private organizations.<p>

<p>

			(iii)	Manages security software packages.<p>

<p>

			(iv)	Administers security access controls for Customs mainframe systems.<p>

<p>

			(v)	Provides assistance and certification for Customs AIS users.<p>

<p>

			(vi)	Coordinates the development of disaster recovery and contingency plans.<p>

<p>

		(c)	<b>Information Resources Management Division (IRM)</b><p>

<p>

			(i)	Develops guidelines and standards for all developmental activities.<p>

<p>

			(ii)	Performs and coordinates IRM reviews, and monitors corrective actions.<p>

<p>

			(iii)	Provides security oversight.<p>

<p>

			(iv)	Evaluates and plans Customs AIS resource capacity requirements.<p>

<p>

			(v)	Coordinates strategic planning efforts.<p>

<p>

			(vi)	Conducts analytical studies as needed in support of all OIT entities.<p>

<p>

			(vii)	Provides technology assessments.<p>

<p>

			(viii)	Develops the Information Systems Plan (ISP).<p>

<p>

			(ix)	Plans and coordinates major procurements for AIS equipment and services.<p>

<p>

			(x)	Provides Systems Development Life Cycle (SDLC) advice, assistance, and
ensures compliance.<p>

<p>

		(d)	<b>Systems Operations Division (OPS)</b><p>

		<p>

			The  Systems Operations Division is responsible for managing all new and existing
Customs computer facilities, hardware and software, and for managing the related
financial resources.  It is responsible for data base administration; systems
engineering; computer operations; communications software design and
implementation; and management of the Customs Data Center facility. <p>

<p>

		(e)	<b>Security Programs Division (SPD)</b><p>

<p>

			The Security Programs Division prescribes policy, procedures, and specifications for
maintaining Customs personnel security programs.<p>

<p>

			The Security Programs Division, Security Management Branch is responsible for
facility and industrial security programs. <p>

<p>

		(f)	<b>Communications Management Division (CMD)</b><p>

<p>

			The Office of Investigations, Communications Management Division,
Communications Security Branch sets policy for handling Customs communications
security (COMSEC) materials and equipment, and establishes standards and
procedures for granting authorization to Customs employees for access or use of
those materials and equipment.  They also evaluate and approve AIS cryptography
and communications security measures.  [USCS 4300-09]<p>

<p>

		(g)	<b>Office of Regulations and Rulings (ORR)</b><p>

<p>

			The Office of Regulations and Rulings, Disclosure Law Branch, sets policy for
Customs Freedom of Information Act and Privacy Act (FOIA/PA) programs.<p>

			[TD P 25-04; TD P 25-05]<p>

<p>

		(h)	<b>Office of Chief Counsel</b><p>

<p>

			The Office of Chief Counsel provides legal advice to all Customs Offices on Customs
enforcement authorities and related subjects.<p>

<p>

<b>1.6	INFORMATION SECURITY POLICY AND GUIDANCE HIERARCHY</b><p>

<p>

The following is for general information purposes.  It is copied from <u>Introduction to Certification and
Accreditation</u>.  [NCSC-TG-029]<p>

<p>

Security policy exists at different levels of abstraction.  Federal and national-level policy is stated in public
laws, Executive Orders (EO), National Security Directives (NSD), National Security Telecommunications and
Information Systems Security (NSTISS) issuances, Federal Information Processing Standard Publications
(FIPS PUBS), Office of Management and Budget (OMB) circulars, and other resources.  Federal service and
agency policies interpret Department of Defense (DoD) and national-level policies, as appropriate, and may
impose additional requirements.<p>

<p>

*	TEMPEST generally applies to classified information and is not addressed in this manual.  It refers
control of electronic emanations and is not authorization to use classified data. TEMPEST issues
should be directed to the Treasury Office of Information Systems Security.<p>

	[TD P 71-10; HB 1400-03]<p>

<p>

<p>

Many national and Federal security policy documents exist that apply to both civil and defense agencies. 
Current overall security policy does not reflect an interdependent, cohesive collection of security disciplines. 
This proliferation of policy makes it difficult for security personnel to keep up with the changes and be aware
of all the applicable policies for a given system.  Rapidly changing technology also makes it difficult for policy
to keep up with new security challenges caused by advances in capabilities and technology.<p>

CHAPTER 2<p>

<i>GENERAL POLICY</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

<b>2.1	GENERAL POLICY STATEMENT</b><p>

<p>

	(1)	A Customs AIS is any automated information or telecommunications system owned, leased,
or operated by or for Customs.<p>

<p>

	(2)	Customs will implement at least the minimum security requirements as identified in this
policy, to protect AIS resources and information (non-sensitive and sensitive data) processed,
stored, or transmitted by Customs AISs.  Based on risk management, they may apply
additional safeguards to provide the most restrictive set of controls (privileges) that permit the
performance of authorized tasks (principle of least-privilege).  [TD P 71-10]<p>

<p>

	(3)	Sensitive information in Customs AISs must be safeguarded against unauthorized disclosure,
modification, access, use, destruction, or delay in service.<p>

		[USCS 1460-010]<p>

<p>

	(4)	All AISs processing, storing, or transmitting sensitive information must be accredited.<p>

		[TD P 71-10]<p>

<p>

	(5)	Connectivity is prohibited between Customs AISs which handle sensitive data and any other
systems or networks not under Customs authority, unless formally approved by an appropriate
Customs Accrediting Authority.  [USCS 5500-07]<p>

<p>

	(6)	All Customs AISs are for official Customs business only and users have no expectation of
privacy while using these resources.  [USCS 5500-07]<p>

<p>

	(7)	All persons who use, manage, operate, maintain, or develop Customs AISs, applications, or
data must comply with these policies.<p>

<p>

<b>2.2	ROLES AND RESPONSIBILITIES</b><p>

<p>

	Customs performs AIS Security through a variety of roles with specific responsibilities.<p>

	The general AIS Security organization is shown in Figure 2. Customs AIS Security Organization.<p>

<p>

	(1)	<b>Commissioner of Customs</b> responsibilities:<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

		(a)	Annually certify the adequacy of Customs AIS Security Program to the Department
of the Treasury.<p>

<p>

		(b)	Ensure that a viable Customs AIS security education, training, and awareness
program is established.<p>

<p>

		(c)	Ensure that Customs AIS Security Plan documentation is developed and maintained
according to Treasury and Federal standards.<p>

<p>

		(d)	Designate Accrediting Authorities (AA) for sensitive Customs AISs.<p>

<p>

		(e)	Designate an oversight authority for review and validation of the AIS Security
Program.<p>

<p>

		(f)	Delegate to Headquarters and field managers the responsibility for assigning local
AIS security officers, <u>Designated Security Officer</u> (DSO).<p>

<p>

	(2)	The<b> ADP Steering Committee</b>, <b>Security Subcommittee</b> responsibilities:<p>

<p>

<p>

<p>

<p>

<p>

		(a)	Provide general oversight authority for the AIS Security Program.<p>

<p>

		(b)	Conduct independent reviews of the AIS Security Program and assure compliance
with Federal and Treasury policies.<p>

<p>

		(c)	Report the AIS security posture status to the Commissioner. <p>

<p>

	(3)	<b>Assistant Commissioner</b>, OIT, responsibilities:<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

		(a)	Ensure that an operational AIS security program is in place which provides a
centrally administered security policy.  The AIS Security program must comply with
at least the minimum security requirements defined by Treasury and other Federal
mandates, and preserve the operational flexibility necessary to Customs.<p>

<p>

		(b)	Accredit sensitive Customs AIS (general support systems and major applications).
This responsibility is shared with Process Owners.<p>

<p>

		(c)	Implement Customs AIS Security education, training, and awareness program.<p>

<p>

		(d)	Establish adequate and effective management accountability and control to ensure the
protection of AIS resources.<p>

<p>

		(e)	Designate an AIS Security Officer to develop, implement, and enforce the AIS
Security Program to comply with C2 level functional security requirements.<p>

<p>

		(f)	Support AIS security audits and reviews.<p>

<p>

	(4)	The<b> Director, AIS Security Division</b>, responsibilities:<p>

<p>

<p>

<p>

<p>

		(a)	Develop and promote the Customs AIS Security program policy, including: <p>

<p>

			(i)	Interpret policy relating to AIS security functions and develop unique
guidance, as needed.<p>

<p>

			(ii)	Assist with policy compliance efforts by providing explanation or
clarification of AIS security-related questions on issues that may impact
Customs mission.<p>

<p>

			(iii)	Ensure security administration for sensitive AIS, including general support
systems and major applications .<p>

<p>

		(b)	Coordinate the Designated Security Officers (DSOs) for sensitive Customs AISs, and
provide them guidance and assistance in carrying out their functions.<p>

<p>

		(c)	Review and authorize acquisitions, in coordination with the DSOs, and certify that
the acquisition specifications include appropriate AIS security requirements for: <p>

<p>

			(i) 	AIS installation facility operations, equipment, or applications.<p>

<p>

			(ii)	Acquisition of AIS hardware, software, and/or related services.<p>

<p>

		(d)	Provide direction and guidance to system developers in defining and approving
software development security requirements.<p>

<p>

		(e)	Ensure that accreditation packages are prepared for sensitive Customs AISs and
applications.<p>

<p>

			(i)	Provide guidance on the scope and contents of security plans:<p>

				Review security plans prepared by or for the DSOs.<p>

				Prepare statements of residual risk and compliance summary, to
complete each accreditation package.<p>

				Submit the accreditation package to the appropriate authorities.<p>

<p>

			(ii)	Act as a liaison for AIS security issues to the Information Resources
Management (IRM) and Security Programs Division (SPD) managers.<p>

<p>

		(f)	Maintain a current status on all required accreditation documentation.<p>

<p>

		(g)	Establish and maintain a Risk Management program, including risk assessments, for
sensitive Customs AIS resources, including:<p>

<p>

			(i)	AIS facilities.<p>

<p>

			(ii)	General support AISs.<p>

<p>

			(iii)	Major applications.<p>

<p>

		(h)	Act as the liaison for AIS security matters to the Department of the Treasury.<p>

<p>

		(i)	Report computer security incidents and violations to the OIT Assistant Commissioner
(AC), Process Owners (PO), and Office of Internal Affairs (IA), as appropriate.<p>

<p>

		(j)	Coordinate Customs AIS Virus Prevention program, including, recommending virus
prevention solutions, providing guidance in defining the requirements, and selecting
the approach.<p>

<p>

		(k)	Establish standards and provide guidance for the preparation of AIS Disaster
Recovery and Contingency Operations plans including, conducting of agency-wide
analyses, and establishing and verifying strategies for business recovery and alternate
processing.  This includes coordinating the development of viable Disaster Recovery
and Contingency Operations plans for Customs AIS facilities.<p>

<p>

		(l)	Establish standards and provide guidance for preparing End-User AIS Contingency
plans.<p>

<p>

		(m)	Ensure that all interactive users of Customs AIS meet at least the minimum standards
of eligibility for access.  [USCS 1460-010]<p>

<p>

		(n)	Conduct AIS security compliance review and oversight activities.<p>

<p>

		(o)	Support areas or issues requiring AIS security-related research and development
effort.<p>

<p>

		(p)	Support AIS security audits and reviews, providing assistance as appropriate.<p>

<p>

	(5)	<b>IRM manager</b> responsibilities:<p>

<p>

		(a)	Ensure security-related quality assurance throughout the software development
life-cycle.<p>

<p>

		(b)	Coordinate with AIS Security for review of the SDLC documents and activities to
incorporate security into developed products.  [TD P 84-01]<p>

<p>

		(c)	Assist with AIS security audits and reviews, as appropriate.<p>

<p>

	(6)	<b>Process Owner</b> (identified in the Major Application Security Plan) responsibilities:<p>

		[USCS PPP]<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

		(a)	Accredit assigned Customs AIS Process (responsibility shared with the Assistant
Commissioner, OIT).``<p>

<p>

		(b)	Establish user requirements and controls that conform to Customs System
Development Life Cycle (SDLC) Handbook.  [USCS 5500-04]<p>

<p>

		(c)	Specify that locally developed sensitive AIS products comply with C2 level functional
security requirements.<p>

<p>

		(d)	Designate or ensure that information sensitivity levels are assigned for the
information processed, stored, or transmitted by the Customs AIS Process.<p>

<p>

		(e)	Coordinate with the Customs Office of Regulations and Rulings, Disclosure Law
Branch, to publish a "System of Records" in the Federal Register for any Customs
Process that contains Privacy Act data, as appropriate.  [TD P 25-04]<p>

<p>

		(f)	Ensure that user access requirements and controls are defined for the Customs AIS
Process.<p>

<p>

		(g)	Delegate user access request authorization.<p>

<p>

		(h)	Assist with AIS security audits and reviews, as appropriate.<p>

<p>

	(7)	<b>Application Development Manager</b> responsibilities:<p>

		<p>

		Application development managers (both OIT and development organizations external to OIT)
have data ownership responsibilities for application-related information processed, stored,
created, manipulated or transmitted by and/or for the application, unless data ownership is
otherwise designated by agreements, functions, and/or assignments.<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

		(a)	Ensure that locally developed AIS products comply with C2 level functional security
requirements.<p>

<p>

		(b)	Ensure that at least the minimum security requirements mandated by law, statute, or
regulation are incorporated into Customs AIS Process applications.<p>

<p>

		(c)	Adhere to Customs System Development Life Cycle (SDLC) Handbook development
standards.  [USCS 5500-04]<p>

<p>

		(d)	Prepare documentation for application certification and accreditation packages.<p>

<p>

		(e)	Assist with AIS security audits and reviews, as appropriate.<p>

<p>

	(8)	<b>AIS Owner</b> responsibilities:<p>

<p>

		(a)	Ownership responsibilities for sensitive Customs AISs are assigned to the Office of
Information and Technology, unless otherwise identified.<p>

<p>

		(b)	Assist with AIS security audits and reviews, as appropriate.<p>

<p>

	(9)	<b>AIS Security Administrator</b> responsibilities:<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

		(a)	Act as the primary point-of-contact for AIS security issues.<p>

<p>

		(b)	Identify security threats and establish safeguards (countermeasures) to protect
Customs AIS resources.<p>

<p>

		(c)	Implement security policy for AIS resources for which Customs has direct
operational responsibility.<p>

<p>

		(d)	Ensure that all personnel receive appropriate AIS security training.<p>

<p>

		(e)	Administer the Computer Security Incident Reporting Capability (CSIRC) program
including establishing reporting criteria, and coordinating with the Office of Internal
Affairs (IA), as appropriate.<p>

<p>

		(f)	Report to the AIS Security Officer any security incidents, such as attempts to gain
unauthorized access to information, virus infections, or other events affecting AIS
security, including damage assessments and actions taken to prevent future incidents,
as appropriate.<p>

<p>

		(g)	Ensure that viable End-User AIS Contingency Plans are developed to assure
continued operations of essential AIS functions should an emergency occur.<p>

<p>

		(h)	Coordinate local AIS Security Administrators.<p>

<p>

		(i)	Advise Customs management on implementing provisions of this policy and
applicable guidelines.<p>

<p>

		(j)	Ensure all AIS operations are conducted as authorized in the accreditation, or that
certification package modifications are prepared to accommodate the variances.<p>

<p>

		(k)	Assist with AIS security audits and reviews, as appropriate.<p>

<p>

	(10)	A <b>Designated Security Officer (DSO)</b> must be assigned for each sensitive AIS, including
general support systems and major applications.<p>

<p>

		<u>Designated Security Officer</u>:  The Customs person responsible to the AA for ensuring that
security is provided for and implemented throughout the life-cycle of an AIS (from concept
development through design, development, operations, maintenance, and disposal phases).<p>

<p>

		The DSO responsibilities:<p>

<p>

		(a)	Ensure that appropriate security features are implemented in <u>new</u> sensitive AISs  and
that they meet at least the minimum security requirements defined in this policy.<p>

<p>

			Review and authorize acquisitions, in coordination with the AIS Security Officer, and
certify that appropriate AIS security is included in the specifications for the operation
of an AIS installation facility, equipment, or application, and for acquisition of AIS
hardware, software, or related services.<p>

<p>

		(b)	Prepare site certification packages in preparation for accreditation.<p>

<p>

			Certification-related activities include:<p>

<p>

			(i)	Conduct design reviews, security tests, and certify the results when security-relevant changes (hardware, software, firmware, etc.) are made, to ensure
that the accreditation status is not affected.<p>

<p>

			(ii)	Identify and recommend AIS security improvements to management. <p>

<p>

			(iii)	Ensure that configuration management (CM) is used and maintained to
protect the AIS security-related features.<p>

<p>

		(c)	Prepare, or oversee the preparation of, AIS security plans, and maintain related
documentation for each AIS under their purview.<p>

<p>

		(d)	Ensure the distribution of end-user security procedures tailored for administrators,
and operators of sensitive AISs; advising users of the security features and
procedures used on the AISs.  [USCS 5500-04]<p>

<p>

		(e)	Coordinate with the appropriate DSOs of other AISs, process owners, application
development managers, and the Customs AIS Security Officer to ensure that planning
adequately addresses the AIS security requirements.<p>

<p>

		(f)	Establish, in coordination with AIS Security Administration, access control criteria
and administrative procedures consistent with Customs policy, by which only
authorized persons gain access to the AIS.<p>

<p>

		(g)	Provide support for audit trail reviews and related discrepancy investigations.<p>

<p>

		(h)	Report immediately to AIS Security Administration, any security incident, such as
attempts to gain unauthorized access to information, virus infections, or other events
or conditions which may affect AIS security accreditation.<p>

<p>

		(i)	Conduct periodic security reviews of AIS facilities under their purview to assure
safeguards are commensurate with the AIS information being stored, processed or
transmitted.<p>

<p>

		(j)	Assist with AIS security audits and reviews, as appropriate.<p>

<p>

	(11)	<b>Local AIS Security Administrator</b> responsibilities:<p>

<p>

		(a)	Request and/or grant user access to AIS based on management authorization.<p>

<p>

		(b)	Remove or modify user access based on authorized requests of management, process
owners, and/or administrative processes.<p>

<p>

		(c)	Conduct authorized reviews of the user access to assure timely detection of
suspicious, inappropriate, or unauthorized activity.<p>

<p>

		(d)	Report to DSO or AIS Security Administration, any security incidents or other events
affecting AIS security (e.g., virus infections, attempts to gain unauthorized access
to information, suspicious, inappropriate, or unauthorized activity, etc.).<p>

<p>

		(e)	Assist with AIS security audits and reviews, as appropriate.<p>

<p>

		(f)	Support compliance of C2 level functional security requirements for locally
developed sensitive AIS products, as appropriate.<p>

<p>

	(12)	<b>Facility manager</b> (or functional equivalent) responsibilities:<p>

<p>

		(a)	Ensure that a physical inventory is maintained (usually by the local property officer)
of all AIS resources within their area of responsibility.<p>

<p>

		(b)	Ensure the physical security and accreditation of the sensitive AIS facility (site).<p>

<p>

			Included in these responsibilities are AIS-related safety and security activities (e.g.,
Occupant Emergency Plan, Physical Security Plan, etc.).<p>

<p>

		(c)	Coordinate with appropriate DSOs any AIS security-relevant facility changes.<p>

<p>

		(d)	Assist with AIS security audits and reviews, as appropriate.<p>

<p>

	(13)	<b>Manager</b> and <b>Supervisor</b> responsibilities:<p>

<p>

		(a)	Ensure that sensitive AIS data and resources within their area of responsibility are
properly protected by appropriate security safeguards.<p>

<p>

		(b)	Ensure that subordinates have access only to those AIS applications and data
necessary to perform authorized tasks (principle of least-privilege).<p>

<p>
		(c)	Report to the appropriate Security Administrator any changes to employee access
requirements.  Also coordinate with appropriate management when employee or
management transfers occur which might affect AIS access.<p>
<p>

		(d)	Review employee AIS access activity to ensure compliance to AIS security
requirements and provide timely detection of suspicious, inappropriate, or
unauthorized activity.<p>

<p>

		(e)	Ensure that a DSO is identified for each sensitive AIS (or group of facilities
designated as a sensitive AIS) used by employees under their management authority,
as warranted.<p>

<p>

		(f)	Report AIS security-related changes in their own job status to the responsible
Security Administrator.<p>

<p>

		(g)	Ensure that proposed acquisitions of sensitive AIS-related hardware, software,
communications, applications, and equipment satisfy AIS security requirements and
receive DSO concurrence prior to acquisition.<p>

<p>

		(h)	Ensure that sensitive AIS products developed under their management authority
comply with C2 level functional security requirements.<p>

<p>

		(i)	Ensure that employees under their management authority receive AIS security
training relevant to their assignments, as required by laws, regulations, MOUs, or
other agreements.<p>

<p>

		(j)	Attend AIS security training as required by laws, regulations, MOUs, or other
agreements.<p>

<p>

		(k)	Assist with AIS security audits and reviews, as appropriate.<p>

<p>

	(14)	<b>User</b> responsibilities:<p>

<p>

		(a)	Protect access IDs, authentication codes (e.g., passwords, personal identification
numbers [PIN], encryption codes, etc.) from improper disclosure.<p>

<p>

		(b)	Access only authorized AIS applications and data necessary to perform approved 
responsibilities.<p>

<p>

			Due to technical capability of some AIS, access might exceed authority.  Access
capability however, does not equate to authority (e.g., <b>casual browsing of data is
not permitted</b>).<p>

<p>

			<b>It is a violation of law for users to access U.S. Government AIS data in excess
of their authorization. [18 USC 1030]</b><p>

<p>

		(c)	Notify supervisor and AIS Security Administrator when AIS access or authority is
no longer required for their authorized tasks.<p>

<p>

		(d)	Apply the security controls required by AIS security policies and standards.<p>

<p>

		(e)	Comply with the provisions in the Customs AIS Security Policy manual.<p>

<p>

		(f)	Attend AIS security training as required by laws, regulations, MOUs, or other
agreements.<p>

<p>

		(g)	Provide assistance with AIS security audits and reviews as required by laws,
regulations, MOUs, or other agreements, as appropriate.<p>

<p>

	(15)	<b>External agency user</b> responsibilities:<p>

<p>

		(a)	Comply with U.S. Government AIS-related laws and regulations.<p>

<p>

		(b)	Comply with inter-agency MOU (Memorandum of Understanding) or other formal
agreements between themselves and Customs.<p>

<p>

			External agencies must designate AIS Security Coordinators.  The head of the
external agency, or delegate (<u>as identified in writing</u>), is responsible for ensuring that
employees and contractors under their authority observe Customs AIS Security
Policy as identified in this manual.<p>

<p>

		(c)	Protect access IDs, authentication codes (e.g., passwords, personal identification
numbers [PIN], encryption codes, etc.) from improper disclosure.<p>

<p>

		(d)	Access only authorized AIS applications and data necessary to perform approved
activities.<p>

<p>

			Due to the technical capability of some AIS, access might exceed authority.  Access
capability however, does not equate to authority (e.g., <b>casual browsing of data is
not permitted</b>).<p>

<p>

			<b>It is a violation of law for users to access U.S. Government AIS data in excess
of their authorization. [18 USC 1030]</b><p>

<p>

		(e)	Notify Customs AIS Security Administrator when AIS access or authority is no
longer required for approved tasks.<p>

<p>

		(f)	Use the security controls required by AIS security policies and standards.<p>

<p>

		(g)	Comply with the provisions in the Customs AIS Security Policy manual.<p>

<p>

		(h)	Attend AIS security training as required by laws, regulations, MOUs, or other
agreements.<p>

<p>

		(i)	Provide assistance with AIS security audits and reviews as required by laws,
regulations, MOUs, or other agreements, as appropriate.<p>

<p>

	(16)	<b>Trade community user</b> responsibilities:<p>

<p>

		(a)	Comply with U.S. Government AIS-related laws and regulations;<p>

<p>

		(b)	Comply with any formal agreements governing access to Customs AIS resources.<p>

<p>

			Trade community user access to Customs AIS resources must be approved by the
appropriate Customs Accrediting Authorities and formally documented.<p>

<p>

		(c)	Access only authorized AIS applications and data necessary to perform approved 
activities.<p>

			<p>

			AIS access will be restricted to authorized data and processes.  Due to the technical
capability of some AIS however, access might exceed authority.  Access capability
does not equate to authority (e.g.,<b> casual browsing of data is not permitted</b>). <p>

<p>

			<b>It is a violation of law for users to access U.S. Government AIS data in excess
of their authorization. [18 USC 1030]</b><p>

<p>

		(d)	Protect access IDs, authentication codes (e.g., passwords, personal identification
numbers [PIN], encryption codes, etc.) from improper disclosure.<p>

<p>

		(e)	Notify Customs AIS Security Administrator when AIS access or authority is no
longer required for approved tasks.<p>

<p>

		(f)	Use the security controls required by Customs AIS security policies and standards.<p>

<p>

		(g)	Comply with the provisions in the Customs AIS Security Policy manual.<p>

<p>

		(h)	Attend AIS security training as required by laws, regulations, MOUs, or other
agreements.<p>

<p>

		(i)	Support Customs AIS security audits and reviews as required by laws, regulations, 
MOUs, or other agreements.<p>

CHAPTER 3<p>

<i>AIS SECURITY LIFE CYCLE</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

This section documents activities for acquisition and development of AIS and related applications.  It provides
guidance to ensure that sensitive AISs and applications are developed, acquired, and documented according
to Customs policy.<p>

<p>

Topics include:<p>

<p>

<u>Security Planning</u>.  Security planning activities are the responsibility of the appropriate Customs Process
Owner, AIS owner, Applications Developer, DSO, and AIS Security Officer.  These activities pertain to the
development or acquisition of new Customs AISs and applications, or changes to existing ones.<p>

<p>

<u>Certification and Accreditation</u>.  Certification and accreditation activities are the responsibility of the
appropriate Accrediting Authorities (AAs), DSO, and the AIS Security Officer.<p>

<p>

<u>Security Education, Training, and Awareness</u>.  These activities are ongoing and apply to all personnel who
manage, use, or operate Customs AISs, whether or not they are Customs employees.<p>

<p>

<u>Security Oversight</u>.  The AIS Security Officer conducts policy-related security oversight activities for ongoing
day-to-day operations.  The ADP Steering Committee, Security Subcommittee, is designated as the oversight
authority for Customs AIS Security Program. <p>

<p>

<b>3.1	SECURITY PLANNING</b><p>

<p>

	Security planning activities support the accreditation of all sensitive Customs AISs, including general
support systems and major applications.  This section discusses the processes for AIS security
planning, risk management, disaster recovery, contingency operations, and the documentation
required to achieve certification and accreditation.<p>

<p>

	Prior to the development or acquisition of sensitive AISs and applications, the AIS Security Officer
must be consulted to establish the scope of the security-related activities and necessary documentation.<p>

<p>

<b>3.1.1	Approvals</b><p>

<p>

	The security planning process requires the DSO to seek approvals at several steps during system
planning activities.<p>

<p>

	(1)	To the extent feasible, security requirements must be defined prior to the start of AIS
development,  be approved by the DSO and AIS Security Officer, and included as part of the
acquisition process.<p>

<p>

	(2)	Prior to the start of AIS development, system designs must include security reviews and be
approved by the AIS Security Officer.<p>

<p>

	(3)	Security test plans and security testing results must be approved by the AIS Security Officer. <p>

<p>

	(4)	Prior to accreditation, AIS security planning documentation must be approved by AIS
Security Administration.<p>

<p>

<b>3.1.2	AIS Security Plan</b><p>

<p>

	The objective of security planning is to improve the protection of AIS resources and information. <p>

<p>

	(1)	Information owners (those managers most directly affected by and interested in the
information or processing capabilities), must demonstrate how they are planning to protect
information and processing capabilities from loss, misuse, unauthorized access, modification,
unavailability, or undetected security-related activities.<p>

<p>

	(2)	The AIS Security Officer will define the scope and format for Customs AIS security plans
to ensure a standardized approach that provides sufficient information to assess the security
posture and complies with applicable regulations.<p>

<p>

	(3)	Each sensitive Customs AIS requires a security plan to document its security requirements,
from development or acquisition, through implementation and operation, to disposal.  The
assigned DSO will prepare and maintain the system security plan.<p>

<p>

		(a)	When an existing non-sensitive AIS is changed to a sensitive Customs AIS, an
appropriate AIS Security Plan must be prepared.<p>

<p>

		(b)	AIS Security Officer will  determine the final boundaries for AIS networks.<p>

<p>

		(c)	The DSOs will clearly define the boundaries of non-networked sensitive AISs under
their purview and are responsible for ensuring that the AISs are operated according
to the approved AIS security plan.<p>

<p>

	(4)	An AIS security plan will include at least the following: (See also: Appendix D)<p>

<p>

		(a)	Risk management actions pertaining to the AIS.  (See also: Section 3.2.2)<p>

<p>

		(b)	A Certification statement that reflects the results of security features tests and
implementation schedules applicable to the AIS.  (See also: Section 3.4)<p>

<p>

		(c)	A Disaster Recovery and Contingency Operations Plan, consisting of:  (See also:
Section 3.1.3)<p>

<p>

			(i)	emergency response plan,<p>

<p>

			(ii)	back-up operations plan, and<p>

<p>

			(iii)	postdisaster recovery plan.<p>

<p>

		(d)	Security procedures and practices for users and operators of AISs.   (See also:
Section 3.5)<p>

<p>

	(5)	A single (generic) security plan can  cover multiple AISs in some situations.  Such plans must
consider ownership responsibilities, administrative burdens, technical complexity, and be
cost-effective.<p>

<p>

		(a)	A single (generic) AIS security plan can include multiple comparable AISs in similar
and associated operating environments.  If additional security measures for a
particular operating environment are required, they can be added as supplemental to
the primary security plan, rather then create a new plan.  The plan must show how
the changes are associated and maintain the plan integrity.<p>

<p>

		(b)	A single (generic) AIS security plan can cover related AIS resources that perform
similar and/or associated functions and are physically and logically located in the
same general area.  The plan might Include Local Area Networks (LANs), hosts with
terminals, groups of stand-alone personal computers, workstations, and other related
office automation systems.<p>

<p>

		(c)	A single (generic) AIS security plan can cover related AIS resources that perform
similar and/or associated functions in support of a common mission, but might be at
unspecified or physically and/or logically diverse locations.  Such a plan must
consider the diversity of conditions that might be encountered and ensure that
adequate and appropriate levels of security are provided.  The plan might include
personal computers, workstations, and other related AIS equipment over Wide Area
Networks (WANs), Local Area Networks (LANs), and/or other communications
networks or mediums.<p>

<p>

<b>3.1.3	Disaster Recovery and Contingency Operations Planning</b><p>

<p>

	(1)	Each essential (mission-critical) sensitive Customs AIS, including general support systems and
major applications, or grouping of like systems, shall have a viable and logical Disaster
Recovery and Contingency Operations Plan.  Plans shall be well-written, routinely reviewed,
tested, and updated to provide for reasonable continuity of AIS support if normal operations
are interrupted.  This enables rapid restoration of vital operations and resources, and reduces
downtime.  [OMB A-130,AIII]<p>

<p>

	(2)	Disaster Recovery and Contingency Operations planning elements must include, at least the
following:<p>

<p>

		(a)	Emergency response procedures appropriate to government laws, regulations, and
directives, civil disorder, fire, flood, natural disaster, bomb threat, or other incidents
or activity where lives, property, or the capability to perform essential functions are
threatened or seriously impacted.<p>

<p>

		(b)	Back-up operations plans, procedures, and responsibilities to ensure that essential
(mission-critical) operations will continue if normal processing or data
communications are interrupted for an unacceptable period.  The minimally
acceptable level of degraded operation of the essential (mission-critical) systems or
functions must be identified and ranked so that plan priorities are accomplished.  This
must include appropriate provisions for storage, maintenance, and retrieval of
essential back-up and operational support data.<p>

<p>

		(c)	Post-disaster recovery procedures and responsibilities to facilitate the rapid
restoration of normal operations at a primary site, or if necessary at an alternate
facility, following destruction, major damage, or other significant interruptions of the
primary site.<p>

<p>

	(3)	The AIS Security Officer is responsible for ensuring the development of AIS Disaster
Recovery and Contingency Operations Plans for general support systems and major
applications, and for defining the testing requirements that the DSOs will carry out.<p>

<p>

		(a)	The AIS Disaster Recovery and Contingency Operations Plans shall provide for
viable and reasonable continuity of essential AIS capabilities if normal operations are
interrupted.<p>

<p>

		(b)	The AIS Security Officer provides guidance for the formulation of these plans.  The
plans must address the business continuity requirements for interfacing with
applications and be supported by application contingency plans.<p>

<p>

		(c)	AIS application contingency planning activities are conducted in concert with facility
disaster recovery planning and/or end-user contingency planning, when such plans
exist.<p>

<p>

		(d)	Facility disaster recovery plans address physical security, the protection of general
AIS support, and help ensure the availability of critical assets (resources) to facilitate
the continuity of operations during an emergency.<p>

<p>

	(4)	The DSO will develop and maintain a current viable AIS Disaster Recovery and Contingency
Operations Plan for each sensitive and/or mission-critical AIS (general support system,
microcomputers, etc.).  The plan will provide reasonable assurance that critical data
processing support can be continued, or quickly resumed, if normal operations are
interrupted.<p>

<p>

		(a)	Depending on the results of the criticality assessment (business impact analysis), the
DSO may determine that an AIS is not sufficiently critical to the agency or user
community to warrant a Disaster Recovery and Contingency Operations Plan.  In this
event the DSO will provide a Continuity of Operations Statement to that effect,
subject to the approval of the Accrediting Authorities.<p>

<p>

		(b)	End-User AIS Contingency Plans shall be developed, reviewed, and updated at least
every three years, or whenever major processing environment changes occur (e.g.,
physical site, hardware, software, operating systems, etc.).<p>
<p>

	(5)	All plans must be operationally tested at a frequency commensurate with the risk and
importance of loss or harm that could result from disruption of AIS support.<p>

<p>

<b>3.2	SECURITY REQUIREMENTS</b><p>

<p>

<b>3.2.1	Policy Derived Requirements</b><p>

<p>

	Security requirements must be risk management based and result from an analysis of policy as applied
to data and augmented by a risk analysis.  These requirements must be compared to an AIS security
features cost-benefit analysis, not against the minimum requirements.  Appendix F discusses policy
methodology.<p>

<p>

<b>3.2.1.1	Global Security Policy</b><p>

<p>

	The security policy of Customs is to operate its AISs in compliance with existing Federal and national-level policy as stated in public laws (PL), Executive Orders (EO), Federal Information Processing
Standard Publications (FIPS PUBS), Office of Management and Budget (OMB) circulars and
bulletins, Treasury Directives (TD), and Customs Directives (CD); to protect the data and information
in the AISs; and to effectively support the Customs mission.<p>

<p>

<b>3.2.1.2	Cost-Effective Security</b><p>

<p>

	Federal regulations and Treasury directives require that (i) resources are used consistent with the
agency mission; (ii) programs and resources are protected from waste fraud and mismanagement; and
(iii) the best available and most cost-effective products are used in the design and implementation of
AIS security protection. The selection of security products must consider the costs of managing and
administering such products.  Meeting these requirements, and the continually increasing demands for
protection of information, requires consideration of products which are compatible with existing and
anticipated AIS hardware and software configurations.  [OMB A123; TD P 71-10]	<p>

<p>

<b>3.2.2	Risk Management</b><p>

<p>

	(1)	Risk management is the total process of identifying, controlling, and eliminating or reducing
risks that may affect AIS resources.  It includes: risk analysis (identify and analyze the risks);
a determination of the appropriate levels of resources necessary to protect the AIS; a
management decision to implement selected AIS security  safeguards based on the risk
analysis, including accepting residual risk, if necessary; and effectiveness reviews.<p>

<p>

	(2)	Risks are derived from the analysis of threats and vulnerabilities.  A formal risk analysis
requires determining relativity among risks and assessing associated damage or loss
potentials.  This relationship forms the basis for selecting effective safeguards.  Before
starting the risk analysis process, the AIS Security Officer should be consulted for guidance
on the scope of the analysis and the recommended approach.  In the absence of specific
directions, refer to the <u>Treasury Risk Assessment Guideline</u>.  [TD P 85-03] <p>

<p>

		(a)	A risk analysis will be conducted or sponsored by the AIS Security Officer for each
Customs general support AIS (mainframe or network) facility for the following
conditions.<p>

<p>

			(i)	Whenever a new or substantially modified AIS facility design is approved.<p>

<p>

			(ii)	Before design specifications for new general support AISs and their
supporting installations are approved.<p>

<p>

			(iii)	Whenever a significant change occurs to the general support AIS (e.g.,
adding a LAN; changing from batch to on-line processing; adding dial-up
capability, etc.).  The criteria for defining significant changes will be
commensurate with the sensitivity of the data processed by the general
support AIS.<p>

<p>

			(iv)	At periodic intervals established by the AIS Security Officer commensurate
with the sensitivity of the data processed, but not to exceed every three
years, if no risk analysis is performed during that period.<p>

<p>

		(b)	The DSO will coordinate or conduct a risk analysis which focuses on the automated
(technical) and administrative security control techniques associated specifically with
the AIS or process under review.  This includes the interface between the operating
systems and the applications, and/or the communications environment and the
applications, and the threats inherent in processing in a specific environment. 
Facility (physical) risk analysis must be considered when defining and approving
security specifications for the major applications or network systems.<p>

<p>

	(3)	Responsibility for carrying out the recommendations of a risk analysis rests with the manager
of the AIS facility under review, or the application developer, as appropriate.  Response to
the recommended safeguards includes implementation schedules, or rationale for non-implementation.  They must evaluate the recommendations and determine whether to carry
them out based on technical and operational feasibility, and costs.  Customs Accreditation
Authorities (AAs) will consider the effects of the reviewer's actions in making accreditation
decisions.<p>

<p>

<b>3.3	DEVELOPMENT</b><p>

<p>

	(1)	The Customs System Development Life Cycle (SDLC) methodology described in the SDLC
handbook applies to all systems and applications (mainframe, networked, or stand-alone),
developed by or for Customs and used by Customs employees, contract personnel, other
government agencies, and persons or companies using Customs resources, whether or not
under direct control of the Office of Information and Technology (OIT).  It incorporates a
standards-based approach to systems development and AIS development policies.<p>

<p>

	(2)	The SDLC handbook is required reading for all persons new to the Customs automation
environment and incorporates Government and industry development standards applicable to
Customs.  It describes the minimum requirements that Customs applications must meet to
comply with existing standards and directives throughout their projected life-cycles and
facilitates a step-by-step process to deliver accurate, effective and efficient AISs to the users. 
[USCS 5500-4]<p>

<p>

<b>3.4	CERTIFICATION AND ACCREDITATION</b><p>

<p>

	Certification and accreditation, although related, are not the same processes nor do they have the same
objectives.  Certification is a short term activity that is repeated after any significant AIS-related
change and is a prerequisite for accreditation.  Accreditation is a long-term authorization, up to three
years, for an AIS to operate based on the facts, plans, and schedules developed during certification.<p>

<p>

	(1)	Each Customs general support AIS and major application is considered to contain or process
sensitive information and must be certified and accredited.  <p>

<p>

	(2)	All other Customs AISs and applications which contain or process sensitive information and
must be certified and accredited, as appropriate.<p>

<p>

<b>3.4.1	Certification</b><p>

<p>

	Certification is the comprehensive testing and evaluation of the technical and nontechnical AIS security
features, and other safeguards used in support of the accreditation process.   It establishes the extent
to which a particular AIS design and implementation meet a specified set of security requirements. 
Certification primarily addresses software and hardware security safeguards, but also considers
procedural, physical, and personnel security measures employed to enforce AIS security policy.<p>

<p>

	(1)	Software Certification<p>

<p>

		(a)	<u>In-house developed software</u>.  Design reviews and systems tests will be performed,
and a certification of the results recorded, for newly developed software, and for
existing software when significant modifications are made.<p>

<p>

		(b)	<u>Government-Off-The-Shelf Software (GOTS)</u>.  Government developed software will
be examined to assure that the software does not contain features which might be
detrimental to Customs AIS security.  Software design reviews and systems tests will
be performed, and a certification of the results recorded when significant
modifications are made to GOTS software.<p>

<p>

		(c)	<u>Commercial-Off-The-Shelf Software (COTS)</u>.  Commercially procured software will
be examined to assure that the software does not contain features which might be
detrimental to AIS security.  Security-related software will be examined to assure
that the security features function as specified.<p>

<p>

	(2)	The DSO will oversee or conduct AIS certification tests.  Individuals who conduct the
certification testing will be independent of the AIS developers, if resources are available.  The
testing process and results will be documented in a format that ensures that the tests can be
repeated and achieve the results reflected in the certification report, if required.<p>

<p>

	(3)	AIS security safeguards must be modified to correct any deficiencies found during
certification testing, as appropriate.<p>

<p>

	(4)	Certification testing will vary with the AIS security mode of operation.<p>

<p>

		(a)	<u>Dedicated</u> security mode does not require extensive certification efforts as users and
data are not required to be separated with technical security measures.  Certification
focuses on the physical, procedural, and personnel security measures to ensure that
all users have the appropriate access approval and need-to-know for all Customs data
on the AIS.  (Example: a standalone personal computer).<p>

<p>

		(b)	<u>System-high</u> security mode requires that hardware and software security features
reliably segregate users from data for which they do not have a need-to-know, in
addition to the requirements of Dedicated security mode.  (Example: a general
support AIS).<p>

<p>

		(c)	<u>Compartmented</u> and <u>multilevel</u> security modes are used for classified AISs and are
not addressed in the manual.  (Reference: CIS HB 1400-03).<p>

<p>

	(5)	The AIS Security Officer will provide guidance on conducting certification testing.<p>

<p>

<b>3.4.2	Accreditation</b><p>

<p>

	"Any significant modification made to an SBU AIS or network should be reviewed to determine the
impact on security."<p>

<p>

	"Modified systems/networks will be reaccredited by appropriate officials as outlined in TD P 71-10,
Sect. 7.A in light of the results of the security review."  [TD P 71-10]<p>

<p>

	(1)	Accreditation is the official management authorization to operate an AIS based on the
following criteria.<p>

<p>

		(a)	The particular security mode of operation.<p>

<p>

		(b)	The defined set of threats, with related vulnerabilities and prescribed safeguards.<p>

<p>

		(c)	The given operational environment.<p>

<p>

		(d)	The stated operational concept.<p>

<p>

		(e)	The stated interconnection to other AISs.<p>

<p>

		(f)	The operational necessity.<p>

<p>

		(g)	An acceptable level of risk for which the Accrediting Authorities have formally
assumed responsibility.<p>

<p>

	(2)	The Accrediting Authorities (AA) officially declare that a certified AIS will adequately
protect related information, will operate in one of the following security modes, and accept
security responsibilities for the AIS operation.<p>

<p>

		The AIS security mode of operation <u>is</u> based on data sensitivity,  access approval, and need-to-know of the AIS users.  Available or proposed AIS security features <u>do not</u> determine the
security mode.<p>

<p>

		Applicable Security Modes of operations are:<p>

<p>

		(a)	<u>Dedicated</u> security mode.  (See also: Certification. Section 3.4.1.(4)(a).<p>

<p>

		(b)	<u>System-high</u> security mode.  (See also: Certification. Section 3.4.1.(4)(b).<p>

<p>

	(3)	All sensitive AISs, including general support systems and major applications, must be
submitted for and be accredited expeditiously.<p>

<p>

	(4)	The AIS security plan documentation, discussed in Section 3.1, will be submitted by the DSO
to the AIS Security Officer for review.  The AIS Security Officer will develop a summary
of compliance to include security requirements and a statement of residual risk.<p>

<p>

	(5)	Prior to accreditation, Customs Information Resources Management (IRM) and Security
Programs Division (SPD) representatives will review security plan documentation,  for
sensitive AIS, including the summary of compliance and statement of residual risk.<p>

<p>

	(6)	The appropriate Customs AAs will make the accreditation decision based on the summary of
compliance, a statement of residual risk, and an approved AIS security plan.  The
accreditation process results in a decision that the AIS is:<p>

<p>

		(a)	accredited to operate, or<p>

<p>

		(b)	given interim operating approval for a specific time pending satisfactory completion 
of specified requirements, or<p>

<p>

		(c)	denied permission to operate, until identified deficiencies are corrected.<p>

<p>

	(7)	Every sensitive AIS covered by this policy must be reaccredited at least every three years. 
The accreditation status and supporting documentation will be reviewed and revised for the
following conditions or events, as appropriate.<p>

<p>

		(a)	A significant change occurs in the hardware, software, or data communications
configuration that impacts the AIS security safeguards defined in the original
accreditation package.  A significant change is one whose impact is such that it 
needs to be brought to the attention of the AAs.<p>

<p>

		(b)	The sensitivity level of the information being processed is significantly changed.<p>

<p>

		(c)	The security mode of operation is changed.<p>

<p>

		(d)	AIS facility or remote terminal area changes occur, including relocations or
structural modifications, which may affect AIS security.  <p>

<p>

			Whenever a major office relocation occurs (e.g., moves to a new building), the AIS
Security Officer should conduct an AIS compliance review to decide whether the
change in physical location impacts the AIS security posture.  The results of the
security review should be retained as part of Customs AIS security documentation.<p>

<p>

		(e)	An AIS security-related event occurs that appears to invalidate the accreditation.<p>

<p>

	(8)	The accreditation package revision and review process will include at least the following
activities and information.<p>

<p>

		(a)	The same steps required for the original accreditation package will be completed. 
Portions of the package which configuration management shows to still be valid, need
not be redone.<p>

<p>

		(b)	The IRM and SPD representatives will review and approve the AIS security plan,
summary of compliance, and statement of residual risk, as appropriate.<p>

<p>

		(c)	The appropriate AAs will review and reaccredit the AIS.<p>

<p>

	(9)	The AIS Security Officer will maintain a record system containing the status of the documents
in the Customs AIS accreditation packages.<p>

<p>

	(10)	The AAs are the only ones authorized to exempt an operation from the security requirements
specified in the accreditation statement.  This exemption must be formally documented in a
written waiver and retained with the original accreditation package.<p>

<p>

<b>3.5	PROCEDURES AND PRACTICES</b><p>

<p>

	This policy manual does not contain AIS security-related procedures and practices.  They are
presented separately and provided to Customs AIS users, administrators, and operators, as
appropriate.  Procedures and practices explain specific AIS security mechanism operations so that
users, administrators, and operators may consistently and effectively protect Customs information. 
Such information should also be addressed during training, when applicable. ( See also: Section 1.5.1)<p>

<p>

<b>3.6	EDUCATION, TRAINING, AND AWARENESS</b><p>
<p>

	"The Computer Security Act requires Federal agencies to provide for the mandatory periodic training
in computer security awareness and accepted computer security practice of all employees who are
involved with the management, use, or operation of a Federal computer system within or under the
supervision of the Federal agency.  This includes contractors as well as employees of the agency." <p>

<p>

	"Training is particularly important in view of the changing nature of information resources
management.  Decentralization of information technology has placed the management of automated
information and information technology directly in the hands of nearly all agency personnel rather than
in the hands of a few employees at centralized facilities."<p>

<p>

	"The OMB Circular A-130, Appendix III enforces such mandatory training by requiring its completion
prior to granting access to the system."  [OMB A-130,AIII]<p>

<p>

	(1)	The Director, AIS Security Division, shall ensure that a Customs AIS Security Education,
Training, and Awareness Program is established. <p>

<p>

	(2)	Training may be presented in stages, for example, as more access is granted.  In some cases,
the training should be in the form of classroom instruction.  In other cases, interactive
computer sessions or well-written and understandable brochures may be sufficient, depending
on the risk and magnitude of harm related to the subject matter..<p>

<p>

	(3)	Refresher awareness training frequency shall be determined by the Director, AIS Security.<p>

<p>

	(4)	Each new user of a general support system in some sense introduces a risk to all other users.
Therefore, each user should be versed in acceptable behavior -- the rules of the system --
before being allowed to use the system.<p>

<p>

	(5)	Training should be tailored to what a user needs to know to use the system securely, given
the nature of that use, and how to get help in the event of difficulty with using or security of
the system.<p>

<p>

	(6)	Access provided to members of the public should be constrained by controls in the
applications through which access is allowed, and training should be within the context of
those controls.<p>

<p>

	(7)	Additional awareness training will be provided when significant changes occur in AIS security
environments or procedures, or to employees who assume new positions or assignments
dealing with information at a higher level of sensitivity.<p>

<p>

	(8)	Security awareness training should include the following topics, as appropriate.<p>

.<p>

		(a)	Common AIS threats, vulnerabilities, and risks.<p>

<p>

		(b)	Information accessibility, handling, labeling, and storage protection considerations.<p>

<p>

		(c)	Physical and environmental AIS protection considerations.<p>

<p>

		(d)	AIS data access controls and rules of behavior.<p>

<p>

		(e)	Procedures for disaster recovery and contingency operations plans.<p>

<p>

		(f)	AIS security configuration management and control requirements.<p>

<p>

		(g)	AIS-related security incident reporting requirements and procedures.<p>

<p>

	(9)	Specialized training is required for all individuals given access to an application, including
members of the public.  It should vary depending on the type of access allowed and the risk
that access represents to the security of the application and information in it.  This training
will be in addition to that required for access to a support system.  Such training may vary
from a notification at the time of access (e.g., for members of the public using an information
retrieval application) to formal training (e.g., for an employee that works with a high-risk
application).<p>

<p>

	(10)	All personnel who design, develop, operate, or maintain sensitive AIS will be provided
security training appropriate to the level of risk they present to Customs AIS.  The training
shall address the types of security and internal control techniques that ought to be incorporated
into AIS development, operation, and maintenance.<p>

<p>

	(11)	AIS Security Administration should be consulted for guidance on achieving training
objectives.<p>

<p>

<b>3.7	SECURITY OVERSIGHT</b><p>

<p>

	The ADP Steering Committee, Security Subcommittee, is the oversight authority for Customs AIS
Security Program.  (See also: Section 2.2(2))<p>

<p>

	The AIS Security Officer conducts ongoing day-to-day operational policy-related security oversight
activities and ensures that periodic AIS security reviews are conducted.<p>

<p>

	(1)	The AIS Security Officer must develop and maintain, with the assistance of AIS Security
Administration, IRM, and SPD managers, a list of AISs requiring accreditation.  This list
must be annually verified and should include the recommended accreditation priority and AA
identity for each AIS.<p>

<p>

	(2)	Given the global nature of Customs AIS resources, the appointment of DSOs provide local
oversight and help to ensure adherence to AIS security policy.  They provide points-of-contact
for accomplishing AIS security-related activities.<p>

	<p>

	(3)	Customs Office of Information and Technology (OIT) is a sign-off to AIS-related acquisitions
and will enforce AIS security as part of the procurement process.<p>

<p>

		The AIS Security Officer reviews and authorizes all security-related acquisitions for sensitive
AISs to ensure that the appropriate AIS security requirements are included in the
specifications for the operation of an AIS installation facility, equipment, application system,
or the acquisition of AIS hardware, software, or related services.<p>

<p>

	(4)	The Contracting Officer Technical Representative (COTR) has contract oversight and will
ensure that the contractor-related AIS security requirements are followed throughout the
contract life-cycle.<p>

<p>

	(5)	The AIS security policy program is implemented through the following actions:<p>

<p>

		(i)	appointment of DSOs;<p>

<p>

		(ii)	acquisition reviews;<p>

<p>

		(iii)	review and approval of security requirements to support AIS development;<p>

<p>

		(iv)	preparation, approval, and implementation of certification requirements;<p>

<p>

		(v)	preparation and approval of accreditation documentation;<p>

<p>

		(vi)	security training reviews;<p>

<p>

		(vii)	security controls and auditing; and<p>

<p>

		(viii)	security incident reporting.<p>

CHAPTER 4<p>

<i>MINIMUM SECURITY REQUIREMENTS</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

	The AIS security goal is to develop a functionally secure, efficient, cost-effective environment based
on an assessment of security risks and safeguards.  All AISs processing, storing, or transmitting
sensitive information must meet the requirements of this policy through automated or manual means. 
More stringent requirements may be imposed based on a risk analysis.<p>

<p>

	This section documents the minimum security requirements for Customs AISs processing sensitive
data with respect to: Facility, Personnel, Automated, and Telecommunications security.<p>

<p>

<b>4.1	FACILITY SECURITY</b><p>

<p>

	(1) 	The Security Programs Division (SPD), Security Management Branch, prescribes policies,
procedures, and standards for the Customs facility security program.<p>

<p>

	(2)	Facility security addresses the requirements to provide adequate physical and environmental
controls based on the level of risk to the AISs supported in a facility, as identified by a risk
analysis.  The security controls must not be less than the minimum requirements discussed
in this section, unless a written waiver has been granted by the Accrediting Authorities (AAs).<p>

<p>

	(3)	For the purposes of this policy, an AIS facility includes physical space housing AIS equipment
such as terminals, microcomputers, mainframe systems, communications equipment, or
supporting environmental control utilities.  Facilities also include data storage and AIS
documentation libraries (e.g., off-site back-up storage facilities).<p>

<p>
<b>4.1.1	Physical</b><p>

<p>

	(1)	Physical security is concerned with the measures designed to prevent unauthorized physical
access to equipment, facilities, material, information, and documents, and to safeguard them
against espionage, sabotage, damage, tampering, theft, and other covert or overt acts.  AIShardware, software, documentation, and all sensitive information handled by the AIS will be
protected to prevent unauthorized disclosure, modification, or destruction.  AIS hardware,
software, or documentation must be protected if access to such resources may reveal
information that can be used to eliminate, bypass, or otherwise render ineffective the security
safeguards (countermeasures) used to protect sensitive information.<p>

<p>

	(2)	Sensitive Customs information, while operational, must be processed, stored, or transmitted
in physical spaces (i.e., buildings, communications facilities, etc.) which are under exclusive
Customs control, including MOUs (Memorandum of Understanding) and contractual
agreements.  When not in operation, or under the direct control of an authorized person,
Customs AISs and information must be protected by control systems and measures consistent
with Customs facility security program. <p>

<p>

		Prior to conducting sensitive AIS operations at any location, AIS security planning must
consider the facility security program as part of the accreditation process.<p>

<p>

	(3)	For all types of facilities where sensitive information is stored, processed, or transmitted,
physical access will be restricted to those individuals who are authorized according to the
personnel security requirements and who are necessary to complete assigned job functions and
related duties.  (See also: Section 4.2)<p>

<p>

		All other personnel granted facility access must be properly escorted and restricted to those
areas necessary to complete their tasks.  Sensitive Customs information must be protected
from unauthorized disclosure to such persons.<p>

<p>

<b>4.1.2	Environmental</b><p>

<p>

	(1)	Environmental controls address the requirements to provide appropriate temperature and
humidity controls, fire protection, power, and natural disaster protection necessary to ensure
the continuity of operations for AIS facilities and equipment.<p>

<p>

	(2)	Areas that support desktop AIS equipment generally require environmental controls specified
for human safety and comfort.  Additional physical, electrical, temperature, and humidity
controls may be needed to ensure reliable AIS operations in some cases.<p>

<p>

	(3)	Facilities supporting large-scale AIS operations, such as mainframe computers and
telecommunication facilities, may require additional environmental controls as determined by
operational needs and risk analysis.  The following additional controls should be considered:<p>

<p>

		(a)	Fire prevention, detection, suppression, and protection measures.<p>

<p>

		(b)	Water hazard detection, prevention, and corrective measures.<p>

<p>

		(c)	Electric power supply protection.<p>

<p>

		(d)	Temperature and humidity controls.<p>

<p>

		(e)	Protective or control measures from the effects of earthquakes, lightning,
windstorms, and other natural disasters.<p>

<p>

		(f)	Protective or control measures from the effects of industrial, environmental, or other
physical conditions which might seriously impact normal AIS operations.<p>

<p>

		(g)	Housekeeping protection from dirt, dust, and other contaminants.<p>

<p>

		(h)	Personnel safety features.<p>

<p>

<b>4.2	PERSONNEL SECURITY</b><p>

<p>

	(1)	The Security Programs Division (SPD) sets policy and provides procedures and guidance in
support of Customs personnel security program.  Prior to conducting AIS operations, and as
part of the accreditation process, AIS security planning must consider the personnel security
program.<p>

<p>

	(2)	<u>All personnel</u> entrusted with the management, operation, maintenance, or use of a Customs
AIS processing, storing, or transmitting sensitive information require appropriate personnel
security approval.  [USCS 51000-05]<p>

<p>

	(3)	<u>Customs personnel</u> and <u>Non-Customs contractor personnel</u> entrusted with the management,
operation, maintenance, or use of sensitive Customs AISs require an appropriate authorization
and must have a completed Background Investigation (BI).  [USCS 1460-010]<p>

<p>

	(4)	<u>Non-Customs government personnel</u> entrusted with the management, operation, maintenance,
or use of sensitive Customs AISs require an appropriate authorization and background
investigation.<p>

<p>

	(5)	<u>Non-Customs personnel (members of the trade community)</u>, who use Customs AISs must be
authorized in writing by the AIS Security Officer, Process Owner, or some other formalized
process that assures appropriate authorization.<p>

<p>

	(6)	<u>Non-Customs AIS technical support personnel</u> who are required to perform maintenance on
Customs AISs within Customs-controlled facilities may be approved for unescorted access
based on an appropriate authorization and a completed BI.<p>

<p>

	(7)	AIS security training must be provided to all personnel who manage, operate, develop or use
AISs.  (See also: Section 3.6)<p>

<p>

<b>4.3	AUTOMATED SECURITY</b><p>

<p>

	This section establishes near-term requirements and long-term goals to improve the security of
Customs AISs through increasing reliance on automated security features.  The<i> minimum security
requirements</i> addressed in this section are feasible in the current Customs AIS environment.  As
technology evolves, the <i>desirable security features</i> identified in this section should be assessed during
AIS planning and development.<p>

<p>

<b>4.3.1	Minimum Security Requirements</b><p>

<p>

<u>	National Policy on Controlled Access Protection</u>.  The White House,  National Telecommunications
and Information Systems Security Committee, 07/15/87, directs that by Federal agencies must provide
automated Controlled Access Protection (C2 level) for all sensitive or classified information processed
or maintained by AIS, when all users do not have the same authorization to use the sensitive
information.  [NTISSP 200]<p>

<p>

	(1)	AISs used for the processing of sensitive information must have the security functionality of
the C2 level of trust, as defined in the Department of Defense (DoD), <u>Trusted Computer
System Evaluation Criteria</u> (TCSEC).  [5200.28-STD]<p>

<p>

		(a)	In cases where C2 functional security requirements are time consuming, technically
unsound, or adversely affect operations to an unacceptable degree, other safeguards
may be substituted if they maintain the level of system security commensurate with
the sensitivity of the data.  The AIS Security Officer must approve exceptions
(written waiver) to C2 functional security requirements for sensitive AIS.<p>

			(See also: Appendix C)<p>

<p>

		(b)	The National Computer Security Center (NCSC) Technical Guide, <u>Trusted Network
Interpretation of the Trusted Computer System Evaluation Criteria</u> (TNI-TCSEC,
commonly known as the "red book"), provides guidance on achieving C2
functionality in networks.  [NCSC-TG-005]<p>

<p>

	(2)	The design of AISs that process, store, or transmit sensitive information must include at a
minimum, the automated security features discussed in this section.  Security safeguards will
be in place to ensure each person having access to a sensitive AIS is individually accountable
for their actions on the system.  <p>

<p>

		(a)	<u>User Identification</u>.  User access will be controlled and limited based on positive user
identification and authentication mechanisms that support the minimum requirements
of access control, least privilege, and system integrity.<p>

<p>

		(b)	<u>Authentication</u>.  For AIS requiring authentication controls, the AIS will ensure that
each user is authenticated prior to AIS access.  The preferred method for
authenticating users is a password system where authentication is done each time the
password is used.  More sophisticated authentication techniques, such as "smart
cards," MISSI (Multilevel Information Systems Security Initiative) technology
(Fortezza, Capstone, etc.), biological recognition systems (retina scanners, hand
print, voice recognition, etc.), must be cost-justified through the risk analysis
process.  [MISSI]<p>

<p>

		(c)	<u>Audit Records</u>.  AIS transactions are subject to recording and routine review for
inappropriate or illegal activity.  Audit trail records should be sufficient in detail to
facilitate reconstruction of events if compromise or malfunction occurs, or is
suspected, and should be reviewed as specified in the AIS security plan.  The audit
trail records should contain at least the following information.<p>

<p>

			(i)	Identifier of each user and device accessing or attempting to access an AIS.<p>

<p>

			(ii)	The time and date of the access and of the logoff.<p>

<p>

			(iii)	Identify activities that might modify, bypass, or negate AIS security
safeguards.<p>

<p>

			(iv)	Log of security-relevant actions associated with processing.<p>

<p>

		(d)	<u>Object Reuse</u>.  Sensitive AIS must clear memory and/or data storage areas (RAM,
DASD, tape, R/W Optical, etc.) prior to reallocation of the area to a different user. 
This prevents one user from obtaining residual data of another user.<p>

<p>

		(e)	<u>Access Control</u>.  Sensitive AIS may implement additional discretionary access
control (DAC) measures such as file passwords, access control lists, disk encryption,
or other techniques, as defined in the approved system security plan.<p>

<p>

	(3)	For sensitive AIS the following <b>Warning Banner</b> (exactly as worded in Figure 3) must be
displayed to users at logon time, followed by a pause requiring manual intervention to
continue.  This addresses the concern that users are informed that all Customs AISs are
subject to monitoring and that by using the AIS they consent to such monitoring.<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

	(4)	Automatic<u> interactive-session timeout</u> (logoff) will be provided for all general support and/or
sensitive AISs.  This will lockout a user session after an interval of  inactivity, not to exceed
the time interval and restart requirements specified in the AIS security plan. System logon
will be required to re-access the AIS.<p>

<p>

	(5)	Interconnections between sensitive Customs AISs and non-Customs AISs must be established
through controlled interfaces and will be accredited at the highest security level of information
on the network.  Consult the AIS Security Officer for guidance on establishing controlled
interfaces.<p>

<p>

		Controlled interface functions are a combination of gateway and guard functions.<p>

<p>

		Gateways provide secure points of interconnection between networks, connected
peripheral devices, remote terminals, or remote hosts, and provide a reliable
exchange of information to allow secure interconnections between components.<p>

<p>

		Automated guard processors and security filters (e.g., firewall) are software,
combined hardware/software techniques, or specialized hardware that filter
information in a data stream based on associated security information and/or data
content.<p>

<p>

<b>4.3.2	Security Assurances</b><p>

<p>

	(1)	AISs will be examined when received from the vendor(s) and before being placed into
operation.  The following areas must be considered:<p>

<p>

		(a)	<u>Hardware</u>.  An examination will result in assurance that the equipment appears to be
in good working order and has no components that might be detrimental to the secure
operation of the resource when placed under Customs control and cognizance. 
Subsequent changes and developments which affect security may require additional
examination.<p>

<p>

		(b)	<u>In-house Developed Software</u> or <u>Government-Off-The-Shelf</u> (GOTS).  New or
significantly changed software developed by or specifically for Customs or the
Government will be subject to testing and review at all stages of the development, as
required by the SDLC.  [USCS 5500-4]<p>

<p>

		(c)	<u>Commercial-Off-The-Shelf Software (COTS)</u>.  Commercially procured software will
be examined to assure that the software does not contain features which might be
detrimental to AIS security.  Security-related software will be examined by Customs
authorized personnel to assure that the security features function as specified.<p>

<p>

	(2)	Customs endorses the use of products from the Evaluated Products List (EPL) of the National
Computer Security Center (NCSC).  EPL products are computer systems, software, or
components that protect information while it is being stored or processed.  <p>

<p>

		When certified as properly implemented through the process discussed in Section 3.4, these
products will be accepted as meeting the security requirements for the portion of the sensitive
AIS where they are used.<p>

<p>

	(3)	When EPL products are not specified or used for sensitive AIS, the AIS security plan must
include a functionality statement and implementation schedule of how the C2 security level
functionality will be achieved. The statement will become part of the accreditation package
and must address the following EPL evaluation areas.<p>

<p>

		(a)	<u>Confidence in software source</u>.  In acquiring software resources to be used as part
of a sensitive AIS, consideration will be given to the level of confidence placed in the
vendor to provide a quality product, to support the security features of the product,
and to help in the correction of any flaws.<p>

<p>

		(b)	<u>Security performance testing</u>.  Security performance testing includes both
certification testing that is performed before the AIS is accredited and ongoing
performance testing that is performed on a regular basis.<p>

<p>

		(c)	<u>Security penetration testing</u>.  In addition to testing the performance of the AIS,  there
will be testing to attempt to penetrate the security safeguards of the system.  The test
procedures will be documented in the test plan for certification and in the ongoing
test plan.<p>

<p>

		(d)	<u>Life-cycle assurance</u>.  The development of hardware, firmware, and software will
be conducted under life-cycle control and management.<p>

<p>

	(4)	A configuration management (CM) system is required to preserve the AIS accreditation
integrity and maintain control of changes to any of the AIS features that may alter the
accreditation status.  Examples of CM activities include security-related hardware changes,
or changes to any line of source or object code of the security-related software.  The CM
system will record by whom, for what reason, and when the change is made.  Documentation
of the security-related hardware and/or software design will be maintained and kept current. 
[NCSC-TG-006]<p>

<p>

<b>4.3.3	Desirable Security Features</b><p>

<p>

	(1)	AIS planning must consider technological advances in security features. The planning process
will be documented and approved via the AIS security plan.<p>

<p>

	(2)	Interoperability with external systems must consider support for digital signature standards
(DSS), nonrepudiation in messaging systems, and data encryption issues as they relate to
interagency communications or interoperability.<p>

<p>

	(3)	Continuous On-Line Automated Monitoring and Warning functions for sensitive AIS can
provide real-time use monitoring (audit) and real-time warning to the DSOs of suspected AIS
misuse.<p>

<p>

	(4)	Network Access Control Features should address the following areas, to achieve C2 level
security of communications paths:<p>

<p>

		(a)	<u>Identification and Authentication Forwarding</u>.  Reliable forwarding of the
identification should be used between AISs when users are connecting through a
network.  When identification forwarding cannot be verified, a request for access
from a remote AIS should require authentication before permitting access to the
system.<p>

<p>

		(b)	<u>Protection of Authenticator Data</u>.  In forwarding the authenticator information and
any tables (e.g., password tables) associated with it, the data should be protected
from access by unauthorized users (e.g., by encryption) to ensure its integrity.<p>

<p>

<b>4.4	ADMINISTRATIVE SECURITY</b><p>

<p>

	Administrative security consists of the controls and operational procedures used with or in place of
computer security features.  Administrative security controls must be documented in the AIS security
plan, Security Features User's Guide (SFUG), and Trusted Facility Manual (TFM) for each accredited
AIS.<p>

<p>

<b>4.4.1	Accountability and Access Control Criteria</b><p>

<p>

	The DSO will establish access control criteria and administrative procedures to limit access to
information processed, stored, or transmitted by sensitive Customs AISs. These activities are
documented in the AIS security planning process, approved by the AIS Security Officer, and
accredited as discussed in Section 3.4 and should include at least the following:<p>

<p>

	(1)	The access control criteria identify who is authorized AIS access and who is responsible for
approving such access.<p>

<p>

		(a)	The individual who requires access must possess the appropriate security
authorization and have a valid need-to-know.<p>

<p>

		(b)	The AIS security features must have the capability to restrict the user's access to only
that information which is necessary for scope of the job or assignment.<p>

<p>

	(2)	Customs and contractor personnel who access sensitive Customs AISs must have a completed
BI (discussed in Section 4.2).  Personnel must only be granted access to AISs for which they
have a valid need-to-know based on their operational needs (i.e., principle of least-privilege.).<p>

<p>

	(3)	Customs AISs are generally designed for the use of Customs personnel, but by special
arrangements Customs may authorize certain types of access to other Federal, State, local,
or international law enforcement agencies, other government agencies, private contractors,
and trade community members in support of particular operations.<p>

<p>

		Written requests for special access must be submitted to the appropriate Customs Security
Administrator who coordinates the AIS security process for the sponsoring organization.  The
Security Administrator will ensure that such requests meet the following criteria.<p>

<p>

		(a)	The individual for whom access is requested must have appropriate security
authorization for the information or functions which are being requested.<p>

<p>

		(b)	The individual must have a valid need-to-know (i.e., access is an operational
necessity) documented in the application by the sponsoring organization. <p>

<p>

		(c)	The AIS security features have the capability to restrict the user's access to only 
information and/or functions appropriate for the authorized activities.<p>

<p>

		(d)	If the AIS access is for members trade community, it must be based on limits as
specified in formal agreements with Customs.<p>

<p>

	(4)	Some Customs AISs are designed for the support of the law enforcement, trade communities
(e.g., TECS, ACS), and other agencies.  Access requirements, controls, and procedures are
defined for each system and documented in its System Security Plan.  Reference the
appropriate AIS support documentation for details related to such systems.<p>

<p>

<b>4.4.2	Software and Data Security</b><p>

<p>

	(1)	All executable software used on sensitive Customs AISs should be obtained through
authorized procurement channels.  Software acquired by any other means (e.g., public
domain software, bulletin board services, personally owned software [developed or
purchased]) is <u>restricted</u> and must be approved in writing by AIS Security Administration as
an operational necessity.<p>

<p>

	(2)	Safeguards must be in place to detect and minimize inadvertent or malicious modification or
destruction, or attempts to do so, of a sensitive AIS's application software, operating system
software, and critical data files.  The safeguards should achieve the integrity objectives andbe documented in the AIS security plan.<p>

<p>

		(a)	Executable software authorized to run on a sensitive Customs AIS will be identified
in the AIS security plan.<p>

<p>

		(b)	The level of protection must be commensurate with the sensitivity of the information
processed.<p>

<p>

		(c)	At a minimum, essential data should be backed-up and the media stored physically
separate from the AIS (preferably at an off-site location).  Appropriate AIS security
controls must be in place to assure viability of such back-ups.<p>

<p>

	(3)	Virus and malicious code (software) prevention and control measures, commensurate with
the identified level of risk, will be employed to protect the integrity of the software and data
for applicable AIS.<p>

<p>

		(a)	The AIS Security Officer manages the virus protection program for Customs and
should be contacted for approved prevention and control measures (e.g., behavior
detection, scanning, cleanup techniques and/or procedures) if there is a suspected or
known malicious code (software) threat.<p>

<p>

		(b)	Identified incidents of malicious code (software), or virus infections should be
reported promptly to the DSO, AIS Security Officer, and/or IA, as appropriate.<p>

<p>

		(c)	Prior to introduction into or use by Customs, AIS data recording media will be
scanned for malicious code (software), including:<p>

<p>

			(i)	all Customs-seized AIS machines and media,<p>

<p>

			(ii)	all removable AIS magnetic or optical recording media (e.g., floppy disks,
CD-ROM, etc.), regardless of source, and<p>

<p>

			(iii)	all fixed AIS storage devices (e.g., hard drives, R/W Optical, etc.), on a
periodic basis.<p>

<p>

	(4)	Use of copyrighted software will comply with copyright laws and license agreements.<p>

<p>

	(5)	Introduction of data from sources and/or in formats other than those specified in the
appropriate AIS security plan (e.g., financial data received from financial institutions) must
be approved in writing by the AIS Security Officer as an operational necessity.  These
activities must be in conformance with the accreditation of the AIS and FOIA/PA (Freedom
of Information Act/Privacy Act) requirements.<p>

<p>

	(6)	To maintain software integrity, proper configuration management (CM) and controls must
be used to monitor software installation and updates.  This process will provide a historical
record of software changes; helping to ensure that the software functions as expected, is
maintained, and that only authorized software is permitted on the AIS.<p>

<p>

<b>4.4.3	Technical Support and Maintenance</b><p>

<p>

	(1)	Technical support and maintenance activities for Customs AIS must ensure that:<p>

<p>

		(a)	Hardware and software maintenance activities do not affect the integrity of existing
safeguards or permit the introduction of security exposures into an AIS (e.g.,
computer viruses, Trojan Horses, logic bombs, malicious code, etc.).<p>

<p>

		(b)	Sensitive Customs AIS electronic storage and memory devices are not released from
Customs control without proper clearing procedures to remove residual data. 
Exceptions (waivers) must be approved by the AIS Security Officer.<p>

<p>

		(c)	Automated (i.e., computer-connected) dial-up diagnostic maintenance of sensitive
Customs AIS via remote communications between vendors and Customs AIS
facilities is prohibited unless authorized by Principal Accrediting Authority (PAA)
in the AIS Accreditation.  The Accreditation should reference an approved contract,
MOU, or other agreement when such a service is included.<p>

<p>

	(2)	AIS technical support and maintenance work performed in Customs facilities (on-site) must
be supervised by or under the control of Customs personnel knowledgeable in appropriate
AIS operations.<p>

<p>

		On-site AIS technical support and maintenance personnel must meet the personnel security
requirements.  (See also: Section 4.2)<p>

<p>

	(3)	AIS technical support and maintenance must be considered in AIS certification.<p>

<p>

<b>4.4.4	Portable Computer Equipment</b><p>

<p>

	Customs AIS portable computers, related types of equipment, and storage media must be restricted
to the exclusive authorized Customs use.  Unattended Customs AIS equipment and storage media must
be secured in an appropriate manner commensurate with the sensitivity of the data, equipment, and
authorized use.  To the extent possible, such equipment and storage media must be kept in the
possession of the individual to whom it is issued or charged out.<p>

<p>

<b>4.4.5	Classification and Controls</b><p>

<p>

	(1)	Customs AISs that store, process, or transmit sensitive information must be adequately
safeguarded to ensure that access to sensitive Customs information is restricted to Customs
authorized personnel, and operated only by Customs authorized persons in facilities (physical
space) under Customs authorization or control.<p>

<p>

	(2)	When not under the control of Customs authorized personnel, Customs sensitive AISs and
related equipment must, at a minimum, be secured as follows:<p>

<p>

		(a)	Microcomputers, terminals, displays, and related AIS equipment which might
provide unauthorized access to sensitive data or resources, must be turned off or
otherwise made unaccessible.  Additional appropriate security control measures may
be necessary in some situations.  Exceptions (waivers) must be part of the
accreditation statement or separately approved by the AIS Security Officer.<p>

<p>

		(b)	Diskettes, tapes, removable storage devices, printer ribbons or laser cartridges, and
other AIS media which contain sensitive information must be labeled and secured
commensurate with the highest level of information stored on the device. 
Destruction of such media must be appropriate to the level of sensitivity of the data
stored on it.<p>

<p>

<b>4.4.6	External Labels</b><p>

<p>

	In an AIS environment where no classified information is processed or stored, special security labels
with the word "Unclassified," are not required to identify that the storage media contains unclassified
information.  However, for some categories of SBU data, special identification labels are required. 
Reference <u>Safeguarding Classified Information Handbook</u>, for the appropriate procedures.<p>

	[USCS HB 1400-03]<p>

<p>

	The term "unclassified" is not a security classification, but is a category of data within which are
several subcategories, including sensitive but unclassified (SBU) and public  information.<p>

<p>

	Sensitive but unclassified (SBU) information is restricted to authorized persons with a need-to-know
and requires appropriate controls as explained in this manual.<p>

<p>

<b>4.4.7	Customs Work Performed at non-Customs Locations</b><p>

<p>

	When operational necessity requires that Customs authorized work be performed at non-Customs
controlled locations (e.g., field assignment, work at home, etc.), the following policies apply and
associated risks must be appropriately managed.<p>

<p>

	(1)	Customs management must determine that required security controls and documentation are
in place for authorized AIS operations and that SBU information is properly protected. 
Although current technology makes it feasible to address these requirements, providing
adequate safeguards and conducting related activities for individual AISs may not always be
cost-effective.<p>

<p>

		AIS security control documentation includes the following.<p>
<p>

		(a)	System security plan.<p>

<p>

		(b)	Risk analysis.<p>

<p>

		(c)	Contingency plan.<p>

<p>

		(d)	Security procedures.<p>

<p>

		(e)	Certification.<p>

<p>

		(f)	Accreditation.<p>

<p>

	(2)	AIS equipment (whether or not Customs owned) used to process SBU at non-Customs
controlled locations must meet the security requirements for sensitive Customs AISs as
presented in this policy manual.<p>

<p>

	(3)	Authorized use of Customs owned computer equipment at home is permitted when such usage
is consistent with the policy as presented in this manual.<p>

<p>

<b>4.4.8	Use of Non-Customs Owned AISs</b><p>

<p>

	(1)	It is <u>Treasury policy</u> that, "Personally-owned computers and software will not be used to
process sensitive but unclassified (SBU) information without the approval of the Principal
Accrediting Authority." (Reference: TD P 71-10, Chap. VI, Section 4.D.1).<p>

<p>

		<u>Treasury policy</u> defines, <u>Personally-owned computers or software</u> as, "Computers or software
purchased with non-government funds, except those turned over for exclusive U.S.
Government control and use and where the hard-drive will be properly erased when the
system is no longer in U.S. Government use."<p>

		(Reference: TD P 71-10, Appendix B.  Definition updated 11/24/95).<p>

<p>

	(2)	It is <u>Customs policy</u> that, non-Customs owned computers or software will not be used to
process, access, or store Sensitive But Unclassified (SBU) information without the written
approval of the Principal Accrediting Authority (PAA).<p>

<p>

		(a)	Policy exceptions (waivers) must be approved by the PAA who assumes the
associated risks for authorizing the use.<p>

<p>

		(b)	The protection requirements for data on Customs owned equipment apply equally to
the protection of data when used on non-Customs owned equipment.<p>

<p>

<b>4.5	TELECOMMUNICATIONS SECURITY</b><p>

<p>

	The Federal government is developing appropriate security policies and infrastructures that deal with
the rapidly changing field of telecommunications.   Under the auspices of the White House Office of
Science and Technology Policy, the National Information Infrastructure Task Force (NITF) is a
driving force in this effort.  The NITF includes high-level representatives of Federal agencies that play
a major role in the development and application of information and telecommunications technologies. 
[GAO94285; GAO9523]<p>

<p>

<b>4.5.1	Information System Standards<p>

</b><p>

	It is the policy of the Department of the Treasury to comply with all mandatory Federal Information
Processing Standards (FIPS), mandatory Federal Telecommunications Standards (FED-STDs),
voluntary FIPS, FED-STDs, American National Standards Institute (ANSI), or other information
system standards and guidelines to the extent they are determined to be cost-effective and appropriate
for the intended use.  A waiver process is defined in Treasury <u>Information Systems Standard
Program</u>, 8/23/89.  [TD 87-01; COHEN]<p>

<p>

<b>4.5.2	Network Connections</b><p>

<p>

	Telecommunication connections between Customs AISs and non-Customs AISs or networks, public
or private, may be authorized by the AIS Security Officer under the following conditions:<p>

<p>

	(1)	Non-sensitive Customs AIS, when operated in a dedicated security mode, must be locally
documented, including the administrative approval of the AIS Security Officer and a technical
description of the connection(s).  Example: microcomputers, PCs, etc., that do not contain
or process SBU data and are not connected physically or logically to any other Customs AIS
or network (Treasury or Customs).<p>

<p>

	(2)	All other Customs AIS connections to non-Customs networks must be approved by the AIS
Security Officer, on a case-by-case basis.  The AIS Security Officer will ensure that the
appropriate safeguards are in place and that documentation, such as license agreements,
memoranda of understanding (MOU), interconnection agreements, etc., are executed on
behalf of Customs, as part of the approval process.  Example: Customs AIS access to the
National Information Infrastructure (NII) or commercial information databases (e.g.,
LEXIS/NEXIS, Dun &amp; Bradstreet Business records, D&amp;B Worldbase, etc.).<p>

<p>

<b>4.5.3</b>	<b>Internet Services</b><p>

<p>

	<u>Treasury policy</u>:  Issued April 28, 1995, by the Deputy Assistant Secretary for Information Systems. 
[TD INTERNET]<p>

<p>

	Treasury operating policy requires that any access to the Internet services from Treasury AIS
(including Customs) be provided via protected Internet gateways (access control mechanisms) that
have been approved by the Office of Telecommunications Management (OTM).<p>

<p>

	Exceptions must be approved in writing by the Director, OTM.<p>

<p>

	<u>Customs policy</u>:<p>

<p>

	In addition to Treasury policy, Customs owned or controlled AISs may only access the Internet via
Customs approved gateways.<p>

<p>

	This limitation means that Customs owned, controlled, or authorized computer equipment, regardless
of its location or means of connection to any network or system, may not be used to access the
Internet, directly or indirectly (e.g., via service providers such as CompuServe, AOL, etc.) unless
such connection is via a Customs approved Internet gateway (i.e., firewall).  While the configuration
of some networks make it technically possible to access the Internet without going through an
approved gateway, such access is not authorized.<p>

<p>

	Exceptions to this policy must be approved in writing by the Director, OTM, U.S. Treasury
Department.  [TD INTERNET]<p>

<p>

<b>4.5.4	Electronic Mail (E-Mail)</b><p>

<p>

	Government projects and commercial products for secure electronic mail (E-Mail) systems are
undergoing rapid development and will be available in the coming years.  Until such products are
implemented, users are cautioned NOT to send sensitive information via E-Mail.<p>

<p>

<b>4.5.5	Facsimile (FAX)</b><p>

<p>

	Sensitive information will only be transmitted via a secure facsimile system (e.g., encrypted or via
a protected network).  Commercial-off-the-shelf (COTS) software and hardware are available to
provide the necessary safeguards and should be employed as appropriate.<p>

<p>

<b>4.5.6	PBX and Voice Mail Systems</b><p>

<p>

	Private Branch Exchanges (PBX) and Voice mail systems do not currently meet standard security
specifications and are not generally considered secure systems.  They are susceptible to unauthorized
access and messages left on a voice mail system should contain the least amount of information
possible.  Do not leave any information on a voice mail system that, if compromised, could damage
Customs mission.  Report suspected unauthorized access attempts to AIS Security Administration.<p>

<p>

	PBX systems must be physically secured and system security features configured (to the extent
possible for a specific system) to prevent unauthorized access to dial-tones, modems, or other AIS
access.  (See also: Appendix D. Good Security Practices).<p>

<p>

	Voice Mail  and Voice Interactive Response systems must be configured (to the extent possible) to
prevent unauthorized access to dial-tones, modems, or other AIS access.<p>

	(See also: Appendix B. Good Security Practices).<p>

<p>

<b>4.5.7	Communications Security (COMSEC)</b><p>

<p>

	COMSEC is intended is to deny unauthorized persons information derived from telecommunications
of the United States Government related to national security and to ensure the authenticity of such
communications.  COMSEC issues should be directed to the Communications Security Management
Branch, Orlando, FL.  [USCS 4300-09]<p>

CHAPTER 5<p>

<i>SECURITY INCIDENTS AND VIOLATIONS</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

Definition: <u>AIS Security Incident</u>.  An AIS security incident is any event and/or condition that has the potential
to impact the security and/or accreditation of an AIS and may result from intentional or unintentional actions.<p>

<p>

Examples include: unauthorized attempts to gain access to information; introduction of malicious code or
viruses into Customs AISs; loss or theft of computer media; or the failure of an AIS security function to
perform as designed.  For reporting purposes, malicious code (software) incidents include any detection of
malicious code, whether detected on magnetic media prior to the media's entry into a Customs AIS or after
infection of the AIS, and any actual execution of malicious code.<p>

<p>

Definition: <u>AIS Security Violation</u>.  An event which may result in disclosure of sensitive or classified
information to unauthorized individuals, or that results in unauthorized modification or destruction of system
data, loss of computer system processing capability, or loss or theft of any computer system resources.<p>

(See also:  TD P 71-10, Chapter III.4)<p>

<p>

(1)	Customs employees, contractors, and/or users should report security-related incidents and/or
violations through the appropriate supervisory channels to the DSOs, Security Administrators, AIS
Security Officer, or Internal Affairs (IA), as appropriate.  The AIS Security Officer will maintain the
appropriate records and address the impact of the security incidents on the accreditation status of
related AISs.  Additional security safeguards to reduce generic risks may be recommended, as
required.<p>

<p>

(2)	Additionally, malicious code (software) and virus infection incidents on Customs AIS (i.e.,
mainframes, microcomputers, networks, PCS, floppy disks or other media, etc.) should be promptly
reported to the AIS Security Officer.<p>

<p>

(3)	Customs employees may be subject to disciplinary action for failure to comply with Customs AIS
security policy, whether or not the failure results in criminal prosecution.<p>

<p>

	AIS security-related violations are addressed in the Treasury <u>Standards of Ethical Conduct for
Employees of the Executive Branch</u> and the Customs <u>Conduct and Employee Responsibilities</u>.  Such
violations should be reported through the appropriate supervisory channels to the AIS Security Officer
and/or IA, as appropriate.  [TD ETHICS; USCS 51000-05]<p>

<p>

(4)	Non-Customs employees who fail to comply with this policy are subject to having their access to
Customs AISs and facilities terminated, whether or not the failure results in criminal prosecution.<p>

<p>

(5)	Any person who improperly discloses sensitive or classified information is subject to criminal and civil
penalties and sanctions under a variety of laws (e.g., Privacy Act ...).<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<center>(This Page Intentionally Left Blank)</center>
<p>

GLOSSARY<p>

<IMG SRC="images/bar1.gif">
<p>

<p>

Editor's note:	Computer terms have evolved and become more clearly defined during the past decade.  The 
referenced definitions are from recent publications of established sources, and are generally
preferred.<p>

<p>

Source references:<p>

<p>

		<u>Glossary of Computer Security Terminology</u>, developed by the National Security Telecommunications and
Information Systems Security Committee (NSTISSC) and published by NIST as NISTIR 4659. 
Available from NTIS as PB92-112259.<p>

<p>

		<u>Glossary for Computer Security Terms</u>.  National Technical Information Service (NTIS), FIPS PUB 39,
Springfield, VA., 02/15/76.  <b>Withdrawn</b> 4/93.  Replacement is FIPS 11-3.<p>

<p>

		<u>Introduction to Certification and Accreditation</u>.  National Computer Security Center (NCSC), NCSC-TG-029,
Ver. 1, NSA, Ft. George G. Meade, MD., January 1994.<p>

<p>

<u>Treasury Security Manual</u>, TD P 71-10, Appendix B, 1993.<p>

<p>

<p>

<center><b>A</b></center>
<p>

<p>

<b>Access</b><p>

	A specific type of interaction between a subject and an object that results in the flow of information
from one to the other.  The capability and opportunity to gain knowledge of, or to alter information
or materials including the ability and means to communicate with (i.e., input or receive output), or
otherwise make use of any information, resource, or component in a computer system.<p>

<p>

<b>Access Control</b><p>

	The process of limiting access to the resources of a system to only authorized persons, programs,
processes, or other systems.  Synonymous with controlled access and limited access.  Requires that
access to information resources be controlled by or for the target system.  In the context of network
security, access control is the ability to limit and control the access to host systems and applications
via communications links.  To achieve this control, each entity trying to gain access must first be
identified, or authenticated, so that access rights can be tailored to the individual. <p>

<p>

<b>Accreditation/Approval</b><p>

	The official management authorization for operation of an AIS.  It provides a formal declaration by
an Accrediting Authority that a computer system is approved to operate in a particular security mode
using a prescribed set of safeguards.  Accreditation is based on the certification process as well as
other management considerations.  An accreditation statement affixes security responsibility with the
Accrediting Authority and shows that proper care has been taken for security.<p>

<p>

<b>Accrediting Authority (AA)</b><p>

	The official who has the authority to decide on accepting the security safeguards prescribed for a
computer system or that official who may be responsible for issuing an accreditation statement that
records the decision to accept those safeguards.<p>

	See also:  <b>Designated Approving Authority (DAA), Principal Accrediting Authority</b>.<p>

<p>

<b>Adequate Security</b><p>

	Security commensurate with the risk and magnitude of the harm resulting from the loss, misuse, or
unauthorized access to or modification of information.  This includes assuring that systems and
applications used by the agency operate effectively and provide appropriate confidentiality, integrity,
and availability, through the use of cost-effective management, personnel, operational and technical
controls. [OMB A-130, AIII]<p>

<p>

<b>Administrative Systems</b><p>

	An automated Customs system to provide support in areas of accounting, personnel, payroll, logistics
and other support services.<p>

<p>

<b>ADP</b><p>

	Automatic Data Processing.  See also: <b>Automated Information System</b><p>

<p>

<b>AIS</b><p>

	See: <b>Automated Information System</b>.<p>

<p>

<b>AIS Owner</b><p>

	The official who has the authority to decide on accepting the security safeguards prescribed for an AIS
and is responsible for issuing an accreditation statement that records the decision to accept those
safeguards.<p>

	See also:<b>  Accrediting Authority (AA)</b>,<b> Application Owner</b>, <b>Process Owner, PAA, DAA</b>.<p>

<p>

<b>AIS Security</b><p>

	Measures or controls that safeguard or protect an AIS against unauthorized (accidental or intentional)
disclosure, modification, destruction of the AIS and data, or denial of service.  AIS security provides
an acceptable level of risk for the AIS and the data contained in it. Considerations include: 1) all
hardware and/or software functions, characteristics, and/or features; 2) operational procedures,
accountability procedures, and access controls at all computer facilities in the AIS; 3) management
constraints; 4) physical structures and devices; and 5) personnel and communications controls.<p>

<p>

<b>Application</b><p>

	A software organization of related functions, or series of interdependent or closely related programs,
that when executed accomplish a specified objective or set of user requirements.  Customs applications
include: Automated Commercial System (ACS), Automated Export System (AES), Treasury
Enforcement Communication Systems (TECS), and Administrative Systems (AS).  [USCS 5500-05] 
See also:  <b>Major Application</b>, <b>Process</b>.<p>

<p>

<b>Application Owner</b><p>

	The official who has the responsibility to ensure that the program or programs which make up the
application accomplish the specified objective or set of user requirements established for that
application, including appropriate security safeguards.<p>

	See also:<b>  Accrediting Authority (AA)</b>,<b> Process Owner</b>.<p>

<p>

<b>Audit</b><p>

	To conduct the independent review and examination of system records and activities.<p>

<p>

<b>Audit trail</b><p>

	A set of records that collectively provides documentary evidence of processing.  It is used to aid in
tracing from original transactions forward to related records and reports, and/or backwards from
records and reports to their component source transactions.<p>

<p>

<b>Automated Commercial System (ACS)</b><p>

	A joint public/private data processing system used by Customs and the import trade community to
process millions of commercial cargo shipments entering U.S. commerce each year.<p>

<p>

<b> Automatic Data Processing (ADP)</b><p>

	The assembly of computer hardware, firmware, and software used to categorize, sort, calculate,
compute, summarize, store, retrieve, control, process, and/or protect data with a minimum of human
intervention.  ADP systems can include, but are not limited to, process control computers, embedded
computer systems that perform general purpose computing functions, supercomputers, personal
computers, intelligent terminals, offices automation systems (which includes standalone
microprocessors, memory typewriters, and terminal connected to mainframes), firmware, and other
implementations of AIS technologies as may be developed: they also include applications and
operating system software.  See also: <b>Automated Information System (AIS)</b>.<p>

<p>

<b>Automated Export System (AES)</b><p>

	A data processing system used by Customs to provide automatic release of cargo that is subject to
U.S. export regulatory requirements, collect export data and statistics for use in law enforcement,
illegal chemical interdiction, export verification, revenue collection, and other activities.<p>

<p>

<b>Automated Information System (AIS)</b><p>

	An AIS is an assembly of computer hardware, software, and/or firmware configured to collect,
create, communicate, compute, disseminate, process, store, and/or control data or information. 
Examples include: information storage and retrieval systems, mainframe computers, minicomputers,
personal computers and workstations, office automation systems, automated message processing
systems (AMPSs), and those supercomputers and process control computers (e.g., embedded
computer systems) that perform general purpose computing functions.  [TD P 71-10] <p>

<p>

<b>Authenticate/Authentication</b><p>

	1)	The process to verify the identity of a user, device, or other entity in a computer system, often
as a prerequisite to allowing access to resources in a system.<p>

	2)	A process used to verify that the origin of transmitted data is correctly identified, with
assurance that the identity is not false.  To establish the validity of a claimed identity.<p>

<p>

<b>Authenticated user</b><p>

	A user who has accessed an AIS with a valid identifier and authentication combination.<p>

<p>

<b>Authorization</b><p>

	The privileges and permissions granted to an individual by a designated official to access or use a
program, process, information, or system.  These privileges are based on the individual's approval
and need-to-know.<p>

<p>

<b>Authorized Person</b><p>

	A person who has the need-to-know for sensitive information in the performance of official duties and
who has been granted authorized access at the required level.  The responsibility for determining
whether a prospective recipient is an authorized person rests with the person who has possession,
knowledge, or control of the sensitive information involved, and not with the prospective recipient.<p>

<p>

<b>Availability</b><p>

	The property of being accessible and usable upon demand by an authorized entity.  Security
constraints must make AIS services available to authorized users and unavailable to unauthorized
users.<p>

<p>

<p>

<b><center>B</b><p>

</center>
<p>

<p>

<b>Back-up</b><p>

	A copy of a program or data file for the purposes of protecting against loss if the original data
becomes unavailable.<p>

<p>

<b>Back-up Operation</b><p>

	A method of operations to complete essential tasks as identified by a risk analysis.  These tasks would
be employed following a disruption of the AIS and continue until the AIS is acceptably restored.<p>

	See also: <b>Disaster Recovery, Contingency Operations</b>.<p>

<p>

<b>Bacteria</b><p>

	A malicious computer program that consumes AIS resources by replicating itself.  The program does
not explicitly cause damage to files but replicates itself, thereby denying normal availability of AIS
resources.  See also: <b>Virus</b>,<b> Worm, Trojan Horse, Malicious Code, Trap Door.</b><p>

<p>

<b>Baud</b><p>

	The signaling rate of a communications device, such as a modem, as measured by the  changes per
second of an event (usually an electrical or optical change).  Using encoding the bits-per-second rate
can be multiples of the Baud rate.<p>

<p>

<b>Bits-per-second</b><p>

	The signaling rate of a communications device, such as a modem, measured by binary digits transfers
per second.  Using encoding, bits-per-second rate can be multiples of the Baud rate. <p>

	See also:  <b>BAUD</b>.<p>

<p>

<p>

	<center><b>C</b></center>
<p>

<p>

<p>

<b>C2</b><p>

	A level of security safeguard criteria.  See also: <b>Controlled Access Protection, TCSEC</b>.<p>

<p>

<b>CA-TOP SECRET&reg;</b><p>

	A computer system security program marketed by Computer Associates International Corporation&reg;. 
Originally labeled under the trade mark of TOP-SECRET it was renamed CA-TOP SECRET&reg; to
avoid confusion with the DoD classification. <p>

<p>

<b>Capstone</b><p>

	The U.S. Government's long-term project to develop a set of standards for publicly-available
cryptography, as authorized  by the Computer Security Act of 1987. The Capstone cryptographic
system will consist of four major components and be contained on a single integrated circuit microchip
that provides non-DoD data encryption for Sensitive But Unclassified information.  It implements the
Skipjack algorithm.  See also: <b>Clipper</b>, <b>Fortezza</b>, <b>Sensitive But Unclassified</b>, <b>MISSI</b>.<p>

<p>

<b>Category I</b><p>

	"Consists of Federal departments and agencies expected to play a major role in establishing broad
policy parameters, participating in setting national priorities, and defining and implementing strategies
for response to national security emergencies.  Departments and agencies in this category have
uninterruptible functions which are vital to the national security, immediate survival, and continuity
of government." (Reference: TD P 71-10, V.1.I.2.a, Attachment Section 1, 10/01/92). <p>

	Note:  The Customs Service is designated Category I.<p>

<p>

<b>Certification</b><p>

	The comprehensive analysis of the technical and nontechnical features, and other safeguards, to
establish the extent to which a particular AIS meets a set of specified security requirements. 
Certification is part of the accreditation process and carries with it an implicit mandate for
accreditation.  See also: <b>Accreditation</b>.<p>

<p>

<b>Channel</b><p>

	An information transfer path within a system or the mechanism by which the path is affected.<p>

<p>

<b>CICS (Customer Information Control System)</b><p>

	An IBM&reg; program product for the management of on-line communications between terminal users
and a data base.<p>

<p>

<b>Cipher</b><p>

	An algorithm for encryption or decryption.  A cipher replaces a piece of information (an element of
plain text) with another object, with the intent to conceal meaning.  Typically, the replacement rule
is governed by a secret key.  See also: <b>Encryption, Decryption</b>.<p>

<p>

<b>Classification</b><p>

	A systematic arrangement of information in groups or categories according to established criteria. 
In the interest of national security it is determined that the information requires a specific degree of
protection against unauthorized disclosure together with a designation signifying that such a
determination has been made.  The established categories are Top Secret, Secret, and Confidential,
as specified in E.O. 12958, 4/17/95.  For details on classified information handling processes
reference: CIS HB 1400-03, 1991.  See also:  <b>Limited Official Use</b>.<p>

<p>

<b>Clear or clearing (AIS Storage Media)</b><p>

	The removal of sensitive data from AIS storage and other peripheral devices with storage capacity,
at the end of a period of processing.  It includes data removal in such a way that assures, proportional
to data sensitivity, it may not be reconstructed using normal system capabilities, i.e., through the
keyboard.  See also: <b>Remanence, Object Reuse</b>.<p>

<p>

<b>Clipper</b><p>

	Clipper is an encryption chip developed and sponsored by the U.S. government as part of the
Capstone project.  Announced by the White House in April, 1993, Clipper was designed to balance
competing concerns of Federal law-enforcement agencies and private citizens by using escrowed
encryption keys.  See also: <b>Capstone, Fortezza, MISSI, Skipjack.</b><p>

<p>

<b>Commercial-Off-The-Shelf (COTS</b>)<p>

	Products that are commercially available and can be utilized as generally marketed by the
manufacturer.  <p>

<p>

<b>Compromise</b><p>

	The disclosure of sensitive information to persons not authorized access or having a need-to-know.<p>

<p>

<b>COMSEC (Communication security)</b><p>

	Measures and controls that deny unauthorized persons access to, and ensure the authenticity of,
sensitive (or classified) information derived from telecommunications.  For details on applying
COMSEC to classified information reference: CIS HB 1400-03, 1991.<p>

<p>

<b>Computer Fraud and Abuse Act of 1986</b><p>

	This law makes it a crime to knowingly gain access to a Federal Government computer without
authorization and to affect its operation.  [18 USC 1030]  See also: <b>Federal Government Computer</b>.<p>

<p>

<b>Computer Security</b><p>

	Technological and managerial procedures applied to AIS to ensure the availability, integrity, and
confidentiality of information managed by the AIS.  See also: <b>Information System Security</b>.<p>

<p>

<b>Computer Security Act of 1987</b><p>

	The law provides for improving the security and privacy of sensitive information in "federal computer
systems"--"a computer system operated by a Federal agency or other organization that processes
information (using a computer system) on behalf of the Federal Government to accomplish a Federal
function."  [PL 100-235]  See also: <b>Federal Government Computer</b>.<p>

<p>

<b>Confidential</b><p>

	A security classification for information relevant to national security.  For details on classified
information handling processes reference: CIS HB 1400-03, 1991; E.O. 12958, 4/17/95.<p>

	See also: <b>Limited Official Use</b>.<p>

<p>

<b>Confidentiality</b><p>

	The condition when designated information collected for approved purposes is not disseminated
beyond a community of authorized knowers.  It is distinguished from secrecy, which results from the
intentional concealment or withholding of information.  [OTA-TCT-606]<p>

<p>

	Confidentiality refers to: 1) how data will be maintained and used by the organization that collected
it; 2) what further uses will be made of it; and 3) when individuals will be required to consent to such
uses.  It includes the protection of data from passive attacks and requires that the information (in an
AIS or transmitted) be accessible only for reading by authorized parties.  Access can include printing,
displaying, and other forms of disclosure, including simply revealing the existence of an object.<p>

<p>
<b>Configuration Management (CM)</b><p>

	The management of changes made to an AIS hardware, software, firmware, documentation, tests, test
fixtures, test documentation, communications interfaces, operating procedures, installation structures,
and all changes thereto throughout the development and operational life-cycle of the AIS.<p>

	[NCSC-TG-006]<p>

<p>

<b>Contingency Plan</b><p>

	The documented organized process for implementing emergency response, back-up operations, and
post-disaster recovery, maintained for an AIS as part of its security program, to ensure the availability
of critical assets (resources) and facilitate the continuity of operations in an emergency. <p>

	See also: <b>Disaster Recovery, Emergency Plan</b>.<p>

<p>

<b>Contingency Planing</b><p>

	The process of preparing a documented organized approach for emergency response, back-up
operations, and post-disaster recovery that will ensure the availability of critical AIS resources and
facilitate the continuity of AIS operations in an emergency.<p>

	See also: <b>Contingency Plan, Disaster Recovery, Emergency Plan</b>,<p>

<p>

<b>Controlled Access Protection (C2)</b><p>

	A category of safeguard criteria as defined in the Trusted Computer Security Evaluation Criteria
(TCSEC).  It includes identification and authentication, accountability, auditing, object reuse, and
specific access restrictions to data.  This is the minimum level of control for SBU information.
(Reference: TD P 71-10, VI, 4.B.1).  See also: <b>TCSEC, Appendix E</b> (this document).<p>

<p>

<b>Conventional Encryption</b><p>

	A form of cryptosystem in which encryption and decryption are performed using the same key.<p>

	See also: <b>Symmetric Encryption.</b><p>

<p>

<b>COTS</b><p>

	See:  <b>Commercial-Off-The-Shelf</b>.  <p>

<p>

<b>Countermeasures</b><p>

	See: <b>Security Safeguards</b><p>

<p>

<b>Cracker</b><p>

	See: <b>Hacker</b>.<p>

<p>

<b>Critical Assets</b><p>

	Those assets which provide direct support to the organization's ability to sustain its mission.  Assets
are critical if their absence or unavailability would significantly degrade the ability of the organization
to carry out its mission, and when the time that the organization can function without the asset is less
than the time needed to replace the asset.<p>

<p>

<b>Critical processing</b><p>

	Any applications which are so important to an organization that little or no loss of availability is
acceptable; critical processing must be defined carefully during disaster and contingency planning. 
See also: <b>Critical Assets</b><p>

<p>

<b>Cryptanalysis</b><p>

	The branch of cryptology dealing with the breaking of a cipher to recover information, or forging
encrypted information what will be accepted as authentic.<p>

<p>

<b>Cryptography</b><p>

	The branch of cryptology dealing with the design of algorithms for encryption and decryption,
intended to ensure the secrecy and/or authenticity of messages.<p>

<p>

<b>Cryptology</b><p>

	The study of secure communications, which encompasses both cryptography and cryptanalysis.<p>

<p>

<p>

	<center><b>D</b></center>
<p>

<p>

<p>

<b>DAA</b><p>

	See: <b>Designated Approving Authority, PAA, AA</b>.<p>

<p>

<b>DAC</b><p>

	See: <b>Discretionary Access Control, C2, TCSEC</b>.<p>

<p>

<b>DASD (Direct Access Storage Device)</b><p>

	A physical electromagnetic data storage unit used in larger computers.  Usually these consist of
cylindrical stacked multi-unit assemblies which have large capacity storage capabilities.<p>

<p>

<b>Data</b><p>

	A representation of facts, concepts, information, or instructions suitable for communication,
interpretation, or processing.  It is used as a plural noun meaning "facts or information" as in: <i>These
data are described fully in the appendix</i>, or as a singular mass noun meaning "information" as in:<i> The
data is entered into the computer</i>.  [<u>Random House Webster's College Dictionary</u>, 1994]<p>

<p>

<b>Data Encryption Standard (DES)</b><p>

	Data Encryption Standard is an encryption block cipher defined and endorsed by the U.S. government
in 1977 as an official standard (FIPS PUB 59).  Developed by IBM&reg;, it has been extensively studiedfor over 15 years and is the most well-know and widely used cryptosystem in the world.<p>

	See also: <b>Capstone, Clipper, RSA, Skipjack</b>.<p>

<p>

<b>Data integrity</b><p>

	The state that exists when computerized data are the same as those that are in the source documents
and have not been exposed to accidental or malicious alterations or destruction.  It requires that the
AIS assets and transmitted information be capable of modification only by authorized parties. 
Modification includes writing, changing, changing status, deleting, creating, and the delaying or
replaying of transmitted messages.  See also: <b>Integrity, System integrity</b>.<p>

<p>

<b>Deciphering</b><p>

	The translation of encrypted text or data (called ciphertext) into original text or data (called plaintext). 
See also: <b>Decryption</b>.<p>

<p>

<b>Decryption</b><p>

	The translation of encrypted text or data (called ciphertext) into original text or data (called plaintext). 
See also: <b>Deciphering</b>.<p>

<p>

<b>Dedicated Security Mode</b><p>

	An operational method when each user with direct or indirect individual access to a computer system,
its peripherals, and remote terminals or hosts has a valid personnel security authorization and a valid
need-to-know for all information contained within the system.<p>

	See also: <b>System High Security Mode</b>.<p>

	<p>

<b>Designated Approving Authority (DAA)</b><p>

	The official who has the authority to decide to accept the security safeguards prescribed for an AIS
or the official who may be responsible for issuing an accreditation statement that records the decision
to accept those safeguards.  See also:  <b>Accrediting Authority, AA, DAA, PAA</b>.<p>

<p>

<b>DES</b><p>

	See: <b>Data Encryption Standard</b><p>

	See also: <b>Capstone, Clipper, RSA, Skipjack</b>.<p>

<p>

<b>Dedicated System</b><p>

	A system that is specifically and exclusively dedicated to and controlled for a specific mission, either
for full time operation or a specified period of time.  See also: <b>Dedicated Security Mode</b>.<p>

<p>

<b>Denial of Service</b><p>

	The prevention of authorized access to resources or the delaying of time-critical operations.  Refers
to the inability of an AIS system or any essential part to perform its designated mission, either by loss
of, or degradation of operational capability.<p>

<p>

<b>Department of Defense (DOD) Trusted Computer System Evaluation Criteria</b><p>

	The National Computer Security Center (NCSC) criteria intended for use in the design and evaluation
of systems that will process and/or store sensitive (or classified) data.  This document contains a
uniform set of basic requirements and evaluation classes used for assessing the degrees of assurance
in the effectiveness of hardware and software security controls built in the design and evaluation of
AIS.  [5200.28-STD]  See also: <b>C2, Orange Book, TCSEC</b>.<p>

<p>

<b>Designated Security Officer</b><p>

	The person responsible to the DAA for ensuring that security is provided for and implemented
throughout the life-cycle of an AIS from the beginning of the system concept development phase
through its design, development, operations, maintenance, and disposal.  [NCSC-TG-027] <p>

	See also:<b> DSO</b>, <b>ISSO</b>.<p>

<p>

<b>Digital Signature Standard</b><p>

	DSS is the Digital Signature Standard, which specifies a Digital Signature Algorithm (DSA), and is
part of the U.S. government's Capstone project.  It was selected by NIST and NSA to be the digital
authentication standard of the U.S. government, but has not yet been officially adopted.<p>

	See also: <b>Capstone, Clipper, RSA, Skipjack</b>.<p>

<p>

<b>Disaster Recovery Plan</b><p>

	The procedures to be followed should a disaster (fire, flood, etc.) occur.  Disaster recovery plans may
cover the computer center and other aspects of normal organizational functioning. <p>

	See also: <b>Contingency Plan</b>, <b>Emergency Plan</b>.<p>

<p>

<b>Discretionary Access Control (DAC)</b><p>

	A means of restricting access to objects based on the identity of subjects and/or groups to which they
belong or on the possession of an authorization granting access to those objects.  The controls are
discretionary in the sense that a subject with a certain access permission is capable of passing that
permission (perhaps indirectly) onto any other subject.  [NCSC-TG-003]<p>

<p>

<b>Discretionary processing</b><p>

	Any computer work that can withstand interruption resulting from some disaster.<p>

<p>

<b>DoD</b><p>

	U.S. Department of Defense.<p>

<p>

<b>DoD Directive 5200.28-STD</b><p>

	The 1988 DoD policy establishing uniform security requirements, administrative controls, and
technical measures to protect classified information processed by DoD computer systems. <p>

	See also: <b>C2, TCSEC, Orange Book</b>.<p>

<p>

<b>DSO</b><p>

	See: <b>Designated Security Officer</b><p>

	See also: <b>ISSO</b><p>

<p>

<b>DSS</b><p>

	See: <b>Digital Signature Standard, Capstone, Clipper, RSA, Skipjack</b>.<p>

<p>

	<center><b>E</b></center>
<p>

<p>

<p>

<b>Emergency Response</b><p>

	A response to emergencies such as fire, flood, civil commotion, natural disasters, bomb threats, etc.,
in order to protect lives, limit the damage to property and the impact on AIS operations.<p>

<p>

<b>Emergency Operating Records</b><p>

	Records which are vital to the continuation of essential functions of the Department and its operating
units and should be safeguarded.  Such records are those that would be required on an immediate basis
to support the implementation of the emergency operations of the Department to ensure the continuity
of the Federal government.  (Reference: TD P 71-10, V.1.III.2.a, 1992).<p>

	See also: <b>Vital Records and Rights and Interests Records</b>.<p>

<p>

<b>Emanations</b><p>

	See: <b>TEMPEST</b>.<p>

<p>

<b>Enciphering</b><p>

	The conversion of plaintext or data into unintelligible form by mean of a reversible translation that is
based on a translation table or algorithm.  See also: <b>Encryption</b>.<p>

<p>

<b>Encryption</b><p>

	The conversion of plaintext or data into unintelligible form by mean of a reversible translation that is
based on a translation table or algorithm.  See also: <b>Enciphering</b>, <b>MISSI</b>.<p>

<p>

<b>Entity</b><p>

	Something that exists as independent, distinct or self-contained.  For programs, it may be anything
that can be described using data, such as an employee, product, or invoice.  Data associated with an
entity are called attributes.  A product's price, weight, quantities in stock, and description all
constitute attributes.  It is often used in describing distinct business organizations or government
agencies.<p>

<p>

<b>Environment</b><p>

	The aggregate of external circumstance, conditions, and events that affect the development, operation,
and maintenance of a system.  Environment is often used with qualifiers such as computing
environment, application environment, or threat environment, which limit the scope being considered.<p>

<p>

<b>Evaluation</b><p>

	Evaluation is the assessment for conformance with a preestablished metric, criteria, or standard.<p>

<p>

<b>Evaluated Products List (EPL)</b><p>

	The <u>Information Systems Security Products and Services Catalog</u>, published quarterly by NSA. 
Contains information systems security products and services that have been evaluated by the National
Computer Security Center (NCSC) and approved by the NSA to assist in the selection of products that
will provide an appropriate level of information security.  See also: <b>Trusted Product</b><p>

	<p>

<p>

	<center><b>F</b></center>
<p>

<p>

<p>

<b>Federal Government Computer</b>.<p>

	A Federal government computer is any computer used by the United States government and/or
Federally-insured financial institutions.  [18 USC 1030]<p>

	See also:  <b>Computer Fraud and Abuse Act of 1986</b>.<p>

<p>

<b>Firewall</b><p>

	A collection of components or a system that is placed between two networks and possesses the
following properties: 1) all traffic from inside to outside, and vice-versus, must pass through it; 2)
only authorized traffic, as defined by the local security policy, is allowed to pass through it; 3) the
system itself is immune to penetration.  [CHES94]<p>

<p>

<b>Firmware</b><p>

	Equipment or devices within which computer programming instructions necessary to the performance
of the device's discrete functions are electrically embedded in such a manner that they cannot be
electrically altered during normal device operations.  [NCSC-TG-006]<p>

<p>

<b>Fortezza</b><p>

	See: <b>Fortezza Crypto Card</b><p>

<p>

<b>Fortezza Crypto Card</b><p>

	A credit card size data security device containing MISSI Phase 1 encryption algorithms, key material
and user related information.  This device is based on a Personal Computer Memory Card Interface
Association (PCMCIA) card which has been built to perform the cryptographic features required by
the MISSI Phase 1 program (data hashing, signing, encrypting and decrypting).  This card was
formerly known as the "Tessera Crypto Card."  [MISSI] <p>

	See also:  <b>Capstone, Encryption, MISSI, Clipper, RSA, Skipjack</b>.<p>

<p>

<p>

	<center><b>G</b></center>
<p>

<p>

<p>

<b>Gateway</b><p>

	A machine or set of machines that provides relay services between two networks.<p>

<p>

<b>General Support System</b><p>

	An interconnected set of information resources under the same direct management control which
shares common functionality.  A system normally includes hardware, software, information, data,
applications, communications, and people.  A system can be, for example, a local area network
(LAN) including smart terminals that support a branch office, an agency-wide backbone, a
communications network, a departmental data processing center including its operating system and
utilities, a tactical radio network, or a shared information processing service organization (IPSO).<p>

	[OMB A-130, AIII]<p>

<p>

<p>

	<center><b>H</b></center>
<p>

<p>

<p>

<b>Hack</b><p>

	Any software in which a significant portion of the code was originally another program.  Many hacked
programs simply have the copyright notice removed.  Some hacks are done by programmers using
code they have previously written that serves as a boilerplate for a set of operations needed in the
program they are currently working on.  In other cases it simply means a draft.  Commonly misused
to imply theft of software.  See also: <b>Hacker</b><p>

<p>

<b>Hacker</b><p>

	Common nickname for an unauthorized person who breaks into or attempts to break into an AIS by
circumventing software security safeguards.  Also, commonly called a "cracker."<p>

	See also: <b>Intruder</b>, <b>Hack</b>.<p>

<p>

<p>

<b><center>I</b></center>
<p>

<p>

<p>

<b>Information Security</b><p>

	The protection of information systems against unauthorized access to or modification of information,
whether in storage, processing or transit, and against the denial of service to authorized users or the
provision of service to unauthorized users, including those measures necessary to detect, document,
and counter such threats.<p>

<p>

<b>Information Systems Security (INFOSEC)</b><p>

	The protection of information assets from unauthorized access to or modification of information,
whether in storage, processing, or transit, and against the denial of service to authorized users or the
provision of service to unauthorized users, including those measures necessary to detect, document,
and counter such threats.  INFOSEC reflects the concept of the totality of AIS security. <p>

	See also: <b>Computer Security.</b><p>

<p>

<b>Identification</b><p>

	The process that enables recognition of an entity by a system, generally by the use of unique machine-readable user names.<p>

<p>

<b>Information System Security Officer (ISSO)</b><p>

	The person responsible to the DAA for ensuring that security is provided for and implemented
throughout the life-cycle of an AIS from the beginning of the system concept development phase
through its design, development, operations, maintenance, and disposal.  [NCSC-TG-027]<p>

	See also:<b> DSO</b>, <b>Designated Security Officer<p>

</b><p>

<b>Integrity</b><p>

	A subgoal of computer security which ensures that: 1) data is a proper representation of information;
2) data retains its original level of accuracy; 3) data remains in a sound, unimpaired, or perfect
condition; 3) the AIS perform correct  processing operations; and 4) the computerized data faithfully
represent those in the source documents and have not been exposed to accidental or malicious
alteration or destruction.  [NCSC C TR 79-91]  See also: <b>Data integrity, System integrity</b>.<p>

<p>

<b>Interconnected System</b><p>

	An approach in which the network is treated as an interconnection of separately created, managed,
and accredited AIS.<p>

<p>

<b>Internet</b><p>

	A world-wide "network of networks" that uses Transmission Control Protocol/Internet Protocol
(TCP/IP) for communications.  [WACK]<p>

<p>

<b>Intruder</b><p>

	An individual who gains, or attempts to gain, unauthorized access to a computer system or to gain
unauthorized privileges on that system.  See also: <b>Hacker</b><p>

<p>

<b>ISSO</b><p>

	See: <b>Information System Security Officer</b>, <b> DSO</b>, <b>Designated Security Officer</b>.<p>

<p>

<p>

	<center><b>J</b></center>
<p>

<p>

<p>

<center>NONE AT THIS TIME</center>
<p>

<p>

<p>

	<center><b>K</b></center>
<p>

<p>

<p>

<b>Key Distribution Center</b><p>

	A system that is authorized to transmit temporary session keys to principals (authorized users).  Each
session key is transmitted in encrypted form, using a master key that the key distribution shares with
the target principal.  See also: <b>DSS, Encryption, Kerberos</b>.<p>

<p>

<b>Kerberos</b><p>

	Kerberos is a secret-key network authentication system developed by MIT and uses DES for
encryption and authentication.  Unlike a public-key authentication system, it does not produce digital
signatures.  Kerberos was designed to authenticate requests for network resources rather than to
authenticate authorship of documents.  See also: <b>DSS</b>.<p>

<p>

<p>

	<center><b>L</b></center>
<p>

<p>

<p>

<b>Label</b><p>

	The marking of an item of information that reflects its information security classification.  An internal
label is the marking of an item of information that reflects the classification of that item within the
confines of the medium containing the information.  An external label is a visible or readable marking
on the outside of the medium or its cover that reflects the security classification information resident
within that particular medium.  See also: <b>Confidential, Limited Official Use</b>.<p>

<p>

<b>LAN (Local Area Network)</b><p>

	An interconnected system of computers and peripherals.  LAN users can share data stored on hard
disks in the network and can share printers connected to the network.<p>

<p>

<b>Least Privilege</b><p>

	The principle that requires each subject be granted the most restrictive set of privileges needed for the
performance of authorized tasks.  The application of this principle limits the damage that can result
from accident, error, or unauthorized use.  [5200.28-STD]<p>

<p>

<b>Limited Official Use (LOU)</b><p>

	A category of SBU information that must be protected in the same manner as national security
information classified Confidential. (Reference: TD P 71-10, III.2; CIS HB 1400-03).<p>

	See also: <b>Sensitive But Unclassified (SBU)</b>, <b>Confidential</b>.<p>

<p>

<p>

	<center><b>M</b></center>
<p>

<p>

<p>

<b>Malicious Code</b><p>

	Software or firmware that is intentionally included in an AIS for an unauthorized purpose.<p>

	See also: <b>Bacteria</b>, <b>Trapdoor</b>, <b>Trojan Horse</b>, <b>Virus</b>, <b>Worm</b>.<p>

<p>

<b>Major Application</b><p>

	An application that requires special attention to security due to the risk and magnitude of the harm
resulting from the loss, misuse, or unauthorized access to or modification of the information in the
application.  Note: All Federal applications require some level of protection.  Certain applications, 
because of the sensitive information in them, however, require special management oversight and
should be treated as major.  Adequate security for other applications should be provided by security
of the systems in which they operate.  [OMB A-130,AIII]  See also: <b>Application</b>, <b>Process</b>.<p>

	<p>

<b>Microprocessor</b><p>

	A semiconductor central processing unit contained on a single integrated circuit chip.<p>

<p>

<b>MISSI</b><p>

	The MISSI is a National Security Agency (NSA) program which provides value added security
services for Unclassified But Sensitive (SBU) information.  These services provided confidentiality
through data encryption and decryption, original authentication through public key digital signatures,
non-repudiation (undeniable proof of identity) of the originator and recipient, also by public key digital
signatures on the message and receipts respectively, and data integrity through a secure hashing
algorithm.  [MISSI]  See also:  <b>Capstone, Fortezza, Crypto Card</b><p>

<p>

<p>

	<center><b>N</b></center>
<p>

<p>

<p>

<b>National Computer Security Center</b> (NCSC)<p>

	The government agency part of the National Security Agency (NSA) and that produces technical
reference materials relating to a wide variety of computer security areas.  It is located at 9800 Savage
Rd., Ft. George G. Meade, MD.<p>

<p>

<b>National Telecommunications and Information Systems Security Policy</b><p>

	Directs Federal agencies, by July 15, 1992, to provide automated Controlled Access Protection (C2
level) for AIS, when all users do not have the same authorization to use the sensitive information. 
[NTISSP 200]<p>

<p>

<b>Need-to-Know</b><p>

	A determination by the owner of sensitive information that a prospective recipient has a requirement
for access to, knowledge of, or possession of the information in order to perform tasks or services
essential to carry out official duties.<p>

<p>

<b>Network</b><p>

	A communications medium and all components attached to that medium whose responsibility is the
transference of information.  Such components may include AISs, packet switches,
telecommunications controllers, key distribution centers, and technical control devices.<p>

<p>

<b>Network Security</b><p>

	Protection of networks and their services from unauthorized modification, destruction, or disclosure,
and the provision of assurance that the network performs its critical functions correctly and there are
no harmful side-effects.<p>

<p>

<b>NIST</b><p>

	National Institute of Standards and Technology in Gaithersburg, MD.  (Prior to 1988, called the
National Bureau of Standards).  NIST publishes a wide variety of materials on computer security,
including FIPS publications.<p>

<p>

<b>Non-Repudiation</b><p>

	Method by which the sender is provided with proof of delivery and the recipient is assured of the
sender's identity, so that neither can later deny having processed the data.<p>

<p>

<b>Nonvolatile Memory Units</b><p>

	Devices which continue to retain their contents when power to the unit is turned off (e.g. bubble
memory, Read Only Memory-ROM).<p>

<p>

<p>

	<center><b>O</b></center>
<p>

<p>

<p>

<b>Object</b><p>

	A passive entity that contains or receives information.  Access to an object potentially implies access
to the information it contains.  Examples of objects are records, blocks, pages, segments, files,
directories, directory tree, and programs, as well as bits, bytes, words, fields, processors, video
displays, keyboards, clocks, printers, network nodes, etc.<p>

<p>

<b>Object Reuse</b><p>

	The reassignment to some subject of a medium (e.g., page frame, disk sector, or magnetic tape) that
contained one or more objects.  To be securely reassigned, no residual data from previously contained
object(s) can be available to the new subject through standard system mechanisms.<p>

	[NCSC-TG-025]  See also: <b>Remanence</b>.<p>

<p>

<b>Official Use Only</b><p>

	A category of SBU information that must be administratively controlled and protected at a security
level at least equal to C2.  (Reference: TD P 71-10, III.2; CIS HB 1400-03, 1991).<p>

	See also: <b>Sensitive But Unclassified (SBU), C2</b>.<p>

<p>

<b>Off-line</b><p>

	Pertaining to the operation of a functional unit when not under direct control of a computer.<p>

	See also: <b>On-line</b>.<p>

<p>

<b>On-line</b><p>

	Pertaining to the operation of a functional unit when under the direct control of a computer.<p>

	See also: <b>Off-line</b>.<p>

<p>

<b>Orange book</b><p>

	Named because of the color of its cover, this is the DoD Trusted Computer System Evaluation
Criteria, DoD 5200.28-STD.  It provides the information needed to classify computer systems as
security levels of A, B, C, or D, defining the degree of trust that may be placed in them.<p>

	See also: <b>C2, TCSEC</b>.<p>

<p>

<b>Overwrite Procedure</b><p>

	A process which removes or destroys data recorded on a computer storage medium by writing patterns
of data over, or on top of, the data stored on the medium.<p>

<p>

<p>

	<center><b>P</b></center>
<p>

<p>

<p>

<b>Password</b><p>

	A protected and private character string used to authenticate an AIS user.<p>

<p>

<b>Personally-owned computers or software</b><p>

	"Computers or software purchased with non-government funds, except those turned over for exclusive
U.S. Government control and use and where the hard-drive will be properly erased when the system
is no longer in U.S. Government use."<p>

	(Reference: TD P 71-10, Appendix B.  Definition updated 11/24/95).<p>

<p>

<b>Personnel Security</b><p>

	The procedures established to ensure that all personnel who have access to any sensitive information
have all required authorities or appropriate security authorizations.<p>

<p>

<b>Physical Security</b><p>

	The application of physical barriers and control procedures as preventative measures or safeguards
against threats to resources and information.<p>

<p>

<b>Principal Accrediting Authority (PAA)</b><p>

	The official who has the authority to decide on accepting the security safeguards prescribed for an AIS
or the official who may be responsible for issuing an accreditation statement that records the decision
to accept those safeguards.<p>

	See also:  <b>Accrediting Authority (AA), Designated Approving Authority (DAA)</b>.<p>

<p>

<b>Privacy Act of 1974</b><p>

	A US law permitting citizens to examine and make corrections to records the government maintains. 
It requires that Federal agencies adhere to certain procedures in their record keeping and interagency
information transfers.  Reference: FIPS Pub. 41, 05/30/75 (Implementing the Privacy Act of 1975),
and the <u>Privacy Act of 1974, As Amended</u>.  [5 USC 552a. PL 93-579]<p>

	See also: <b>System of Records</b>.<p>

<p>

<b>Private Branch Exchange</b><p>

	Private Branch eXchange (PBX) is a telephone switch providing speech connections within an
organization, while also allowing users access to both public switches and private network facilities
outside the organization. The terms PABX, PBX, and PABX are used interchangeably.<p>

<p>

<b>Process</b><p>

	An organizational assignment of responsibilities for an associated collection of activities that takes one
or more kinds of input to accomplish a specified objective that creates an output that is of value. 
Customs processes include: Passenger Compliance, Cargo Compliance, Informed Compliance,
Strategic Trade, Anti-smuggling, Outbound Process, Intelligence and Investigations.  [USCS PPP] 
See also:<b> Application</b>.<p>

<p>

<b>Process Owner</b><p>

	The official who defines the process parameters and its relationship to other Customs processes.  The
process owner has Accrediting Authority (AA) to decide on accepting the security safeguards
prescribed for the AIS process and is responsible for issuing an accreditation statement that records
the decision to accept those safeguards.<p>

	See also:<b>  Accrediting Authority (AA)</b>,<b> Application Owner</b>.<p>

<p>

<b>Public Law 100-235</b><p>

	Established minimal acceptable standards for the government in computer security and information
privacy.  See also: <b>Computer Security Act of 1987</b>.<p>

<p>

<p>

	<center><b>Q</b></center>
<p>

<p>

<p>

<center>NONE AT THIS TIME</center>
<p>

<p>

<p>

	<center><b>R</b></center>
<p>

<p>

<p>

<b>Rainbow Series</b><p>

	A series of documents published by the National Computer Security Center (NCSC) to discuss in
detail the features of the DoD, <u>Trusted Computer System Evaluation Criteria</u> (TCSEC) and provide
guidance for meeting each requirement.  The name "rainbow" is a nickname because each document
has a different color of cover.  See also: <b>NCSC</b>.<p>

<p>

<b>Read</b><p>

	A fundamental operations that results only in the flow of information from an object to a subject.<p>

<p>

<b>Recovery</b><p>

	The process of restoring an AIS facility and related assets, damaged files, or equipment so as to be
useful again after a major emergency which resulted in significant curtailing of normal ADP
operations.  See also: <b>Disaster Recovery</b>.<p>

<p>

<b>Remanence</b><p>

	The residual information that remains on storage media after erasure.  For discussion purposes, it is
better to characterize magnetic remanence as the magnetic representation of residual information that
remains on magnetic media after the media has been erased. The magnetic flux that remains in a
magnetic circuit after an applied magnetomotive force has been removed.<p>

	[<u>Random House Webster's College Dictionary</u>, 1994; NCSC-TG-025]  See also: <b>Object Reuse</b>.<p>

<p>

<b>Residual Risk</b><p>

	The part of risk remaining after security measures have been implemented.<p>

<p>

<b>Rights and Interests Records</b><p>

	"Records that are necessary for the preservation of the rights and interests of individual citizens and
the Federal government."  (Reference: TD P 71-10, V.1.III.2.b, 1992).<p>

	See also: <b>Emergency Operating Records</b>, <b>Vital Records</b>.<p>

<p>

<b>Risk Analysis</b><p>

	The process of identifying security risks, determining their magnitude, and identifying areas needing
safeguards.  An analysis of an organization's information resources, its existing controls, and its
remaining organizational and AIS vulnerabilities.  It combines the loss potential for each resource or
combination of resources with an estimated rate of occurrence to establish a potential level of damage
in dollars or other assets.  [TD 85-03]  See also: <b>Risk Assessment, Risk Management</b>.<p>

<p>

<b>Risk Assessment</b><p>

	Process of analyzing threats to and vulnerabilities of an AIS to determine the risks (potential for
losses), and using the analysis as a basis for identifying appropriate and cost-effective measures.
[TD 85-03]  See also: <b>Risk  Analysis, Risk Management</b>.<p>

<p>

	Note: Risk analysis is a part of risk management, which is used to minimize risk by specifying
security measures commensurate with the relative values of the resources to be protected, the
vulnerabilities of those resources, and the identified threats against them.  The method should be
applied iteratively during the system life-cycle.  When applied during the implementation phase or to
an operational system, it can verify the effectiveness of existing safeguards and identify areas in which
additional measures are needed to achieve the desired level of security.  There are numerous risk
analysis methodologies and some automated tools available to support them.<p>

<p>

<b>Risk Management</b> <p>

	The total process of identifying, measuring, controlling, and eliminating or minimizing uncertain
events that may affect system resources.  Risk management encompasses the entire system life-cycles
and has a direct impact on system certification.  It may include risk analysis, cost/benefit analysis,
safeguard selection, security test and evaluation, safeguard implementation, and system review. 
[OMB A-130,AIII; TD 85-03]  See also: <b>Risk Analysis, Risk Assessment</b><p>

<p>

<b>ROM</b><p>

	Read Only Memory.  See also: <b>Nonvolatile Memory Units</b>.<p>

<p>

<b>RSA</b><p>

	A public-key cryptosystem for both encryption and authentication based on exponentiation in modular
arithmetic. The algorithm was invented in 1977 by Rivest, Shamir, and Adelman and is generally
accepted as practical or secure for public-key encryption.  <p>

	See also: <b>DES, Capstone, Clipper, RSA, Skipjack</b>.<p>

<p>

<p>

	<center><b>S</b></center>
<p>

<p>

<p>

<b>Safeguards</b><p>

	Countermeasures, specifications, or controls, consisting of actions taken to decrease the organizations
existing degree of vulnerability to a given threat probability, that the threat will occur.<p>

<p>

<b>Security Incident</b><p>

	An AIS security incident is any event and/or condition that has the potential to impact the security
and/or accreditation of an AIS and may result from intentional or unintentional actions.<p>

	See also: <b>Security Violation</b>.<p>

<p>

<b>Security Policy</b><p>

	The set of laws, rules, directives, and practices that regulate how an organization manages, protects,
and distributes controlled information.<p>

<p>

<b>Security Requirements</b><p>

	Types and levels of protection necessary for equipment, data, information, applications, and facilities
to meet security policies.<p>

<p>

<b>Security Safeguards (countermeasures)</b><p>

	The protective measures and controls that are prescribed to meet the security requirements specified
for a system.  Those safeguards may include, but are not necessarily limited to: hardware and
software security features; operating procedures; accountability procedures; access and distribution
controls; management constraints; personnel security; and physical structures, areas, and devices. 
Also called safeguards or security controls.<p>

<p>

<b>Security Specifications</b><p>

	A detailed description of the security safeguards required to protect a system.<p>

<p>

<b>Security Violation</b><p>

	An event which may result in disclosure of sensitive information to unauthorized individuals, or that
results in unauthorized modification or destruction of system data, loss of computer system processing
capability, or loss or theft of any computer system resources.  See also: <b>Security Incident</b>.<p>

<p>

<b>Sensitive Information</b><p>

	A category of unclassified Government controlled information.<p>

	See also: <b>Sensitive But Unclassified (SBU), Limited Official Use, Confidential</b>.<p>

<p>

<b>Sensitive But Unclassified (SBU) Information</b><p>

	"Any information, the loss, misuse, or unauthorized access to or modification of which could
adversely affect the national interest or the conduct of Federal programs, or the privacy to which
individuals are entitled under 5 USC 552a (Privacy Act), but which has not been specifically
authorized under criteria established by an Executive order or an Act of Congress to be kept secret
in the interest of national defense of foreign policy.  This definition is synonymous with "<b>sensitive
information</b>" as defined in Public Law 100.235, "The Computer Security Act of 1987," dated January
8, 1988.  In addition, Treasury SBU information also includes trade secret or confidential information
protected by Section 1905 of Title 18, USC (Trade Secret Act).  All information designated Limited
Official Use (LOU) is included within SBU information." <p>

	(Reference: TD P 71-10, Appendix B, page 52; also Chapter VI, Section 2.A.4.b).<p>

<p>

	"SBU AIS and networks shall be protected to at least the minimum level of controlled access
protection (C2) as defined in Section 4.B.1."  (Reference: TD P 71-10, Chapter VI.4.B).<p>

<p>

	"Examples of SBU information include financial, law enforcement, and counternarcotics information.<p>

 	 (Reference: TD P 71-10, Chapter VI, Section 2.A.4.b).<p>

<p>

	<b>Editor Notes</b>:<p>

	Sensitive But Unclassified (SBU) is a category of <b>unclassified</b> Government controlled information. 
Similar terms may appear in other government documents as "unclassified but sensitive" or 
"sensitive."  The meaning however, remains the same.  The majority of the information in Customs
AIS is categorized as SBU and may include, but is not limited to, information, the improper use or
disclosure of which could adversely affect the ability of Customs to accomplish its mission;
information that is investigative in nature; grand jury information subject to the Federal Rules of
Criminal Procedure, Rule 6(e), Grand Jury Secrecy of Proceedings and Disclosure; proprietary
information; records about individuals requiring protection under the Privacy Act; information not
releasable under the Freedom of Information Act; and information which could be manipulated for
personal profit or to hide the unauthorized use of money, equipment, or privileges.<p>

	See also:<b> Confidential, C2, Limited Official Use, TCSEC.</b><p>

<p>

<b>Site</b><p>

	Usually a single physical location, but it may be one or more AISs that are the responsibility of the
DSO.  The system may be a stand-alone AIS, a remote site linked to a network, or workstations
interconnected via a local area network (LAN).<p>

<p>

<b>Skipjack</b><p>

	A classified NSA designed encryption algorithm contained in the Clipper Chip.  It is substantially
stronger than DES and Intended to provide a Federally mandated encryption process which would
enable law enforcement agencies to monitor and wiretap private communications. [MISSI]<p>

	See also: <b>Capstone, DES, Fortezza, Clipper, RSA, Skipjack</b>.<p>

<p>

<b>Standard Security Procedures</b><p>

	Step-by-step security instructions tailored to users and operators of AISs that process sensitive
information.<p>

<p>

<b>Standalone System</b><p>

	A single-user AIS not connected to any other systems.<p>

<p>

<b>Symmetric Encryption</b><p>

	See: <b>Conventional Encryption</b>.<p>

<p>

<b>System</b><p>

	See:  <b>Automated Information System, AIS</b><p>

<p>

<b>System High Security Mode</b><p>

	A mode of operation wherein all users having access to the AIS possess a security authorization, but
not necessarily a need-to-know for all data handled by the AIS. [5200.28.STD, 1985] <p>

	See also: <b>Dedicated Security Mode</b>.<p>

	<p>

<b>System Integrity</b><p>

	The attribute of a system relating to the successful and correct operation of computing resources. <p>

	See also: <b>Integrity</b>.<p>

<p>

<b>System of Records</b><p>

	A group of any records under the control of the Department from which information is retrieved by
the name of an individual, or by some other identifying number, symbol, or other identifying
particular assigned to an individual.  [TD 25-04]  See also: <b>Privacy Act of 1974</b><p>

<p>

<p>

	<center><b>T</b></center>
<p>

<p>

<p>

<b>TCSEC</b><p>

	<u>Trusted Computer System Evaluation Criteria</u> (TCSEC).  DoD 5200.28-STD, National Institute of
Standards and Technology (NIST), Gaithersburg, MD., 1985.  Establishes uniform security
requirements, administrative controls, and technical measures to protect sensitive information
processed by DoD computer systems. It provides a standard for security features in commercial
products and gives a metric for evaluating the degree of trust that can be placed in computer systems
for the securing of sensitive information. See also: <b>C2, Orange Book</b>.<p>

<p>

<b>Test Condition</b><p>

	A statement defining a constraint that must be satisfied by the program under test.<p>

<p>

<b>Test Data</b><p>

	The set of specific objects and variables that must be used to demonstrate that a program produces a
set of given outcomes.  See also: <b>Disaster Recovery</b>, <b>Test program</b>.<p>

<p>

<b>Test Plan</b><p>

	A document or a section of a document which describes the test conditions, data, and coverage of a
particular test or group of tests.<p>

	See also: <b>Disaster Recovery</b>,<b> Test Condition</b>, <b>Test Data</b>, <b>Test procedure (Script)</b>.<p>

<p>

<b>Test procedure (Script)</b><p>

	A set of steps necessary to carry out one or a group of tests.  These include steps for test environment
initialization, test execution, and result analysis.  The test procedures are carried out by test operators.<p>

<p>

<b>Test program</b><p>

	A program which implements the test conditions when initialized with the test data and which collects
the results produced by the program being tested.<p>

	See also: <b>Disaster Recovery</b>,<b> Test Condition</b>, <b>Test Data</b>, <b>Test procedure (Script)</b>.<p>

<p>

<b>TEMPEST</b><p>

	The study and control of spurious electronic signals emitted from AIS equipment.  All TEMPEST
issues should be directed to the Treasury Office of Information Systems Security.<p>

	[5200.28-STD; TD P 71-10; CIS HB 4300-09]<p>

<p>

<b>Top Secret</b><p>

	A high DoD security classification.  See also: <b>CA-TOP SECRET&reg;</b><p>

<p>

<b>Threat</b><p>

	An event, process, activity (act), substance, or quality of being perpetuated by one or more threat
agents, which, when realized, has an adverse effect on organization assets, resulting in losses
attributed to:<p>

	Direct loss<p>

	Related direct loss<p>

	Delays or denials<p>

	Disclosure of sensitive information<p>

	Modification of programs or data bases<p>

	Intangible, i.e., good will, reputation, etc.<p>

<p>

<b>Threat agent</b><p>

	Any person or thing which acts, or has the power to act, to cause, carry, transmit, or support a threat. 
See also: <b>Threat</b>.<p>

<p>

<b>Trapdoor</b><p>

	A secret undocumented entry point into a computer program, used to grant access without normal
methods of access authentication.  See also:<b> Malicious Code</b>.<p>

<p>

<b>Treasury Enforcement Communications System (TECS)</b><p>

	An automated enforcement and inspection support system built to aid Customs and other Federal
agencies.<p>

<p>

<b>Trojan Horse</b><p>

	A computer program with an apparently or actually useful function that contains additional (hidden)
functions that surreptitiously exploit the legitimate authorizations of the invoking process to the
detriment of security.  See also: <b>Malicious Code</b>.<p>

<p>

<b>Trusted Computer Base (TCB)</b><p>

	The totality of protection mechanisms within a computer system, including hardware, firmware, and
software, the combination of which is responsible for enforcing a security policy.  A TCB consists
of one or more components that together enforce a security policy over a product or system.<p>

	See also: <b>C2, TCSEC, Orange Book</b>.<p>

<p>

<b>Trusted Computing System</b><p>

	A computer and operating system that employs sufficient hardware and software integrity measures
to allow its use for simultaneously processing a range of sensitive information and can be verified to
implement a given security policy.<p>

<p>

<b>Trusted Product</b><p>

	A product that has been evaluated by the National Computer Security Center (NCSC) and approved
by the National Security Agency (NSA) for inclusion in the Evaluated Products List (EPL).<p>

	See also: <b>Evaluated Products List (EPL)</b><p>

<p>

<p>

	<center><b>U</b></center>
<p>

<p>

<p>

<b>UPS (Uninterruptible Power Supply)</b><p>

	A system of electrical components to provide a buffer between utility power, or other power source,
and a load that requires uninterrupted, precise power.  This often includes a trickle-charge battery
system which permits a continued supply of electrical power during brief interruption (blackouts,
brownouts, surges, electrical noise, etc.) of normal power sources.<p>

<p>

<p>

	<center><b>V</b></center>
<p>

<p>

<p>

<b>Vaccine</b><p>

	Any software designed to prevent the introduction of a computer virus to a system.<p>

	See also: <b>Bacteria</b>, <b>Malicious Code</b>.<p>

<p>

<b>Verification</b><p>

	The process of comparing two levels of system specifications for proper correspondence.<p>

<p>

<b>Vital Records</b><p>

	Records designated by Category I agencies and departments as necessary to accomplish assigned
essential functions during emergency situations.  These records, identified as vital records, are
grouped into two distinct categories: 1) emergency operating records; and 2) rights and interests
records.  (Reference: TD P 71-10, V.1.III.1, 1992).<p>

	See also: <b>Emergency Operating Records, Rights and Interest Records, Category I</b>. <p>

<p>

<b>Virus</b><p>

	Code imbedded within a program that causes a copy of itself to be inserted in one or more other
programs.  In addition to propagation the virus usually performs some unwanted function.  Note that
a program need not perform malicious actions to be a virus; it need only infect other programs. <p>

	See also: <b>Bacteria</b>, <b>Malicious Code</b>.<p>

<p>

<b>Vulnerability</b><p>

	A weakness, or finding that is non-compliant, non-adherence to a requirement, a specification or a
standard, or unprotected area of an otherwise secure system, which leaves the system open to potential
attack or other problem.<p>

	<center><b>W</b></center>
<p>

<p>

<p>

<b>WAN (Wide Area Network)</b><p>

	A network of LANs which provides communication services over a geographic area larger than served
by a LAN.<p>

<p>

<b>WWW</b><p>

	See: <b>World Wide Web</b><p>

<p>

<b>World Wide Web</b><p>

	An association of independent information data bases accessible via the Internet.  Often called the
WEB, WWW, or W.<p>

<p>

<b>Worm</b><p>

	A computer program that can replicate itself and send copies from computer to computer across
network connections.  Upon arrival, the worm may be activated to replicate and propagate again.  In
addition to propagation, the worm usually performs some unwanted function.<p>

	See also:<b> Malicious Code</b>.<p>

<p>

<b>Write</b><p>

	A fundamental operation that results only in the flow of information from a subject to an object.<p>

<p>

<p>

	<center><b>X</b></center>
<p>

<p>

<p>

<center>NONE AT THIS TIME</center>
<p>

<p>

	<center><b>Y</b></center>
<p>

<p>

<center>NONE AT THIS TIME</center>
<p>

<p>

<p>

	<center><b>Z</b></center>
<p>

<p>

<center>NONE AT THIS TIME</center>
<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<center>(This Page Intentionally Left Blank)</center>
<p>

BIBLIOGRAPHY<p>

<IMG SRC="images/bar1.gif">
<p>

<p>

The following laws, regulations, standards, policies, directives, guidelines, and references are the basis for
the U.S. Customs Service AIS Security Policy Manual, HB 1400-04.<p>

<p>

Note: The following list is sorted alphabetically by <u>Reference ID</u>.<p>
<p>

<u>Reference ID	</u>	<u>Document Title</u><p>

<p>

[CHES94]				William R. Cheswick and Steven M. Bellovin.  <u>Firewalls and Internet Security</u>. 
Addison-Wesley, Reading, MA, 1994.<p>

<p>

[COHEN]				<u>Information Technology Management Reform Act of 1996</u>.  Wash.,D.C. Also
known as the "Cohen Bill."<p>

<p>

[EO 12958]				Office of the President, <u>Classified National Security Information</u>.  EO 12958,
Wash., DC, April 17, 1995, (Revoked EO 12356, 04/06/82).  9.o <p>

<p>

[FIPS P 39]				<u>Glossary for Computer Security Terms</u>.  U.S. Department of Commerce, National
Technical Information Service (NTIS), FIPS PUB 39, Springfield, VA.,
02/15/76.<p>

<p>

[GAO94285]				<u>Information Superhighway: Issues Affecting Development</u>.  GAO Report.
GAO/RCED-94-285.<p>

<p>

[GAO9523]				<u>Information Superhighway: An Overview of Technology Challenges</u>.  GAO Report.
GAO/AIMD-95-23<p>

<p>

[MISSI]		<u>MISSI Phase 1</u>.  NSA, Ft. George G.  Meade, MD., 1994.<p>

<p>

[NCSC-TG-003]			<u>A Guide to Understanding Discretionary Access Control in Trusted Systems</u>. 
NCSC, NCSC-TG-003, Ver. 1, NSA, Ft. George G. Meade, MD.,
September 1987.<p>

<p>

[NCSC-TG-005]			<u>Trusted Network Interpretation</u>.  NCSC,  NCSC-TG-005, Ver. 1, NSA, Ft. George
G. Meade, MD., July 1987.  aka. Red Book.<p>

<p>

[NCSC-TG-006]			<u>A Guide to Understanding Configuration Management in Trusted Systems</u>.  NCSC,
NCSC-TG-006, Ver. 1, NSA, Ft. George G. Meade, MD., March 1988.<p>

<p>

[NCSC-TG-025]			<u>Data Remanence in Automated Information Systems</u>.  NCSC, NCSC-TG-025, Ver.
2, NSA, Ft. George G. Meade, MD., September 1991.<p>

<p>

[NCSC-TG-027]			<u>A Guide to Understanding Information Systems Security Officer Responsibilities for
AIS</u>.  NCSC, NCSC-TG-027, Ver. 1, NSA, Ft. George G. Meade, MD.,
May 1992.<p>

<p>

[NCSC-TG-029]			<u>Introduction to Certification and Accreditation</u>.  NCSC, NCSC-TG-029, Ver. 1,
NSA, Ft. George G. Meade, MD., January 1994.<p>

<p>

[NCSC TR 79-91]			<u>Integrity in Automated Information Systems</u>.  NCSC, NCSC C TR  79-91, NSA, Ft.
George G. Meade, MD., September 1991.<p>

<p>

[NTISSP 200]				<u>National Policy on Controlled Access Protection</u>.  The White House.  National
Telecommunications and Information Systems Security Committee.
07/15/87.<p>

<p>

[NIST 500-172]			Todd, Mary Anne, and Constance Guitan, <u>Computer Security Training Guidelines</u>. 
NIST, SP 500-172, Gaithersburg, MD., 11/89.<p>

<p>

[OMB A-123]				<u>Management Accountability and Control</u>. Cir. A-123, Revised, Wash., DC, June
21,1995.<p>

<p>

[OMB A-130]				<u>Management of Federal Information Resources</u>.  OMB Cir. A-130, Wash., DC,
1985, 1993, 1994.<p>

<p>

[OMB A-130,AIII]			<u>Security of Federal Automated Information Resources</u>.  OMB Cir. A-130, Appendix
III., Wash., DC, 02/08/96.<p>

<p>

[OTA-TCT-606]	<u>		Information Security and Privacy in Network Environments</u>.  U.S. Congress.  Office
of Technical Assistance.  OTA-TCT-606.  Wash., DC: GPO, September
1994.<p>

<p>

[PL 100-235]				<u>Computer Security Act of 1987</u>.  40 USC 759, 101 STAT 1724.  PL 100-235,
Wash., DC,  01/08/88.	<p>

<p>

[TD ETHICS]				U.S. Treasury Department.  <u>Standards of Ethical Conduct for Employees of the
Executive Branch</u>.  Wash., DC, 02/03/93.<p>

<p>

[TD INTERNET]			U.S. Treasury Department. Treasury Directive.  <u>MANAGING THE INTERNET
ACCESS: Operating Policy for Bureau Telecommunications Managers and
Information Resources Management Officials within the Department of the
Treasury</u>. 4/28/95.<p>

<p>

[TD P 25-04]				U.S. Treasury Department.  <u>Privacy Act Handbook</u>.  TD P 25-04, Wash., DC,
04/91.<p>

<p>

[TD P 25-05]				U.S. Treasury Department.  <u>Freedom of Information Act Handbook</u>.  TD P 25-05,
Wash., DC, 06/93.<p>

<p>

[TD 84-01]				U.S. Treasury Department.  <u>Information Systems Development Life Cycle Manual</u>. 
TD 84-01, Wash., DC, 07/94.<p>

<p>

[TD 87-01]				U.S. Treasury Department.  <u>Information Systems Standards Program</u>.  TD 87-01,
Wash., DC, 08/23/89.<p>

<p>

[TD P 71-10]				U.S. Treasury Department.  <u>Security Manual</u>.  TD P 71-10, Wash., DC, 12/93.<p>

<p>

[TD 85-03]				U.S. Treasury Department.  <u>Risk Assessment Guidelines</u>, Volumes I &amp; II.  TD
85-03, Wash., DC, June 1990.<p>

<p>

[USCS PPP]				U.S. Customs Service.  <u>People, Processes and Partnerships: A Report on the
Customs Service for the 21st Century</u>, Wash., DC, September 1994.<p>

<p>

[USCS 96PLAN]			U.S. Customs Service. <u>Annual Plan Fiscal Year 1996.</u>. Wash., DC, 10/95.<p>

<p>

[USCS IRMPLAN]			U.S. Customs Service. <u>Strategic IRM Plan for Fiscal Years 1998-2002.</u> Wash., DC,
04/96.<p>

<p>

[USCS 1400-03]			U.S. Customs Service.  <u>Safeguarding Classified Information Handbook</u>.  USCS HB
1400-03, Wash., DC, 02/91.<p>

<p>

[USCS 1460-010]			U.S. Customs Service.  <u>Access Requirements for Customs Automated Information
Systems</u>.  USCS Directive 1460-010, Wash., DC, 09/11/92.<p>

 <p>

[USCS 4300-09]			U.S. Customs Service.  <u>Communications Security (COMSEC) Handbook</u>.  USCS
HB 4300-09, Wash., DC, 12/92. (Supersedes/rescinds USCS Directives
4350-01, 4350-02, and 4350-03, also Handbook dated 1/90).<p>

<p>

[USCS 51000-05]			U.S. Customs Service.  <u>Conduct and Employee Responsibilities</u>.  USCS Manual
Transmittal 51000-05, Wash., DC, 12/29/77.<p>

<p>

[USCS 5500-04]			U.S. Customs Service.  <u>Systems Development Life Cycle Handbook</u>.  Office of
Information Management, Springfield, VA., 1995.<p>

<p>

[USCS 5500-05]			U.S. Customs Service.  <u>Automated Information Systems Services Handbook</u>.  Office
of Information and Technology, Springfield, VA., November, 1995.<p>

<p>

[USCS 5500-07]			U.S. Customs Service.  <u>Illegal Use of ADP and Telecommunications Systems</u>. 
USCS Directive 5500-07, Wash., DC, 02/22/89.<p>

<p>

[5 USC 552]				<u>Freedom of Information and Reform Act</u> (FOIA).  5 USC 552.  Wash., DC  August
13, 1987.<p>

<p>

[5 USC 552a-74]			<u>Privacy Act of 1974</u>.  5 USC 552a, Wash., DC, 12/31/74.<p>

<p>

[5 USC 552a-87]			<u>Privacy Act of 1974, As Amended</u>.  5 USC 552a, PL 93-579,  Wash., DC, 07/14/87<p>

<p>

[18 USC 1030]				<u>Computer Fraud and Abuse Act of 1986</u>.  18 USC 1030,  PL 99-474, Wash., DC,
10/16/86.<p>

<p>

[5200.28-STD]				Department of Defense.  <u>Trusted Computer System Evaluation Criteria</u> (TCSEC). 
DoD 5200.28-STD, NIST, Gaithersburg, MD., aka. Orange Book, 1985.<p>

<p>

[WACK]				Wack, John P. and Lisa J. Carnahan.  <u>Keeping Your Site Comfortably Secure: An
Introduction to Internet Firewalls</u>.  NIST, SP 800-10, Gaithersburg, MD,
December 1994.<p>

<i>Selected Readings</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

Note: The following list is sorted alphabetically by author, title, or department.<p>

(Reference: GPO Manual of Style. March 1984).<p>

<p>

		<u>A Guide to Understanding Identification and Authentication in Trusted Systems</u>.  NCSC, NCSC-TG-017, Ver.
1, NSA, Ft. George G. Meade, MD., September 1992.<p>

<p>

		<u>A Guide to Understanding Object Reuse in Trusted Systems</u>.  NCSC, NCSC-TG-018, Ver. 1, NSA, Ft.
George G. Meade, MD., July 1992.<p>

<p>

		<u>A Guide to Understanding Security Testing and Test Documentation in Trusted Systems</u>.  NCSC,
NCSC-TG-023, Ver. 1, NSA, Ft. George G. Meade, MD., July 1993.<p>

<p>

		<u>A Guide to Understanding Trusted Distribution in Trusted Systems</u>.  NCSC, NCSC-TG-008, Ver. 1, NSA,
Ft. George G. Meade, MD., December 1988.<p>

<p>

		<u>A Guide to Understanding Trusted Recovery in Trusted Systems</u>.  NCSC, NCSC-TG-022, Ver. 1, NSA, Ft.
George G. Meade, MD., December 1991.<p>

<p>

		<u>A Guide to Writing the Security Features User's Guide for Trusted Systems</u>.  NCSC, NCSC-TG-026, Ver.
1, NSA, Ft. George G. Meade, MD., September 1991.<p>

<p>

		<u>An Introduction to Computer Security: The NIST Handbook</u>.  NIST SP 800-12, Gaithersburg, MD., March 
1995. <p>

<p>

		<u>Assessing Controlled Access Protection</u>.  NCSC, NCSC-TG-028, Ver. 1, NSA, Ft. George G. Meade,  MD.,
May 1992.<p>

<p>

		<u>Bomb Threats and Physical Security Planning</u>.  U.S. Treasury Department, Bureau of Alcohol, Tobacco, and
Firearms, ATF Publication 7550.2, Wash., DC, 07/87.<p>

<p>

		<u>Computer Matching and Privacy Act of 1974</u>.  PL 100-503, Wash., DC, 1974.<p>

<p>

		<u>Computer Matching and Privacy Protection Act of 1988</u>.  PL 100-503, Wash., D.C., 12/1988.<p>

<p>

		<u>Computer Matching and Privacy Protection Amendments of 1990</u>.  PL 101-508, Wash., DC, 11/05/90.<p>

<p>

		<u>Computer Viruses: Prevention, Detection, and Treatment</u>.  NCSC, C1 TR -001, NSA, Ft. George G. Meade,
MD., March 1990.<p>

<p>

		<u>Counterfeit Access Device and Computer Fraud and Abuse Act of 1984</u>.  PL 98-473, Chapter XXI - Access
Devices and Computers, 18 USC 2101 and 2102a, Chapter 47, Wash., DC 10/12/84.<p>

<p>

		Department of Defense.  <u>Password Management Guidelines</u>.  CSC-STD-002-85, NSA, Ft. George G. Meade,
MD., 04/12/85.<p>

<p>

		Department of Defense.  <u>Security Requirements for Automated Information Systems (AISs)</u>.  DoD Directive
5200.28, DOD, Wash., DC, March 1988.<p>

<p>

		Department of Defense.  <u>Technical Rational Behind CSC-STD-003-85: COMPUTER SECURITY
REQUIREMENTS -- Guidance for Applying the DoD Trusted Computer System Evaluation Criteria
in Specific Environments</u>.  CSC-STD-003-85, NSA, Ft. George G. Meade, MD., June 1985.<p>

<p>

<u>		Disclosure of Confidential Information Generally. Trade Secrets Act</u>.  18 USC 1905, PL 102-660, Wash.,
DC, Amended 10/28/92.<p>

<p>

		<u>Electronic Communications Privacy Act of 1986</u>.  18 USC 2510 et seq., PL 99-508, Wash., DC, 10/21/86.<p>

<p>

<u>		Escrowed Encryption Standard</u>.  U.S. Department of Commerce, National Technical Information Service
(NTIS),  FIPS PUB 185, Springfield, VA.<p>

<p>

		Everhart, Kathie, ed., <u>Computer Security Training &amp; Awareness Course Compendium</u>.  NIST, NISTIR 5495,
Gaithersburg, MD., September 1994. <p>

<p>

		<u>Executive Guide to ADP Contingency Planning</u>.  NIST, SP 500-85, Gaithersburg, MD., 1985.<p>

<p>

<u>		FBI ADPT Security Policy</u>.  Department of Justice, Federal Bureau of Investigation, Information Systems
Security Unit, National Security Division, Wash., DC, April 29, 1994.<p>

<p>

		<u>Federal Computer Systems Security Training</u>.  HR 145-6, Section 5, House of Representatives, Wash., DC<p>

<p>

<u>		Federal Information Resources Management Regulation (FIRMR)</u>.  40 CFR 201 et seq., Wash., DC. <p>

<p>

		<u>Federal Managers Financial Integrity Act of 1982</u>.  (FMFIA)  PL 97-255, H.R. 1526, 31 USC 1105, 1113,
3512, Wash., DC, September 1982.<p>

<p>

		<u>Financial Management Systems</u>.  OMB Cir. A-127 (Revised), Transmittal Memorandum No. 1, Wash., DC,
07/23/93.<p>

<p>

		<u>Glossary of Computer Security Terminology</u>.  National Security Telecommunications and Information Systems
Security Committee (NSTISSC), Published by NIST as NISTIR 4659.  Available from NTIS as PB92-112259, 1992.<p>

<p>

		<u>Guidelines for ADP Contingency Planning</u>.  U.S. Department of Commerce, National Technical Information
Service (NTIS), FIPS PUB 87, Springfield, VA., 03/81.<p>

<p>

		<u>Guidance for Preparation of Security Plans for Federal Systems that Contain Sensitive Information</u>.  OMB
Bulletin 90-08, Wash., DC, 07/09/90.<p>

<p>

		<u>Guidelines for Writing Trusted Facility Manuals</u>.  NCSC, NCSC-TG-016, Ver.1, NSA, Ft. George G.
Meade, MD., October 1992.<p>

<p>

<u>		Information Technology Installation Security</u>.  GSA.  Office of Technical Assistance.  Wash., DC: GPO,
December  1988.<p>

<p>

		<u>Integrity - Oriented Control Objectives: Proposed Revisions to the Trusted Computer System Evaluation
Criteria (TCSEC), DoD 5200.28-STD</u>.  NCSC, NCSC C TR  111-91, NSA, Ft. George G. Meade,
MD., October 1991.<p>

<p>

<u>		Issue Update On Information Security and Privacy in Network Environments</u>.  U.S. Congress.  Office of
Technical Assistance.  OTA-BP-ITC-147.  Wash., DC: GPO, June 1995.<p>

<p>

		<u>Management Accountability and Control</u>.  OMB Cir. A-123.  Wash., DC, June 21, 1995.<p>

<p>

		Office of the President, <u>National Security Information</u>.  32 CFR Part 2001, Directive No. 1, National Security
Council, Information Security Oversight Office, Wash., DC, June 1982.<p>

<p>
		Office of the President, <u>National Security Information: Standard Forms</u>.  32 CFR Part 2003, National Security
Council, Information Security Oversight Office, Wash., DC, March 1987.<p>

<p>

<u>		The Paperwork Reduction Act of 1980</u>.  As amended.  44 USC 350, et seq.,  PL 96-511. Wash., DC,
12/11/80.<p>

<p>

		<u>The Paperwork Reduction Reauthorization Act of 1986</u>.  44 USC 3506, PL 99-500 Title VIII. Wash., DC.<p>

<p>

		<u>Password Usage</u>.  U.S. Department of Commerce, National Technical Information Service (NTIS), FIPS
PUB 112, Springfield, VA., May 1985.<p>

<p>

		<u>People, Processes and Partnerships: A Report on the Customs Service for the 21st Century</u>.  U.S. Customs
Service, Wash., DC, September 1994.<p>

<p>

		<u>Performance of Commercial Activities</u>.  OMB Cir. A-76 (Revised), Transmittal Memorandum #13, Wash.,
DC, 03/02/94.<p>

<p>

		<u>Personnel Suitability</u>.  Federal Personnel Manual (FPM) Instruction 311, Chapter 31, Wash., DC, 01/06/84.<p>

<p>

		<u>Policy and Procedures Manual for Guidance of Federal Agencies -Title 2, Accounting</u>.  Government
Accounting Office, Wash., DC, August 1987.<p>

<p>

		<u>Public Key Encryption</u>.  NIST, SP 800-2, Gaithersburg, MD.<p>

<p>

		<u>Requirements for a Shared Federal Computer Back-up Facility</u>.  Office of Technical Assistance, Falls Church,
VA., May 1991.<p>

<p>

		Ruder, Brian, and J.D. Madden, <u>An Analysis of Computer Security Safeguards for Detection and Prevention
of Intentional Computer Misuse</u>.  NIST, SP 500-25, Gaithersburg, MD.<p>

<p>

		Ruthberg, Zella G. and William Nugent, <u>Overview of Computer Security Certification and Accreditation</u>. 
NIST, SP 500-109, Gaithersburg, MD., April 1984.<p>

<p>

		<u>Smart Card Technology: New Methods for Computer Access Control</u>.  NIST, SP 500-157, Gaithersburg,
MD.<p>

<p>

		<u>Training Requirement for the Computer Security Act</u>.  Office of Personnel Management (OPM), 5 CFR
PART 930, Federal Register Vol. 56, No. 233, Wash., DC, 12/04/91.<p>

<p>

		<u>Trusted Database Management System Interpretation (TDI) of the Trusted Computer System Evaluation
Criteria</u>.  NCSC,  NCSC-TG-021, Ver. 1, NSA, Ft. George G. Meade, MD., April 1991.<p>

<p>

		<u>Trusted Network Interpretation Environments Guideline</u>.  NCSC,  NCSC-TG-011, Ver. 2, NSA, Ft. George
G. Meade, MD., August 1990.<p>

<p>

		<u>Trusted Product Evaluations: A Guide for Vendors</u>.  NCSC,  NCSC-TG-002, Ver. 1, NSA, Ft. George G.
Meade, MD., June 1990.<p>

<p>

		<u>Turning Multiple Evaluation Products into Trusted Systems</u>.  NCSC, TR -003, NSA, Ft. George G. Meade,
MD., July 1994.<p>

<p>

		U.S. Customs Service.  <u>Abbreviations and Acronyms</u>.  Wash., DC, 04/92.<p>

<p>

		U.S. Customs Service.  <u>Distribution, Submission and Processing of Background Investigation (BI) Forms</u>. 
USCS Directive 099-51332-004, Wash., DC, 03/08/92.<p>

<p>

		U.S. Customs Service.  <u>Five Year Plan</u>.  Wash., DC, 12/91.<p>

<p>

		U.S. Customs Service.  <u>Information Systems Plan for Fiscal Years 1997 - 2001</u>.  Wash., DC, April 1995.<p>

<p>

		U.S. Customs Service.  <u>Personnel Security Requirements for ADP and Data Communications Contract
Employees</u>.  USCS Directive 1400-12, Wash., DC, 11/02/88.<p>

<p>

		U.S. Customs Service.  <u>Physical Security Handbook</u>.  USCS HB 1400-02, Wash., DC, 08/89.<p>

<p>

		U.S. Customs Service.  <u>Prohibition of Unauthorized Use of Electronic Mail</u>.  USCS Directive 1460-008,
Wash., DC, 11/25/91.<p>

<p>

		U.S. Customs Service.  <u>Restriction of Access to Production Data on the Customs Computer</u>.  USCS
Information Notice 92-030, Wash., DC, 06/30/92.<p>

<p>

		U.S. Customs Service.  <u>Service Level Agreement</u>.  Office of Information Management, Springfield, VA.,
09/30/92.<p>

<p>

		U.S. Customs Service.  <u>Table of Offenses and Penalties</u>.  USCS Directive 51751-01, Wash., DC, 01/09/90.<p>

<p>

		U.S. Customs Service.  <u>Unauthorized Release of Official Information</u>.  Commissioner Memorandum,
Wash., DC, 07/08/91.<p>

<p>

		U.S. Customs Service.  <u>Use of Computer Virus Protection Software</u>.  USCS Directive 1400-26, Wash., DC,
05/01/91.<p>

<p>

		U.S. Customs Service.  <u>Use of Personally-Owned Computers and Software for Classified and Sensitive Work</u>. 
USCS Directive 1460-011, Wash., DC, 03/25/93.<p>

<p>

		U.S. Treasury Department.  <u>Acquisition of Federal Information Processing Resources</u>.  TD 83-01, Wash.,
DC, 12/03/91.<p>

<p>

		U.S. Treasury Department.  <u>Disclosure of Records</u>.  31 CFR Part 1, Subpart A - Freedom of Information and
Reform Act (FOIA).  PL 99-570.  Wash., DC  August 13, 1987.<p>

<p>

		U.S. Treasury Department.  <u>Electronic Funds and Securities Transfer Policy.  Message Authentication and
Enhanced Security</u>.  TD 16-02, Wash., DC, 12/21/92.<p>

<p>

		U.S. Treasury Department.  <u>Information Systems Planning</u>.  TD 81-06, Wash., DC,  PL 99-570.  08/20/86.<p>

<p>

		U.S. Treasury Department.  <u>National Security Information</u>. Treasury Directive.  31 CFR Part 2,  Wash., DC,
2/22/89.<p>

<p>

		U.S. Treasury Department.  <u>Responsibilities for Telecommunications and Information Systems Security</u>. 
TD 85-09,  Wash., DC, 09/25/90.<p>

<p>

		<u>Viability Study for a Shared Federal Computer Back-up Facility</u>.  Office of Technical Assistance, Falls
Church, VA., November 1990.<p>

<p>

		Wack, John P., <u>Establishing Computer Security Incident Response Capability (CSIRC)</u>.  NIST, SP 800-3,
Gaithersburg, MD., 1991.<p>

<p>

		Wack, John P. and Stanley A.  Kutzban, <u>Computer Virus Attacks</u>.  Computer Systems Laboratory (CSL)
Bulletin, NIST Special, Gaithersburg, MD, August 1990.<p>

APPENDIX A<p>

<i>Abbreviations and Acronyms</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

AA			Accrediting Authority<p>

ACS			Automated Commercial System<p>

ADP			Automatic Data Processing<p>

AES			Automated Export System<p>

AIS			Automated Information Systems<p>

AISS			AIS Security Division<p>

AS			Administrative Systems<p>

BI			Background Investigation<p>

CD-ROM		Compact Disk-Read Only Memory<p>

CFR			Code of Federal Regulations<p>

CIS			Customs Issuance System<p>

CICS			Customer Information Control System<p>

COMSEC		Computer Security<p>

COTS			Commercial-Off-The-Shelf Software<p>

CM			Configuration Management<p>

CMD			Communications Management Division<p>

CSC			DoD Computer Security Center (now NCSC)<p>

DAA			Designated Accrediting Authority<p>

DAC			Discretionary Access Control<p>

DES			Data Encryption Standard<p>

DOD			Department of Defense (DoD)<p>

DODD			Department of Defense Directive<p>

DSA			Digital Signature Algorithm<p>

DSO			Designated Security Officer<p>

DSS			Digital Signature Standard<p>

EO			Executive Order<p>

FBI			Federal Bureau of Investigation<p>

FEDSIM		Federal Systems Integration and Management Center<p>

FIPS PUB		Federal Information Processing Standards Publication<p>

FOIA			Freedom of Information Act<p>

GAO			U.S. General Accounting Office<p>

GPO			U.S. Government Printing Office<p>

GSA			U.S. General Services Administration<p>

HR			House of Representatives Report<p>

HB			Handbook<p>

IBM&reg;			International Business Machines<p>

IRM			Information Resources Management<p>

IRS			Internal Revenue Service<p>
LAN			Local Area Network<p>

LOU			Limited Official Use<p>

MOU 			Memorandum of Understanding<p>

MISSI			Multilevel Information System Security Initiative<p>

NBS			National Bureau of Standards (now NIST)<p>

NCIC			National Crime Information Center<p>

NCSC			National Computer Security Center<p>

NITF 			National Information Infrastructure Task Force<p>

NIST			National Institute of Standards and Technology<p>

NSA			National Security Agency<p>

NSD			National Security Directive<p>

NSDD			National Security Decision Directive<p>

NTIS			National Technical Information Service<p>

NSTISS		National Security Telecommunications and Information Systems Security <p>

OIT			Office of Information and Technology<p>

OMB			Office of Management and Budget<p>

OPM			Office of Personnel Management<p>

OPS			Systems Operations Division<p>

ORR			Office of Regulations and Rulings<p>

OTA			Office of Technical Assistance<p>

PA			Privacy Act<p>

PAA			Principal Accrediting Authority<p>

PBX			Private Branch Exchange<p>

PC			Personal Computer<p>

PL			Public Law<p>

RAM			Random Access Memory<p>

ROM			Read Only Memory<p>

R/W			Read/Write<p>

SBU			Sensitive But Unclassified<p>

SDLC			Systems Development Life Cycle<p>

SFUG			Security Features User's Guide<p>

SP			Special Publication<p>

SPD			Security Programs Division<p>

TCB			Trusted Computer Base<p>

TCSEC		DoD Trusted Computer System Evaluation Criteria (the Orange Book)<p>

TECS			Treasury Enforcement Communication Systems<p>

TD			Treasury Directive<p>

TFM			Trusted Facility Manual<p>

UPS			Uninterruptible Power Supply<p>

USC			United States Code<p>

USCS			U.S. Customs Service<p>

WAN			Wide Area Network<p>

WWW			World Wide Web<p>

<p>

APPENDIX B<p>

<i>Good Security Practices</i><p>

<IMG SRC="images/bar1.gif">
 <p>

<b>B.1	General Computer Care and Handling</b>.<p>

<p>

The owners or operators guides for computers and components specify special precautions, care, and handling
procedures that can help avoid system failures and data loss.<p>

<p>

The following are general guidelines and recommendations:<p>

<p>

1.	Plug each power cable into a grounded (3-hole) outlet.  Use a good quality electrical surge protector,
power filter system, or uninterruptible power supply to protect the computer system from electrical
variations which can cause failures.<p>

<p>

2.	Do not connect or disconnect computer system components with the system turned on, unless the
system and components are specifically designed for that purpose.<p>

<p>

3.	Electrostatic discharge (EDS) can cause computer component failures.  Take precautions to discharge
yourself before touching the computer or attached components.  If you must work inside the
computer, wear proper EDS grounding equipment (e.g., wrist straps, etc.) and frequently touch the
unpainted metal chassis periodically to neutralize static buildup.<p>

<p>

4.	Keep strong magnetic fields away from the computer components and magnetic recording media (e.g.,
diskettes, tapes, etc.).  If audio speakers are used with the system, ensure that they are designed with
proper magnetic shielding. <p>

<p>

5.	Do not touch the surfaces of magnetic recording media (e.g., diskettes, tapes, etc.) or gold electrical
connectors (circuit card contacts or connectors).  Body oils will contaminate these surfaces and can
result in component failures.<p>

<p>

7.	Protect computer equipment and recording media (e.g. portable PCS, diskettes, CDS, etc.) from
adverse environmental conditions (e.g., extremes of temperature and humidity, corrosive gases,
liquids, dust, or other contaminants).<p>

<p>

6.	Computer components do fail.  Make appropriate back-ups of all critical data and store in a secure
area, preferably separate from the same area where the computer is kept. <p>

<p>

<b>B.2	General Security Practices<p>

</b><p>

1.	Control physical access to computer systems and limit access to only authorized persons.<p>

<p>

2.	Position computer displays such that they may not be viewed by unauthorized persons (e.g., through
windows, doors, open work areas, etc.).<p>

<p>

3.	Do not allow computer access by unauthorized persons:<p>

	Logoff active host or LAN connections whenever the terminal sessions are unattended.<p>

	Power off computer equipment when not in use.<p>

	Secure unattended terminal areas (lock the doors). <p>

<p>

4.	Identify the level of sensitivity of the data stored, processed, or used in the computer and implement
appropriate security measures.<p>

<p>

5.	For systems which use logon IDs and/or password access controls, ensure that chosen IDs and/or
passwords conform to the requirements of the specific control system where they are used. <p>

<p>

	Note: Passwords are a commonly used but easily compromised access control method.  Automated
computer penetration programs can quickly determine common words, names, or character
combinations used for logon IDs and/or passwords.  It is therefore prudent to make the ID and/or
password as complex as appropriate.	<p>

<p>

	(a)	Change default passwords as soon as practical.  Do not allow security access controls to be
operational using manufacturer or vendor supplied passwords.<p>

<p>

	(b)	Keep logon IDs confidential. Divulge IDs only on a need-to-know basis.<p>

<p>

	(c)	DO NOT SHARE PASSWORDS.  If a password must be divulged, change it as soon as
possible.<p>

 	<p>

	(d)	Generally do not write down passwords.  If it is necessary to write them down, store them
in a secure area. <p>

<p>

	(e)	Change passwords at least every 90 days (30 days is recommended) or any time they have
been, or are suspected to have been, compromised.<p>

<p>

	(f)	Do not include passwords in programs, scripts, or other files where they can be
compromised. <p>

<p>

	(g)	Recommended password patterns are:<p>

		- 6 to 8 alphanumeric characters, with at least one of each type (e.g., PQT1FYX).<p>

		- no sequentially repeated characters (e.g., 11, aa, etc.).<p>

		- no names, birthdays, commonly used identifiers (e.g., Social Security #, etc.).<p>

		- no ascending or descending digits (e.g., 1234, abcd, etc.).<p>

<p>

6.	Protect access control devices from loss or unauthorized access (e.g., lock keys, smart cards,
Fortezza cards, encryption cards/keys, security codes, etc.).<p>

<p>

	Note: Loss or compromise of encryptions codes or devices (e.g., Fortezza cards, etc.) usually
requires replacement of codes or devices at both sending and receiving locations.  This can severely
impact data availability.  <b>Protect all encryptions codes or devices.</b><p>

<p>

7.	Ensure proper control and disposal of printer ribbons, laser printer cartridges, recording media (e.g.,
diskettes, CDS, tapes, etc.), printouts, and other information storage devices which contain sensitive
data.<p>

	<p>

8.	Use adequate security controls to protect against malicious code:<p>

	Use a quality virus scanner and/or behavioral detection program.<p>

		Virus scanners only detect virus code patterns identified in the particular scanner.<p>

		Virus behavioral detection programs detect code pattern changes which are similar
to those identified in the detection program.<p>

	Virus scanners and behavioral detection programs must be current (not more than 90-180
days old) to be effective.  New virus programs are being created every month.<p>

	Any recorded media whose content is unknown or has not been scanned for known viruses,
may be a source of malicious code contamination.  Even new programs from established
manufacturers and vendors have been sources of such contamination.<p>

<p>

9.	Information stored or processed by computers, related equipment, and programs can be damaged in
numerous ways and from various causes.  It is important that all data which is considered essential
(e.g., programs, data files, etc.) be available and capable of being restored to the AIS environment,
should the original become unusable.  Back-up files should be created and maintained as appropriate. 
Security controls for the back-up files must be commensurate with the sensitivity and criticality of the
data.<p>

<p>

<b>B.3	Good Security Practices for PBX and Voice Mail Systems</b><p>

<p>

Dial-in access to sensitive AIS can be a serious security exposure if appropriate security controls are not
operational.  Most Private Branch Exchange and Voice mail systems have security features which can deter
or prevent unauthorized access.  It is important that these features be activated and enforced.  The following
recommendations are excerpts provided by American Telephone and Telegraph (ATT) to the U.S. Treasury
Office of Telecommunications Management.<p>

<p>

<b>B.3.1	PBX Security</b><p>

<p>

1.	Keep PBX attendant console rooms, telephone wiring closets, telephone equipment rooms, and Local
Exchange Company (LOC) demarcation rooms locked and secured.<p>

<p>

2.	Request positive identification from all service equipment vendors and technicians.<p>

<p>

3.	Ensure that any remote maintenance line phone number is unpublished, preferably not in the same
numbers groups, and not recorded on jacks, wallfield, distribution frame, etc.<p>

<p>

4.	Secure any reports, documentation, or other information files which may reveal the trunk access codes
or passwords.<p>

<p>

5.	Change all default passwords immediately after installation.<p>

<p>

6.	Choose passwords that are difficult, but easy to remember, and contain as many alpha
characters/digits as possible, preferably seven or more.<p>

<p>

7.	Deactivate unused  codes and features.<p>

<p>

8.	Allow only three attempts to enter a valid access code.<p>

<p>

9.	Have the PBX wait four or five rings before answering the remote access line.<p>

<p>

10.	Restrict calling privileges to individual employees.<p>

<p>

11.	Block area codes where business is not done, especially 900, 700, and 976.<p>

<p>

12.	Use the maximum authorization and Remote Access barrier code length.<p>

<p>

13.	Use security devices on all ports.<p>

<p>

<b>B.3.2	Voice Mail<p>

</b><p>

1.	Don't allow outgoing calls from a mailbox.<p>

<p>

2.	Set a minimum number of digits allowed for all passwords (preferably five or more).<p>

<p>

3.	Require  a minimum password length to be one digit longer than extension length.<p>

<p>

4.	Block access to long distance trunks or local lines.<p>

<p>

5.	Require users to frequently change passwords.<p>

<p>

6.	Limit login attempts to three or less.<p>

<p>

7.	Toll restrict lines between the voice mail system and PBX.<p>

<p>

8.	Monitor voice mail system reports daily.<p>

<p>

9.	Delete all unused voice mailboxes.<p>

<p>

10.	If outcalling is used, restrict the port to only those numbers needed using the Automatic Route
Selection partitioning.<p>

APPENDIX C<p>

<i>Controlled Access Protection (C2) Outline</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

The <u>National Policy on Controlled Access Protection</u>, issued by the White House, National
Telecommunications and Information Systems Security Committee, 07/15/87, directed that by July 15, 1992
Federal agencies must provide automated Controlled Access Protection (C2 level) for all sensitive or classified
information processed or maintained by AIS, when all users do not have the same authorization to use the
sensitive information.  [NTISSP 200]<p>

<p>

This outline highlights <u>Treasury Security Manual</u>, TD P 71-10, Chapter VI.4.B.1. on <b>Controlled Access
Protection</b> (C2 level functionality), for AIS and networks processing Sensitive But Unclassified (SBU)
Information.  Exemption to these requirements require a formal Risk Assessment and approvals.<p>

<p>

<b>Functional Requirements</b><p>

<p>

1.	<b>Controlled Access Protection (C2) must provide for the following:</b><p>

	Authentication.<p>

	Integrity.<p>

	Confidentiality.<p>

	Access Control.<p>

	Nonrepudiation.<p>

	Availability.<p>

<p>

2.	<b>Protection is accomplished through:</b><p>

	Accountability (user identification/authentication).<p>

	Audit trail for relevant events.<p>

	Control of access requests.<p>

	Automatic clearing of residual data.<p>

<p>

3.	<b>Protection is required for:</b><p>

	Mainframe systems<p>

	Networks running:<p>

		UNIX.<p>

		Multitasking multiuser Operating Systems.<p>

		Dial-up access to networks.<p>

		Networked DOS systems<p>

	Standalone Microprocessors.<p>

		If  SBU is shared among systems then interim DAC required.<p>
<p>

4.	<b>C2 level requirements include:</b><p>

	Identification based on User ID.<p>

	Authentication based on Password.<p>

	Audit based on an audit trail that includes:<p>

		Records for all events must include:<p>

			Date/time.<p>

			User ID.<p>

			Event type.<p>

			Success/failure.<p>

		Event records must be created and maintained, including:<p>

			Logon/logoff:<p>

				Origin of request (e.g., terminal ID).<p>

			Password change:<p>

				Origin of request (e.g., terminal ID).<p>

			File related events:<p>

				Name, create, delete, open, close.<p>

			Program initiation.<p>

			Actions by:<p>

				System operators.<p>

				Administrators.<p>

				Security officers.<p>

		Data access must be protected from modification by:<p>

			Limited Read access.<p>

		Reports must be:<p>

			Selective by user ID.<p>

<p>

5.	<b>Discretionary Access Control (DAC) Requirements Summary</b>:<p>

	Define/control access for:<p>

		Users.<p>

		Resources (e.g., files and programs).<p>

	Data access authorization:<p>

		User specifies access to data the own.<p>

		Unauthorized access denied.<p>

<p>

6.	<b>Data Remanence Security Requirements Summary</b>:<p>

	Magnetic media may require clearing.<p>

		Based on risk analysis.<p>

	Object Reuse:<p>

		Clearing, purging of data remanence.<p>

<p>

7.	<b>Testing Requirement:</b><p>

	Assurance testing of C2 features must be formally conducted.<p>

<p>

8.	<b>Documentation Requirements Summary:</b><p>

	Security Features User's Guide.<p>

	Trusted Facility Manual.<p>

	Test Documentation.<p>

	Design Documentation.<p>

<p>

9.	<b>Security Products Analysis must include:</b><p>

	Documented review of product requirements/recommendations:<p>

		State areas of compliance.<p>

		Identify areas of noncompliance, including:<p>

			Corrective actions.<p>

			Formal exceptions.<p>

<p>

10.	<b>Network Security Requirements:</b><p>

	Local Area Network Security (To Be Developed)<p>

		This section of the Treasury Security Manual is not available.<p>

	Dial-up Access Control.<p>

		Explicit ID, authentication, and audit trail.<p>

			If encrypted, then must comply with TD P 71-10, VI.3.A.<p>

	When SBU data is transmitted using NSA Type II encryption:<p>

		It must use the Data Encryption Standard (DES).<p>

<p>

	Note: 	Encryption is not mandatory, but can be a cost-effective risk-management consideration.<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<center>(This Page Intentionally Left Blank)</center>
<p>

<p>

<p>

<p>

<p>

<p>

APPENDIX D<p>

<i>Security Plan Format</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

<b>Security Plan Elements</b><p>

<p>

There is no fixed format for a security plan, however the plan should include the following basic elements.<p>

<p>

1.	System Identification<p>

	Responsible Organization<p>

	System Name/Title<p>

	System Category<p>

	System Operational Status<p>

	General Description/Purpose<p>

	System Environment and Special Considerations<p>

	Information Contact(s)<p>

<p>

2.	Information Sensitivity type:<p>

	Public/Unclassified<p>

	Sensitive But Unclassified<p>

		Several categories<p>

	<p>

3.	Security Measures taken:<p>

	Physical control<p>
	Hardware control<p>

	Software controls<p>

	Administrative controls<p>

	Access Control<p>

	Data protection<p>

	Communication protection<p>

	Etc.<p>

The following model is from the Customs Systems Development Life Cycle manual, CIS HB 5500-04, 1996,
and is an acceptable format guideline.<p>

<p>

<center><b>SECURITY PLAN</b></center>
<p>

<p>

Project Name:					Project Number:<p>

<p>

Date Prepared: __/__/__   Date Updated:  __/__/__   Date Presented __/__/__   Date Approved __/__/__<p>

<p>

<b>INITIATION PHASE</b><p>

<p>

<b>1.	System Identification</b> - This section contains basic identifying information about the system.<p>

<p>

	A.	Responsible Organization<p>

<p>

	B.	System Name/Title<p>

<p>

	C.	System Category - State whether it is a Major application, General support system, etc.<p>

<p>

	D.	System Operational Status - State whether it is Operational, Under development, Undergoing a major
modification or a significant security change<p>

<p>

	E.	General Description/Purpose<p>

<p>

	F.	System Environment and Special Considerations<p>

<p>

	G.	Information Contact(s)<p>

<p>

<b>DEFINITION STAGE</b><p>

<p>

<b>2.	Sensitivity of Information</b> - Identify the types of information to be processed.  For each type of
information, identify the following:<p>

<p>

	A.	Applicable Laws or Regulations<p>

<p>

	B.	Whether the integrity protection requirement is low, medium, or high<p>

<p>

	C.	Whether the availability protection required is low, medium, or high<p>

<p>

	D.	Whether the confidentiality protection required is low, medium, or high<p>

<p>

<b>DEFINITION STAGE</b><p>

<p>

<b>3.	System Security Measures</b>	- This section should describe the control measures (in place or planned) that
are intended to meet the protection requirements of the system.  The types of control measures should be
consistent with the need for protection of the system described in the previous section.<p>

<p>

	A.	Risk Assessment and Management<p>

<p>

	B.	Applicable Guidance<p>

<p>

	C.	Security Control Measures - For each control measure (categories 1-6 below), specify whether it is
inplace, planned, not applicable with "Security Control Measures - Describe the Control Measures"<p>

<p>

		1.	Management Controls - Overall management controls of the system.<p>

<p>

			a.	Assignment of Security Responsibility<p>

			b.	Risk Analysis<p>

			c.	Personnel Screening<p>

<p>

		2.	Acquisition/Development/Installation/Implementation Controls - Procedures to assure protection
is built into the system, especially during system development.<p>

<p>

			a.	Acquisition/Security Specifications<p>

			b.	Configuration Management<p>

			c.	Quality Assurance<p>

			d.	Design Review and Testing<p>

			e.	Accreditation/Certification<p>

<p>

		3.	Operational Controls - Day-to-day procedures and mechanisms to protect systems when they
become operational.<p>

<p>

			a.	Physical and Environmental Protection<p>

			b.	Production, I/O Controls<p>

			c.	Emergency, Back-up, and Contingency Planning<p>

			d.	Audit and Variance Detection<p>

			e.	Hardware and System Software Maintenance Controls<p>

			f.	Documentation<p>

			g.	Configuration Management<p>

			h.	Security Administration<p>

			i.	Database Administration<p>

<p>

		4.	Security Awareness and Training - Security awareness and training of users, technical staff, and
managers concerning the system.<p>

<p>

			a.	Security Awareness and Training Measures<p>

<p>

		5.	Technical Controls - Hardware and software controls used to provide automated and/or facilitate
manual protections.<p>

<p>

			a.	User Identification and Authentication<p>

			b.	Authorization/Access Controls<p>

			c.	Integrity/Validation Controls<p>

			d.	Audit Trails<p>

			e.	Confidentiality Controls<p>

<p>

		6.	Controls Over the Security of Applications (including controls provided by Support Systems) -<p>
			The security of each application that processes on a support system affects the security of all
others processing there.  The manager of the support system should understand the risk that each
application represents to the system.<p>

<p>

<b>4.	Additional Comments</b> - This final section is intended to provide an opportunity to include additional
comments about the security of the subject system and any perceived need for guidance or standards.<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<center>(This Page Intentionally Left Blank)</center>
<p>

APPENDIX E<p>

<i>Computer Security Training</i><p>

<IMG SRC="images/bar1.gif">
<p>

<p>

1.	<b>INTRODUCTION</b><p>

<p>

The Office of Personnel Management (OPM) has issued training regulations which implement the Computer 
Security Act of 1987 by prescribing the general procedures, scope, and manner of security training to be
provided to Federal civilian employees.<p>

<p>

2.	<b>AUTHORITY</b><p>

<p>

The Computer Security Act of 1987, PL 100-235, was enacted to improve the security and privacy of sensitive
information in Federal computer systems.  As one way of meeting that goal, the law requires that each agency
shall provide for the<b> mandatory periodic training</b> in computer security awareness and accepted computer
practices of all employees who are involved with the management, use, or operation of each computer system
within or under the supervision of the agency.<p>

<p>

The National Institute of Standards and Technology (NIST) Special Publication No. 500-172,. <i>Computer
Security Training Guidelines</i>, 11/89, sets the specific <b>guidelines</b> for development and implementation of
required awareness training and reporting.<p>

<p>

3.	<b>ORGANIZATION RESPONSIBILITIES</b><p>

	(Reference: TD P 71-10, VI.8.A, 1992).<p>

<p>

	 <b>Director, Office of Security (DOS)</b>: U.S. Treasury<p>

		-	Manage training and awareness programs.<p>

		-	Coordinate training and awareness programs.<p>

		-	Review agency training and awareness programs for compliance.<p>

<p>

	<b>Deputy Assistant Secretary, Information Systems (DASIS):</b> U.S. Treasury<p>

		-	Develop and review training and awareness guidelines.<p>

		-	Review agency training and awareness programs for compliance.<p>

<p>

<b>	Heads of Bureaus</b>:<p>

		-	Develop, fund, and implement training and awareness program.<p>

		-	Ensure contractors are trained (required contract provisions).<p>

		-	Appoint bureau official as liaison to annually (July 31) report training and awareness
program status to DOS (Treasury).<p>

		-	Annually develop, maintain, and update training and awareness program.<p>

		-	Annually report training status and plans summary to DOS.<p>

<p>

4.	<b>AWARENESS TRAINING BASIC REQUIREMENTS</b><p>

	<i>Computer Security Training Guidelines</i>, 11/89. [NIST 500-172]<p>

<p>

4.1.	<b>Objectives:</b><p>

		a.	Understand the value of information.<p>

		b.	Awareness of vulnerabilities, risks, and threats to AIS.<p>

		c.	Understanding to enable personnel to apply Federal, Treasury, and Bureau
INFOSEC/COMSEC policies, practices, and procedures.<p>

<p>

4.2.	<b>Procedures:</b><p>

		a.	New personnel within 5-days of appointment.<p>

			- Orientation on specific responsibilities.<p>

			- Managers, users, or operators using SBU data, within 60-days.<p>

		b.	Training update whenever AIS INFOSEC/COMSEC environment changes.<p>

		c.	Threat briefing and awareness refresher.  All personnel.	OMB Circular A-130, February 8, 1996 requires that security awareness training must be
periodic.  The NIST <i>Computer Security Training Guidelines</i>, 11/89 recommend annual refresher
training, but it is not a requirement. [NIST 500-172]<p>

			Examples of training:  e-Mail, newsletter, memoranda, training diskettes, videos.<p>

<p>

4.3.  <b>Content/Audience:</b><p>

		a.	Minimum content/subject matter:<p>

			- Security basics, security planning and management.<p>

			- May use in-house or commercial training.<p>

		b.	Must include bureau and contractor personnel for each content area:<p>

			- executives, operations, programming staff, and users.<p>

		c.	Training level for each specific target audience category, based on individual
responsibilities, should include:<p>

			- awareness, policy, implementation, and performance.<p>

<p>

4.4.	<b>Reporting:</b><p>

		a.	Bureau Head reports to DOS by 07/31 annually.<p>
			- Name, phone, address of agency training liaison.<p>

		b.	Prior 12 month training summary.<p>

		c.	Projected course of study for next fiscal year.<p>

			- Approximate number of jobs (billets) involved.<p>

			- Areas of study.<p>

			- Audience type (e.g., technical, management, etc.).<p>

<p>

5.	<b>COMPUTER SECURITY BASICS TOPICAL OUTLINE</b><p>

<p>

5.1.	<b>Threats and Vulnerabilities</b><p>

		- Definitions of terms<p>

		- Major threats:<p>

			- Unauthorized, accidental, or intentional;<p>

			- disclosure;<p>

			- modification;<p>

			- destruction; and<p>

			- delay.<p>

		- Impact areas.<p>

	 	- Computer abuse examples.<p>

		- Vulnerability examples.<p>

<p>

5.2.	<b>Organizational responsibilities</b><p>

		- Policy makers.<p>

		- Senior management.<p>

		- End users, programmers, or Functional managers.<p>

		- Data Processing organization.<p>

		- Information Resources Management, Security, and Audit functions.<p>

<p>

5.3.	<b>Risk management basic concepts</b><p>

		- Threat and vulnerability assessment.<p>

		- Cost/benefit analysis.<p>

		- Cost-effective controls.<p>

		- Efficiency/effectiveness of controls.<p>

<p>

5.4.	<b>Policy for protecting information</b><p>

		- Agency computer security policy.<p>

		- Employee/contractor accountability for information resources.<p>

<p>

5.5.	<b>Good security practices</b><p>

		- Physical/electronic protection of:<p>

			- physical areas (spaces);<p>

			- equipment;<p>

			- passwords;<p>

			- data files;<p>

			- against viruses, worms, etc.;<p>

			- back-up of data files;<p>

			- storage of magnetic media; and<p>

			- reporting security violations.<p>

<p>

6.	<b>BASIC LEVEL: COMPUTER SECURITY AWARENESS TRAINING</b><p>

<p>

6.1.	<b>Threats and Vulnerabilities</b><p>

		- Definitions of terms.<p>

		- Sources of threats:<p>

			- External:<p>

				- Things outside the computer systems,<p>

				- facilities,<p>

				- environment,<p>

				- physical controls, and<p>

				- physical emergencies, etc.<p>

		- Supervisor Mode:<p>

			- Things inside the computer systems:<p>

				- hardware,<p>

				- firmware, and<p>

				- operating software.<p>

		- User Mode:<p>

			- Things users interface to the computer systems:<p>

				- application software,<p>

				- user software,<p>

				- utility software, and<p>

				- communications, etc.<p>

		- Object of Threats:<p>

			- Operating System and Subsystem Integrity,<p>

			- Accounting mechanisms,<p>

			- User validation,<p>

			- Priority and process scheduling,<p>

			- Integrity of code,<p>

			- Memory access control, and<p>

			- Continuity of operations.<p>

		- Data Set Access Control:<p>

			- Read,<p>

			- Write,<p>

			- Execute,<p>

			- Append,<p>

			- Delete,<p>

			- Restrict access to specific programs, and<p>

			- Control of offline files (tape, disk, etc.).<p>

		- Major threats:<p>

			- Unauthorized, accidental, or intentional,<p>

			- disclosure,<p>

			- modification,<p>

			- destruction, and<p>

			- delay.<p>

		- Impact areas:<p>

			- Computer abuse examples, and<p>

			- Vulnerability examples.<p>

<p>

6.2.	<b>Organizational responsibilities</b><p>

		- Policy makers:<p>

			- Senior management;<p>

		- End users, programmers, or Functional managers;<p>

		- Data Processing organization; and<p>

		- Information Resources Management, Security, and Audit functions.<p>

<p>

6.3.	<b>Risk management basic concepts</b><p>

		- Threat and vulnerability assessment,<p>

		- Cost/benefit analysis,<p>

		- Cost-effective controls, and<p>

		- efficiency/effectiveness of controls.<p>

<p>

6.4.	<b>Policy for protecting information</b><p>

		- Agency computer security policy,<p>

		- Employee/contractor accountability for information resources.<p>

<p>

6.5.	<b>Good security practices</b><p>

		- Physical/electronic protection of:<p>

			- areas,<p>

			- equipment,<p>

			- passwords,<p>

			- data files,<p>

			- against viruses, worms, etc.,<p>

			- back-up of data files,<p>

			- storage of magnetic media, and<p>

			- reporting security violations.<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<center>(This Page Intentionally Left Blank)</center>
<p>

<p>

APPENDIX F<p>

<i>Security Requirements Methodology<p>

<IMG SRC="images/bar1.gif">
<p>

</i><p>

<b>SECURITY POLICY</b><p>

[TD P 71-10; USCS 96PLAN]<p>

<p>

The U.S. Treasury Department designates Customs as a Category I agency whose essential functions are
uninterruptible and critical to the continuity of the Federal government.  <p>

<p>

Customs mission includes:<p>

	(a)	Ensure that all goods and persons entering or exiting the United States do so in compliance
with all the United States laws and regulation.<p>

	(b)	Protect the public against violations which threaten the national economy and health and
safety.<p>

	(c)	Be the national resource for information on goods and persons crossing our borders.<p>

<p>

These activities provide active enforcement of U.S. laws, including the control and generation of significant
financial revenue to the U.S. Treasury.<p>

<p>

Customs general support AISs and major AIS applications that create, collect, communicate, compute,
disseminate, store, and/or control data which includes law enforcement, personal, financial, and
counternarcotics information are assigned the security category of Sensitive But Unclassified (SBU).  SBU
information must be protected in a manner functionally equivalent to the DoD classification level of C2.<p>

<p>

<b>OPERATIONAL SECURITY POLICY</b><p>

<p>

Customs operational security policy specifies the critical aspects of Customs AISs and the manner in which
regulatory policy is to be satisfied.  It includes the tradeoff decisions made between various security safeguards
and involves the functional allocation of the various security-related tasks to the elements of the AISs.  The
tradeoffs of cost, performance, and risk help determine how security will be built and implemented.  <p>

<p>

<b>ANALYSIS AND DESIGN OF AIS</b><p>

<p>

The analysis of existing AISs and the design of evolving or new ones generally proceeds from the regulating
policy(ies) to the mechanisms implementing compliance to those policies.  There are many ways to satisfy
security requirements and policy is frequently subject to change to accommodate changes in technology,
environment, political and organization structure, and regulations of various kinds.  It is therefore important
that any analysis or design consider current requirements.<p>

<p>

<p>

<b>INTERFACE POLICY</b><p>

<p>

The exchange of between AISs is based on explicit interface policy and can be thought of as an augmentation
of importing and exporting of data.  Such exchange must consider that: 1) the data sent must continue to be
protected at the owner assigned level of control, and 2) the data received must continue to be protected at the
owner assigned level of control.<p>

<p>

In most cases, Customs data must be controlled at security functional level equivalent to C2.  It is the
responsibility of the sending AIS to assure that any virtual communications channels, and/or receiving AIS,
provide appropriate protection controls.<p>

<p>

<b>TRUSTED COMPUTER BASE (TCB) POLICY</b><p>

<p>

The Trusted Computer Base (TCB) concept provides a sound method of AIS security evaluation. <p>

Evaluations of mechanisms which are shared by TCBs must be done individually to ensure consistency with
interface policy and discretionary access controls (DAC).  Each TCB must provide for a security administrator
and generate relevant audit records.<p>

<p>

Networked TCBs must be reviewed to consider the implications of failure on one of the component TCBs from
the standpoint of its impact to all of the interconnecting entities.  A means to cooperatively shut down and
recover in a secure manner must exist.<p>

<p>

<b>RISK MANAGEMENT POLICY</b><p>

<p>

A TCB which has not been assured to comply with the security considerations should be considered and treated
as a risk.  A small part of the risk management process is the risk assessment procedure.  Considering the
results of risk assessment, the risk management may require an iteration of operational policy to ensure
compliance to regulatory policy.<p>

<p>

Propagated risk results from the risk level of one AIS cascading to another interconnected AIS.  The inherent
risk of one AIS may increase the exposed risk of another AIS when interconnection does not limit related risks. 
It is possible that interconnections of AISs can result in a combined contributed risk greater than that solely
contributed by any single AIS.  The four risk factors (risk index, exposed risk, contributed risk, and solely
contributed risk) must be considered when evaluating an AIS.  [TD 85-03]<p>

<p>

In many situations the security goals can be achieved without redesign of existing AISs, also evolving and new
systems can generally add more function and capability while realizing security goals.  The risk management
approach is also a major step towards achieving the security recommended for networked AISs.<p>

APPENDIX G<p>

<i>OMB Circulars<p>

<IMG SRC="images/bar1.gif">
<p>

</i><p>

<b><center>OMB Circular No. A-123, Introduction &amp; Comments</b><p>

<p>

<b>OFFICE OF MANAGEMENT AND BUDGET</b><p>

<p>

<b>Management Accountability and Control</b><p>

</center>
<p>

<b>AGENCY</b>:  Office of Management and Budget<p>

<p>

<b>ACTION</b>:  <b>Final Revision of OMB Circular No. A-123</b><p>

-----------------------------------------------------------------<p>

<p>

<b>SUMMARY</b>:  This Notice revises Office of Management and Budget (OMB) Circular No. A-123,
"Management Accountability and Control."  The Circular, which was previously titled "Internal Control
Systems," <b>implements the Federal Managers' Financial Integrity Act of 1982 (FMFIA).</b><p>

<p>

<b>FOR FURTHER INFORMATION CONTACT</b>: Office of Management and Budget, Office of Federal
Financial Management, Management Integrity Branch, Room 6025, New Executive Office Building,
Washington, D.C. 20503,  telephone (202) 395-6911 and fax (202) 395-3952.  For a copy of the revised
Circular, contact Office of Administration, Publications Office, Room 2200, New Executive Office Building,
Washington, D.C.  20503, or telephone (202) 395-7332.  <p>

<p>

<b>ELECTRONIC ACCESS</b>:  This Circular is also accessible on the U.S. Department of Commerce's
FedWorld Network under the OMB Library of Files.  <p>

	The Telnet address for FedWorld via Internet is "fedworld.gov".  <p>

	The World Wide Web address is "http://www.fedworld.gov/ftp.htm#omb". <p>

	For file transfer protocol (FTP) access, the address is "ftp://fwux.fedworld.gov/pub/omb/omb.htm". 
<p>

The telephone number for the FedWorld help desk is (703) 487-4608. <p>

<p>

<b>SUPPLEMENTARY INFORMATION:</b><p>

<p>

<b>A.  Background</b><p>

<p>

	Circular No. A-123 was last issued on August 4, 1986.<b>  On March 13, 1995 the Office of
Management and Budget requested public comments on a revised version of the Circular (60 FR 13484)</b>.<p>

<p>

	<b>The revision announced here alters requirements for executive agencies on evaluating
management controls, consistent with recommendations made by the National Performance Review.</b> 
The Circular now integrates many policy issuances on management control into a single document, and
provides a framework for integrating management control assessments with other work now being performed
by agency managers, auditors and evaluators.<p>

<p>

	The Circular emphasizes that management controls should benefit rather than encumber management,
and should make sense for each agency's operating structure and environment.  By giving agencies the
discretion to determine which tools to use in arriving at the annual assurance statement to the President and
the Congress, the Circular represents an important step toward a streamlined management control program
that incorporates the reinvention principles of this Administration.<p>

<b><p>

B.  Analysis of Comments</b><p>

<p>

	<b>Thirty-three responses were received from 23 Federal agencies and the American Institute of
Certified Public Accountants (AICPA)</b>.  Of the 33 responses, 14 simply agreed with the proposed revision
and made no comments on the document, although some had minor comments on a proposal by the Chief
Financial Officers' Council to streamline reporting.  Almost all of the remaining 19 responses were also in
favor of the revision, but made some specific suggestions.  <p>

<p>

	A summary of the transmittal memorandum and the five sections of the Circular follows.  Each section
indicates which comments were accepted and which were not accepted.<p>

<p>

	<b><u>Transmittal Memorandum</u>.</b>  This memorandum, signed by the OMB Director, summarizes the
purpose, authority, and policy reflected in the Circular, the actions required, and related administrative
information.  Four agencies  made comments relating to the memorandum.<p>

<p>

	<i>Comments Accepted:</i>  The statement describing management accountability is now repeated in Section
I of the Circular.  The definition of management controls (which appears in both the memorandum and Section
II) has been amended to state that controls should ensure reliable "and timely" information.  The requirement
that agencies report annually on management controls is now explicitly stated in the memorandum.  In
addition, OMB has added instructions on accessing the Circular electronically.<p>

<p>

	<i>Comment Not Accepted:</i>  One agency suggested that performance appraisals be used to hold managers
accountable for management control responsibilities.  OMB supports this concept but prefers that the specific
content of appraisals be left to each agency.<p>

	<p>

	<u><b>Section I. Introduction</u></b>.  This section describes a framework for agency management control
programs that integrates management control activities with other management requirements and policies, such
as the <b>Government Performance and Results Act (GPRA), the Chief Financial Officers (CFOs) Act, the
Inspector General (IG) Act,</b> and other congressional and Executive Branch requirements.  The foundation
of this policy is that management control activities are not stand-alone management practices, but rather are
woven into the day-to-day operational responsibilities of agency managers.<p>

<p>

	Agencies are encouraged to plan for how the requirements of the Circular will be implemented. 
Agencies are also encouraged to establish senior level management councils to address management
accountability and related issues within the broad context of agency operations.<p>

<p>

	<i>Comments Accepted:</i>  At the suggestion of three agencies, the language illustrating how controls can
be integrated into the overall management process has been clarified.  The text now indicates more clearly that
the examples used to make this point are in fact examples, not new Circular requirements.  Because the Act
encompasses agency operations, as well as program and administrative areas, appropriate language has been
included in the Circular.  In addition, the Circular states that <b>24 agencies are covered by the CFOs Act</b>,
which reflects the legislation last year that made the Social Security Administration an independent agency
from the Department of Health and Human Services.<p>

<p>

	<i>Comments Not Accepted:</i>  Two agencies questioned elimination of the Management Control Plan.  The
importance of planning has not been diminished in the new Circular, but <u>OMB will no longer dictate the scope
and content of an agency's planning document</u>.  An agency may choose, for example, to meet the Circular's
planning requirement by addressing management controls in a broader strategic plan for agency management. 
<p>

<p>

	<u><b>Section II. Establishing Management Controls</u></b>.  This section defines management controls, and
requires agency managers to develop and implement appropriate management controls.  Included in this section
are general and specific management control standards, drawn in large part from the standards issued by the
General Accounting Office (GAO).  By including these standards in the Circular, OMB is continuing its efforts
to integrate various management control policies into a single document to make it easier for Federal managers
to implement good management controls.<p>

<p>

	<i>Comments Accepted:</i>  Four agencies questioned whether the definition of internal controls as a subset
of management controls should be limited to conditions "that could have a material effect on [the entity's]
financial statements."  One agency pointed out that deficiencies in internal controls related to events that have
less than a major impact on financial statements, like security weaknesses or conflict of interest problems,
could be reportable under the Integrity Act.  OMB agrees and has deleted the restrictive phrase.<p>

<p>

	In response to one agency's comment, language on developing management controls has been
expanded to emphasize that controls must be developed as programs are initially implemented, as well as
reengineered.  At another agency's suggestion, a statement has been included on the value of drawing on the
expertise of the CFO and IG as controls are developed.  <p>

<p>

	Responding to two agencies' comments on the standards for management controls, the standard on
compliance with law has been expanded to included compliance with regulations, and the standard on
delegation of authority now clearly states that managers should ensure that authority, responsibility and
accountability are defined and delegated.<p>

<p>

	<i>Comments Not Accepted:</i>  The AICPA recommended that the Circular adopt the framework and
definitions of internal controls developed by the Committee of Sponsoring Organizations of the Treadway
Commission (the COSO framework).  OMB has carefully reviewed the COSO approach and feels confident
that the Circular incorporates virtually all of the concepts underlying the COSO framework.  It is critical,
however, for the Circular to present these concepts in language that is meaningful to Federal program
managers as well as financial managers.  Therefore, OMB has decided to retain the Circular's broader
terminology.<p>

<p>

	One agency questioned OMB's authority to (i) include management control standards in the Circular
and (ii) modify the language of GAO's Standards for Internal Control.  OMB has included GAO in discussions
about the Circular's revision since the beginning of the effort, and has provided GAO with the opportunity to
comment on numerous drafts of the document.  GAO has not objected to inclusion of the standards in the
Circular, nor has GAO questioned the document's specific language.  OMB believes that the Circular
accurately incorporates the GAO standards, and appropriately updates the language to reflect developments
in this area since GAO issued its standards in 1983.<p>

<p>

	Two agencies recommended more flexibility in the standard relating to separation of duties, arguing
that the principle may be overly rigid in an era of downsizing.  One agency described the difficulty of applying
this standard in small field offices, and suggested that alternative controls based on advanced technology, such
as systems access controls and automated audit trails, may be appropriate.  While OMB believes that
separation of duties is a key management control standard, it recognizes the validity of these examples.  The
standard has not been modified because appropriate flexibility is already provided; the language states that key
duties "should" be separated among individuals.<p>

<p>

	One agency questioned whether the Circular adequately emphasizes the concept of reasonable
assurance.  OMB recognizes the importance of this concept, and believes that its inclusion as one of the
general management control standards is sufficient.  <p>

<p>

	<u><b>Section III. Assessing and Improving Management Controls</u></b>.  This section states that agency
managers should continuously monitor and improve the effectiveness of management controls.  This continuous
monitoring, and other periodic evaluations, should provide the basis for the agency head's annual assessment
of and report on management controls.  Agencies are encouraged to use a variety of information sources to
arrive at the annual assurance statement to the President and the Congress.  Several examples of sources of
information are included in this section.  The role of the agency's senior management council in making
recommendations on the annual assurance statement and on which deficiencies in management controls should
be considered material is also addressed.<p>

<p>

	<i>Comments Accepted:</i>  OMB recognizes the need to clarify how the term "<b>material weakness</b>" as used
in the Circular differs from the same term as used by Federal auditors.  This issue was raised by one agency
in its written comments, and by other parties in discussions of earlier drafts.  <b>The Circular now recognizes
that Federal auditors are required to identify and report weaknesses that, in their opinion, pose a risk
or threat to the internal control systems of an entity (such as a program or operation) even if the
management of that entity would not report the weakness outside the agency.</b><p>

<p>

	<i>Comments Not Accepted:</i>  Two agencies found the Circular's requirements on assessing and
documenting the sufficiency of management controls to be inadequate, and suggested that the Circular provide
more specific guidance in these areas.  In keeping with the philosophy behind the Circular, OMB prefers to
give agencies the latitude to expand upon the Circular's requirements in these areas, if they believe it is
necessary, rather than to impose uniform criteria for determining, for example, what should be reported as
a material weakness.  <p>

	Along those lines, <b>OMB has chosen not to adopt the definitions used by Federal auditors of a
reportable condition and material weakness, as advocated by one agency and the AICPA</b>.  Those
definitions are weighted heavily toward technical, financially-oriented terms that are probably not meaningful
to Federal program managers.  They also focus on financial statements as the primary end-product of an
internal control structure.  While financial statements are important tools for the agency head in arriving at
an assurance statement on management controls, they are not the only source of information for making this
determination.  Therefore, it is important that the Circular use language that accurately reflects the broad
nature of agency management controls.<p>

<p>

	Two agencies felt that the Circular should require that agencies test their management controls.  OMB
agrees that testing is an important method for determining whether controls actually work, and encourages
agencies to use some form of testing.  Because testing is already implicit in several of the information sources
to be used to assess controls, and is less feasible for other information sources, it is not included as a blanket
requirement.<p>

<p>

	Three agencies commented on the composition of an agency's senior management council; two felt
that the Circular should be more specific in discussing membership, while one found this section too
prescriptive.  OMB believes that the current language adequately addresses the importance of including both
line and staff management and involving the IG, without infringing on the agency's ability to determine the
council's membership.<p>

<p>

	<u><b>Section IV.  Correcting Management Control Deficiencies</u></b>.  This section states that agency
management is responsible for taking timely and effective action to correct management control deficiencies. 
Correcting these deficiencies is an integral part of management's responsibilities and must be considered a
priority by the agency.<p>

<p>

	The only comment received on this section reflected a misunderstanding of the Circular's requirements
on corrective action plans.  Plans must be developed, tracked, and reported for all material weaknesses
(weaknesses included in the Integrity Act report).  For weaknesses that are not included in the report, plans
should be developed and tracked at a level deemed appropriate by the agency. <p>

<p>

	<u><b>Section V.  Reporting on Management Controls</u></b>.  This section describes the required components
of the agency's annual Integrity Act report and its distribution to the President and the Congress. This section
also describes an initiative to streamline reporting by consolidating Integrity Act information with other
performance-related reporting into a broader "Accountability Report" to be issued annually by the agency
head.  Lastly, this section presents Integrity Act requirements as they pertain to government corporations
pursuant to the CFOs Act. <p>

<p>

	<i>Comments Accepted:</i>  <u>At the suggestion of two commenters, agencies are now encouraged to make
their Integrity Act reports available electronically</u>.  The reference to a House committee has been changed to
reflect the nomenclature of the 104th Congress.<p>

<p>

	This section also describes an new approach towards financial management reporting that could help
integrate management initiatives.  This approach is being pilot-tested by several agencies for FY 1995.  Further
information on the implications of this initiative for other agencies will be issued by OMB after the pilot reports
have been evaluated.<p>

<p>

	<i>Comments Not Accepted:</i>  One agency questioned the wisdom of permitting agencies to provide a
qualified statement of assurance.  OMB expects agencies to provide the most direct possible statement of
assurance.  The option of a qualified statement recognizes that in some cases, the most accurate statement of
assurance is one that is qualified by exceptions that are explicitly noted.  <p>

<p>

	The same agency suggested new language in the reporting section to recognize that the Circular
broadens the scope of internal control accountability beyond the requirements of the Integrity Act.  OMB
disagrees with the premise that the link between management controls and program performance is a new one. 
While the Integrity Act uses financially oriented terminology, the Act "clearly encompasses program and
administrative areas, as well as the more traditional accounting and financial management areas" (House
Report 98-937, "First-Year Implementation of the Federal Managers' Financial Integrity Act," Committee on
Government Operations, August 2, 1984, p. 1).<p>

<p>

	<b><u>General Issues</u>.</b>  Some comments were not limited to specific sections of the Circular.  <p>

<p>

	<i>Comments Accepted:</i>  In response to one agency's suggestion, <u>the acronym "FMFIA" has been
replaced throughout the Circular by the term "Integrity Act" to better emphasize the purpose and scope of the
law.</u>  OMB has also modified the term "should" in several instances where specific agency action is required.<p>

<p>

	<i>Comments Not Accepted:</i>  Two agencies proposed that the Circular broaden the linkage between
management controls and other management initiatives, particularly performance measurement and
implementation of GPRA.  OMB encourages agencies to integrate their efforts to evaluate management
controls and program performance, but is not prepared at this time to include policy guidance on performance
measurement in this Circular.<p>

<p>

	One agency proposed inclusion of language describing the applicability of the Circular to discretionary
policy matters, as had been done in the 1986 version.  OMB does not believe that this language is necessarybecause it is clear that the President and agency head have full discretion over policymaking functions,
including determining and interpreting policy, determining program need, making resource allocation
decisions, and pursuing rulemaking.  <p>

<p>

	Two agencies suggested that the Circular specifically address OMB's High Risk Program.  OMB has
chosen not to do so because implementation of the management control program outlined in the Circular will
likely eliminate the need for separate tracking of high risk areas.  If agencies report their most serious
management deficiencies to the President and the Congress as envisioned by the Circular, the Integrity Act
reports will essentially reflect the highest risk areas in government, and a separate High Risk Program may
no longer be necessary.<p>

<p>

(Signed)<p>

<p>

John B. Arthur,<p>

Associate Director for Administration<p>

<b><center>Circular No. A-123,  Revised<p>

June 21, 1995</b><p>

</center>
<p>

TO THE HEADS OF EXECUTIVE DEPARTMENTS AND ESTABLISHMENTS<p>

<p>

FROM:	Alice M. Rivlin<p>

		Director<p>

<p>

SUBJECT:	<b>Management Accountability and Control<p>

</b><p>

1.	<u>Purpose and Authority</u>.  As Federal employees develop and implement strategies for reengineering
agency programs and operations, they should design management structures that help ensure accountability
for results, and include appropriate, cost-effective controls.  This Circular provides guidance to Federal
managers on improving the accountability and effectiveness of Federal programs and operations by
establishing, assessing, correcting, and reporting on management controls.<p>

<p>

	The Circular is issued under the authority of the <b>Federal Managers' Financial Integrity Act of 1982
as codified in 31 U.S.C. 3512</b>.<p>

<p>

	<b>The Circular replaces Circular No. A-123, "Internal Control Systems," revised, dated August
4, 1986, and OMB's 1982 "Internal Controls Guidelines" and associated "Questions and Answers"
document, which are hereby rescinded.</b><p>

<p>

2.	<u>Policy</u>.  Management accountability is the expectation that managers are responsible for the quality
and timeliness of program performance, increasing productivity, controlling costs and mitigating adverse
aspects of agency operations, and assuring that programs are managed with integrity and in compliance with
applicable law.<p>

<p>

	Management controls are the organization, policies, and procedures used to reasonably ensure that
(i) programs achieve their intended results; (ii) resources are used consistent with agency mission; (iii)
programs and resources are protected from waste, fraud, and mismanagement; (iv) laws and regulations are
followed; and (v) reliable and timely information is obtained, maintained, reported and used for decision
making. <p>

<p>

3.	<u>Actions Required</u>.  Agencies and individual Federal managers must take systematic and proactive
measures to (i) develop and implement appropriate, cost-effective management controls for results-oriented
management; (ii) assess the adequacy of management controls in Federal programs and operations; (iii)
identify needed improvements; (iv) take corresponding corrective action; and (v) report annually on
management controls.<p>

<p>

4.	<u><b>Effective Date</u>.  This Circular is effective upon issuance.  <p>

</b><p>

5.	<u>Inquiries</u>.  Further information concerning this Circular may be obtained from the Management
Integrity Branch, Office of Federal Financial Management, Office of Management and Budget, Washington,
DC 20503, 202/395-6911.<p>

<p>

6.	<u>Copies</u>.  Copies of this Circular may be obtained by telephoning the Executive Office of the President,
Publication Services, at 202/395-7332.<p>

<p>

7.	<u>Electronic Access</u>.  This document is also accessible on the U.S. Department of Commerce's
<b>FedWorld</b> Network under the OMB Library of Files.  <p>
	The Telnet address for FedWorld via Internet is "fedworld.gov".  <p>

	The World Wide Web address is "http://www.fedworld.gov/ftp.htm#omb". <p>

	For file transfer protocol (FTP) access, the address is "ftp://fwux.fedworld.gov/pub/omb/omb.htm". 
<p>

The telephone number for the FedWorld help desk is 703/487-4608.  <p>

<p>

<p>

Attachment<p>

	Attachment<p>

<p>

<center><b>I.  INTRODUCTION</b></center>
<p>

<p>

The proper stewardship of Federal resources is a fundamental responsibility of agency managers and staff. 
Federal employees must ensure that government resources are used efficiently and effectively to achieve
intended program results.  Resources must be used consistent with agency mission, in compliance with law
and regulation, and with minimal potential for waste, fraud, and mismanagement.  <p>

<p>

To support results-oriented management, the <b>Government Performance and Results Act</b> (GPRA, P.L. 103-62) requires agencies to develop strategic plans, set performance goals, and report annually on actual
performance compared to goals.  As the Federal government implements this legislation, these plans and goals
should be integrated into (i) the budget process, (ii) the operational management of agencies and programs,
and (iii) accountability reporting to the public on performance results, and on the integrity, efficiency, and
effectiveness with which they are achieved. <p>

<p>

Management accountability is the expectation that managers are responsible for the quality and timeliness of
program performance, increasing productivity, controlling costs and mitigating adverse aspects of agency
operations, and assuring that programs are managed with integrity and in compliance with applicable law.<p>

<p>

Management controls -- organization, policies, and procedures -- are tools to help program and financial
managers achieve results and safeguard the integrity of their programs.  This Circular provides guidance on
using the range of tools at the disposal of agency managers to achieve desired program results and meet the
requirements of the Federal Managers' Financial Integrity Act (FMFIA, referred to as the Integrity Act
throughout this document).  <p>

<p>

<u>Framework</u>.  The importance of management controls is addressed, both explicitly and implicitly, in many
statutes and executive documents.  <b>The Federal Managers' Financial Integrity Act </b>(P.L. 97-255) establishes
specific requirements with regard to management controls.  The agency head must establish controls that
reasonably ensure that:  (i) obligations and costs comply with applicable law; (ii) assets are safeguarded against
waste, loss, unauthorized use or misappropriation; and (iii) revenues and expenditures are properly recorded
and accounted for. 31 U.S.C. 3512(c)(1).  In addition, the agency head annually must evaluate and report on
the control and financial systems that protect the integrity of Federal programs.  31 U.S.C. 3512(d)(2).  The
Act encompasses program, operational, and administrative areas as well as accounting and financial
management. <p>

<p>

Instead of considering controls as an isolated management tool, agencies should integrate their efforts to meet
the requirements of the Integrity Act with other efforts to improve effectiveness and accountability.  Thus,
management controls should be an integral part of the entire cycle of planning, budgeting, management,
accounting, and auditing.  They should support the effectiveness and the integrity of every step of the process
and provide continual feedback to management. <p>

<p>

For instance, good management controls can assure that performance measures  are complete and accurate. 
As another example, the management control standard of organization would align staff and authority with the
program responsibilities to be carried out, improving both effectiveness and accountability.  Similarly,
accountability for resources could be improved by more closely aligning budget accounts with programs andcharging them with all significant resources used to produce the program's outputs and outcomes. <p>

<p>

Meeting the requirements of the <b>Chief Financial Officers Act </b>(P.L. 101-576, as amended) should help
agencies both establish and evaluate management controls.  The Act requires the preparation and audit of
financial statements for 24 Federal agencies.  31 U.S.C. 901(b), 3515.  In this process, auditors report on
internal controls and compliance with laws and regulations.  Therefore, the agencies covered by the Act have
a clear opportunity both to improve controls over their financial activities, and to evaluate the controls that are
in place.<p>

<p>

The <b>Inspector General Act </b>(P.L. 95-452, as amended) provides for independent reviews of agency programs
and operations.  Offices of Inspectors General (OIGs) and other external audit organizations frequently cite
specific deficiencies in management controls and recommend opportunities for improvements.  Agency
managers, who are required by the Act to follow up on audit recommendations, should use these reviews to
identify and correct problems resulting from inadequate, excessive, or poorly designed controls, and to build
appropriate controls into new programs.  <p>

<p>

Federal managers must carefully consider the appropriate balance of controls in their programs and operations. 
Fulfilling requirements to eliminate regulations (<b>"Elimination of One-Half of Executive Branch Internal
Regulations</b>,"  Executive Order 12861) should reinforce to agency managers that too many controls can result
in inefficient and ineffective government, and therefore that they must ensure an appropriate balance between
too many controls and too few controls.  Managers should benefit from controls, not be encumbered by them. 
<p>

<u>Agency Implementation</u>.  Appropriate management controls should be integrated into each system established
by agency management to direct and guide its operations. A separate management control process need not
be instituted, particularly if its sole purpose is to satisfy the Integrity Act's reporting requirements.<p>

<p>

Agencies need to plan for how the requirements of this Circular will be implemented.  Developing a written
strategy for internal agency use may help ensure that appropriate action is taken throughout the year to meet
the objectives of the Integrity Act.  The absence of such a strategy may itself be a serious management control
deficiency.  <p>

<p>

Identifying and implementing the specific procedures necessary to ensure good management controls, and
determining how to evaluate the effectiveness of those controls, is left to the discretion of the agency head. 
However, agencies should implement and evaluate controls without creating unnecessary processes, consistent
with recommendations made by the National Performance Review.<p>

<p>

The President's Management Council, composed of the major agencies' chief operating officers, has been
established to foster governmentwide management changes ("Implementing Management Reform in the
Executive Branch," October 1, 1993).  Many agencies are establishing their own senior management council,
often chaired by the agency's chief operating officer, to address management accountability and related issues
within the broader context of agency operations.  Relevant issues for such a council include ensuring the
agency's commitment to an appropriate system of management controls; recommending to the agency head
which control deficiencies are sufficiently serious to report in the annual Integrity Act report; and providing
input for the level and priority of resource needs to correct these deficiencies.  (See also Section III of this
Circular.)<p>

<p>

<center><b>II.  ESTABLISHING MANAGEMENT CONTROLS</center>
<p>

</b><u><p>

Definition of Management Controls</u>.  Management controls are the organization, policies, and procedures used
by agencies to reasonably ensure that (i) programs achieve their intended results; (ii) resources are used
consistent with agency mission; (iii) programs and resources are protected from waste, fraud, and
mismanagement; (iv) laws and regulations are followed; and (v) reliable and timely information is obtained,
maintained, reported and used for decision making. <p>

<p>

Management controls, in the broadest sense, include the plan of organization, methods and procedures adopted
by management to ensure that its goals are met.  Management controls include processes for planning,
organizing, directing, and controlling program operations.  A subset of management controls are the internal
controls used to assure that there is prevention or timely detection of unauthorized acquisition, use, or
disposition of the entity's assets.  <p>

<u><p>

Developing Management Controls</u>.  As Federal employees develop and execute strategies for implementing
or reengineering agency programs and operations, they should design management structures that help ensure
accountability for results.  As part of this process, agencies and individual Federal managers must take
systematic and proactive measures to develop and implement appropriate, cost-effective management controls. 
The expertise of the agency CFO and IG can be valuable in developing appropriate controls. <p>

<p>

Management controls guarantee neither the success of agency programs, nor the absence of waste, fraud, and
mismanagement, but they are a means of managing the risk associated with Federal programs and operations. 
To help ensure that controls are appropriate and cost-effective, agencies should consider the extent and cost
of controls relative to the importance and risk associated with a given program.<p>

<p>

<u>Standards</u>.  Agency managers shall incorporate basic management controls in the strategies, plans, guidance
and procedures that govern their programs and operations.  Controls shall be consistent with the following
standards, which are drawn in large part from the "Standards for Internal Control in the Federal Government,"
issued by the General Accounting Office (GAO).<p>

<p>

General management control standards are:<p>

	<b>Compliance With Law</b>.  All program operations, obligations and costs must comply with applicable
law and regulation.  Resources should be efficiently and effectively allocated for duly authorized
purposes.<p>

<p>

	<b>Reasonable Assurance and Safeguards</b>.  Management controls must provide reasonable assurance
that assets are safeguarded against waste, loss, unauthorized use, and misappropriation.  Management
controls developed for agency programs should be logical, applicable, reasonably complete, and
effective and efficient in accomplishing management objectives.<p>

<p>

	<b>Integrity, Competence, and Attitude</b>.  Managers and employees must have personal integrity and
are obligated to support the ethics programs in their agencies.  The spirit of the Standards of Ethical
Conduct requires that they develop and implement effective management controls and maintain a level
of competence that allows them to accomplish their assigned duties.  Effective communication within
and between offices should be encouraged.<p>

<p>

Specific management control standards are:<p>

<p>

	<b>Delegation of Authority and Organization</b>.  Managers should ensure that appropriate authority,
responsibility and accountability are defined and delegated to accomplish the mission of the
organization, and that an appropriate organizational structure is established to effectively carry out
program responsibilities.  To the extent possible, controls and related decision-making authority should
be in the hands of line managers and staff. <p>

<p>

	<b>Separation of Duties and Supervision</b>.  Key duties and responsibilities in authorizing, processing,
recording, and reviewing official agency transactions should be separated among individuals. 
Managers should exercise appropriate oversight to ensure individuals do not exceed or abuse their
assigned authorities.<p>

<p>

	<b>Access to and Accountability for Resources</b>.  Access to resources and records should be limited to
authorized individuals, and accountability for the custody and use of resources should be assigned and
maintained.<p>

<p>

	<b>Recording and Documentation</b>.  Transactions should be promptly recorded, properly classified and
accounted for in order to prepare timely accounts and reliable financial and other reports.  The
documentation for transactions, management controls, and other significant events must be clear and
readily available for examination. <p>

<p>

	<b>Resolution of Audit Findings and Other Deficiencies</b>.  Managers should promptly evaluate and
determine proper actions in response to known deficiencies, reported audit and other findings, and
related recommendations.  Managers should complete, within established timeframes, all actions that
correct or otherwise resolve the appropriate matters brought to management's attention.<p>

<p>

Other policy documents may describe additional specific standards for particular functional or program
activities.  For example, OMB Circular No. A-127, "Financial Management Systems," describes government-wide requirements for financial systems.  The Federal Acquisition Regulations define requirements for agency
procurement activities.<p>

<p>

<center><b>III.  ASSESSING AND IMPROVING MANAGEMENT CONTROLS </b></center>
<p>

<p>

Agency managers should continuously monitor and improve the effectiveness of management controls
associated with their programs.  This continuous monitoring, and other periodic evaluations, should provide
the basis for the agency head's annual assessment of and report on management controls, as required by the
Integrity Act.  Agency management should determine the appropriate level of documentation needed to support
this assessment.  <p>

<p>

<u>Sources of Information</u>.  The agency head's assessment of management controls can be performed using a
variety of information sources.  Management has primary responsibility for monitoring and assessing controls,
and should use other sources as a supplement to -- not a replacement for -- its own judgment.  Sources of
information include:<p>

<p>

	Management knowledge gained from the daily operation of agency programs and systems.<p>

<p>

	Management reviews conducted (i) expressly for the purpose of assessing management controls, or
(ii) for other purposes with an assessment of management controls as a by-product of the review.  <p>

<p>

	IG and GAO reports, including audits, inspections, reviews, investigations, outcome of hotline
complaints, or other products.<p>

<p>

	Program evaluations.<p>

<p>

	Audits of financial statements conducted pursuant to the Chief Financial Officers Act, as amended,
including:  information revealed in preparing the financial statements; the auditor's reports on the
financial statements, internal controls, and compliance with laws and regulations; and any other
materials prepared relating to the statements.  <p>

<p>

	Reviews of financial systems which consider whether the requirements of OMB Circular No. A-127
are being met.<p>

<p>

	Reviews of systems and applications conducted pursuant to the Computer Security Act of 1987 (40
U.S.C. 759 note) and OMB Circular No. A-130, "Management of Federal Information Resources." <p>

<p>

	Annual performance plans and reports pursuant to the Government Performance and Results Act.<p>

<p>

	Reports and other information provided by the Congressional committees of jurisdiction.<p>

<p>

	Other reviews or reports relating to agency operations, e.g. for the Department of Health and Human
Services, quality control reviews of the Medicaid and Aid to Families with Dependent Children
programs.<p>

<p>

Use of a source of information should take into consideration whether the process included an evaluation of
management controls.  Agency management should avoid duplicating reviews which assess management
controls, and should coordinate their efforts with other evaluations to the extent practicable.  <p>

<p>
If a Federal manager determines that there is insufficient information available upon which to base an
assessment of management controls, then appropriate reviews should be conducted which will provide such
a basis. <p>

<p>

<u>Identification of Deficiencies</u>.  Agency managers and employees should identify deficiencies in management
controls from the sources of information described above.  A deficiency should be reported if it is or should
be of interest to the next level of management.  Agency employees and managers generally report deficiencies
to the next supervisory level, which allows the chain of command structure to determine the relative
importance of each deficiency.<p>

<p>

A deficiency that the agency head determines to be significant enough to be reported outside the agency (i.e.
included in the annual Integrity Act report to the President and the Congress) shall be considered a "material
weakness."This Circular's use of the term "material weakness" should not be confused with use of the same term
by government auditors to identify management control weaknesses which, in their opinion, pose a risk or
a threat to the internal control systems of an audited entity, such as a program or operation.  Auditors are
required to identify and report those types of weaknesses at any level of operation or organization, even if
the management of the audited entity would not report the weaknesses outside the agency.  This designation requires a judgment by agency managers as to the relative risk and significance
of deficiencies.  Agencies may wish to use a different term to describe less significant deficiencies, which are
reported only internally in an agency.  In identifying and assessing the relative importance of deficiencies,
particular attention should be paid to the views of the agency's IG.<p>

<p>

Agencies should carefully consider whether systemic problems exist that adversely affect management controls
across organizational or program lines.  The Chief Financial Officer, the Senior Procurement Executive, the
Senior IRM Official, and the managers of other functional offices should be involved in identifying and
ensuring correction of systemic deficiencies relating to their respective functions.<p>

<p>

Agency managers and staff should be encouraged to identify and report deficiencies, as this reflects positively
on the agency's commitment to recognizing and addressing management problems.  Failing to report a known
deficiency would reflect adversely on the agency.<p>

  <p>

<u>Role of A Senior Management Council</u>.  Many agencies have found that a senior management council is a
useful forum for assessing and monitoring deficiencies in management controls.  The membership of such
councils generally includes both line and staff management; consideration should be given to involving the IG. 
Such councils generally recommend to the agency head which deficiencies are deemed to be material to the
agency as a whole, and should therefore be included in the annual Integrity Act report to the President and the
Congress.  (Such a council need not be exclusively devoted to management control issues.)  This process will
help identify deficiencies that although minor individually, may constitute a material weakness in the aggregate. 
Such a council may also be useful in determining when sufficient action has been taken to declare that a
deficiency has been corrected.  <p>

 <p>

<center><b>IV.  CORRECTING MANAGEMENT CONTROL DEFICIENCIES</b></center>
<p>

<u><p>

</u>Agency managers are responsible for taking timely and effective action to correct deficiencies identified by
the variety of sources discussed in Section III.  Correcting deficiencies is an integral part of management
accountability and must be considered a priority by the agency.<p>

<p>

The extent to which corrective actions are tracked by the agency should be commensurate with the severity
of the deficiency.  Corrective action plans should be developed for all material weaknesses, and progress
against plans should be periodically assessed and reported to agency management.  Management should track
progress to ensure timely and effective results.  For deficiencies that are not included in the Integrity Act
report, corrective action plans should be developed and tracked internally at the appropriate level.<p>

<p>

A determination that a deficiency has been corrected should be made only when sufficient corrective actions
have been taken and the desired results achieved.  This determination should be in writing, and along with
other appropriate documentation, should be available for review by appropriate officials.  (See also role of
senior management council in Section III.)<p>

<p>

As managers consider IG and GAO audit reports in identifying and correcting management control
deficiencies, they must be mindful of the statutory requirements for audit followup included in the IG Act, as
amended.  Under this law, management has a responsibility to complete action, in a timely manner, on audit
recommendations on which agreement with the IG has been reached. 5 U.S.C. Appendix 3.  (Management
must make a decision regarding IG audit recommendations within a six month period and implementation of
management's decision should be completed within one year to the extent practicable.)  Agency managers and
the IG share responsibility for ensuring that IG Act requirements are met.<p>

<p>

<center><b>V.  REPORTING ON MANAGEMENT CONTROLS </b></center>
<p>

<p>

<u>Reporting Pursuant to Section 2</u>.  31 U.S.C. 3512(d)(2) (commonly referred to as Section 2 of the Integrity
Act) requires that annually by December 31, the head of each executive agency submit to the President and
the Congress (i) a statement on whether there is reasonable assurance that the agency's controls are achieving
their intended objectives; and (ii) a report on material weaknesses in the agency's controls.  OMB may provide
guidance on the composition of the annual report.<p>

<p>

	<u>Statement of Assurance</u>.  The statement on reasonable assurance represents the agency head's
informed judgment as to the overall adequacy and effectiveness of management controls within the
agency.  The statement must take one of the following forms:  statement of assurance; qualified
statement of assurance, considering the exceptions explicitly noted; or statement of no assurance.<p>

	In deciding on the type of assurance to provide, the agency head should consider information from
the sources described in Section III of this Circular, with input from senior program and
administrative officials and the IG.  The agency head must describe the analytical basis for the type
of assurance being provided, and the extent to which agency activities were assessed. The statement
of assurance must be signed by the agency head.<p>

<p>

	<u>Report on Material Weaknesses</u>.  The Integrity Act report must include agency plans to correct the
material weaknesses and progress against those plans.  <p>

<p>

<u>Reporting Pursuant to Section 4</u>.  31 U.S.C. 3512(d)(2)(B) (commonly referred to as Section 4 of the Integrity
Act) requires an annual statement on whether the agency's financial management systems conform with
government-wide requirements.  These<b> financial systems requirements are presented in OMB Circular
No. A-127, "Financial Management Systems," section 7</b>.  If the agency does not conform with financial
systems requirements, the statement must discuss the agency's plans for bringing its systems into compliance. 
<p>

If the agency head judges a deficiency in financial management systems and/or operations to be material when
weighed against other agency deficiencies, the issue must be included in the annual Integrity Act report in the
same manner as other material weaknesses.<p>

<p>

<u>Distribution of Integrity Act Report</u>.  The assurance statements and information related to both Sections 2 and
4 should be provided in a single Integrity Act report.  Copies of the report are to be transmitted to the
President; the President of the Senate; the Speaker of the House of Representatives; the Director of OMB; and
the Chairpersons and Ranking Members of the Senate Committee on Governmental Affairs, the House
Committee on Government Reform and Oversight, and the relevant authorizing and appropriations committees
and subcommittees.  In addition, 10 copies of the report are to be provided to OMB's Office of Federal
Financial Management, Management Integrity Branch.  Agencies are also encouraged to make their reports
available electronically.<p>

<p>

<u>Streamlined Reporting</u>.  The Government Management Reform Act (GMRA) of 1994 (P.L. 103-356) permits
OMB for fiscal years 1995 through 1997 to consolidate or adjust the frequency and due dates of certain
statutory financial management reports after consultation with the Congress.  GMRA prompted the CFO
Council to recommend to OMB a new approach towards financial management reporting which could help
integrate management initiatives.  This proposal is being pilot-tested by several agencies for FY 1995.  Further
information on the implications of this initiative for other agencies will be issued by OMB after the pilot reports
have been evaluated.  In the meantime, the reporting requirements outlined in this Circular remain valid except
for those agencies identified as pilots by OMB.<p>

<p>

Under the CFO Council approach, agencies would consolidate Integrity Act information with other
performance-related reporting into a broader "Accountability Report" to be issued annually by the agency
head. This report would be issued as soon as possible after the end of the fiscal year, but no later than March
31 for agencies producing audited financial statements and December 31 for all other agencies.  The proposed
"Accountability Report" would integrate the following information:  the Integrity Act report, management's
Report on Final Action as required by the IG Act, the CFOs Act Annual Report (including audited financial
statements), Civil Monetary Penalty and Prompt Payment Act reports, and available information on agency
performance compared to its stated goals and objectives, in preparation for implementation of the GPRA.  <p>

 <p>

<u>Government Corporations</u>.  Section 306 of the <b>Chief Financial Officers Act</b> established a reporting
requirement related to management controls for corporations covered by the <b>Government Corporation and
Control Act.  31 U.S.C. 9106.</b>  These corporations must submit an annual management report to the Congress
not later than 180 days after the end of the corporation's fiscal year.  This report must include, among other
items, a statement on control systems by the head of the management of the corporation consistent with the
requirements of the Integrity Act.  <p>

<p>

The corporation is required to provide the President, the Director of OMB, and the Comptroller General a
copy of the management report when it is submitted to Congress.<p>

<p>

<p>

<b><center>OMB Circular No. A-130, Appendix III,  Revised</b></center>
<p>

<p>

<center><b>EXECUTIVE OFFICE OF THE PRESIDENT</b></center>
<p>

<center>OFFICE OF MANAGEMENT AND BUDGET</center>
<p>

<center>WASHINGTON, D.C. 20503</center>
<p>

<p>

<center>February 8, 1996</center>
<p>

<p>

	CIRCULAR NO. A-130,  Revised<p>

	(Transmittal Memorandum No. 3)<p>

<p>

MEMORANDUM FOR HEADS OF EXECUTIVE DEPARTMENTS AND ESTABLISHMENTS<p>

<p>
SUBJECT:  Management of Federal Information Resources<p>

<p>

	Circular No. A-130 provides uniform government-wide information resources management policies
as required by the Paperwork Reduction Act of 1980, as amended by the Paperwork Reduction Act of 1995,
44 U.S.C. Chapter 35.  This Transmittal Memorandum contains updated guidance on the "Security of Federal
Automated Information Systems," Appendix III and makes minor technical revisions to the Circular to reflect
the Paperwork Reduction Act of 1995 (P.L. 104-13).<p>

<p>

<p>

<p>

				(Signed)<p>

				Alice M. Rivlin<p>

				Director<p>

<p>

Attachment<p>

<p>

<p>

February 8, 1996<p>

<p>

<b>Appendix III to OMB Circular No. A-130 - Security of Federal Automated Information Resources</b><p>

<p>

<b>A.	Requirements.</b><p>

<p>

1.	<u>Purpose</u><p>

<p>

This Appendix establishes a minimum set of controls to be included in Federal automated information security
programs; assigns Federal agency responsibilities for the security of automated information; and links agency
automated information security programs and agency management control systems established in accordance
with OMB Circular No. A-123.  The Appendix revises procedures formerly contained in Appendix III to OMB
Circular No. A-130 (50 FR 52730; December 24, 1985), and incorporates requirements of the Computer
Security Act of 1987 (P.L. 100-235) and responsibilities assigned in applicable national security directives.<p>

<p>

2.	<u>Definitions</u><p>

<p>

The term:<p>

<p>

	a.  "adequate security" means security commensurate with the risk and magnitude of the harm resulting
from the loss, misuse, or unauthorized access to or modification of information.  This includes assuring
that systems and applications used by the agency operate effectively and provide appropriate
confidentiality, integrity, and availability, through the use of cost-effective management, personnel,
operational, and technical controls.<p>

<p>

	b.  "application" means the use of information resources (information and information technology) to
satisfy a specific set of user requirements.<p>

<p>

	c.  "general support system" or "system" means an interconnected set of information resources under the
same direct management control which shares common functionality.  A system normally includes
hardware, software, information, data, applications, communications, and people.  A system can be, for
example, a local area network (LAN) including smart terminals that supports a branch office, an
agency-wide backbone, a communications network, a departmental data processing center including its
operating system and utilities, a tactical radio network, or a shared information processing service
organization (IPSO).<p>

<p>

	d.  "major application" means an application that requires special attention to security due to the risk and
magnitude of the harm resulting from the loss, misuse, or unauthorized access to or modification of the
information in the application.  Note:  All Federal applications require some level of protection.  Certain
applications, because of the information in them, however, require special management oversight and
should be treated as major.  Adequate security for other applications should be provided by security of the
systems in which they operate.<p>

<p>

3.	<u>Automated Information Security Programs</u>.  Agencies shall implement and maintain a program to assure
that adequate security is provided for all agency information collected, processed, transmitted, stored, or
disseminated in general support systems and major applications.<p>

<p>

Each agency's program shall implement policies, standards and procedures which are consistent with
government-wide policies, standards, and procedures issued by the Office of Management and Budget, the
Department of Commerce, the General Services Administration and the Office of Personnel Management
(OPM).  Different or more stringent requirements for securing national security information should be
incorporated into agency programs as required by appropriate national security directives.  At a minimum,
agency programs shall include the following controls in their general support systems and major applications:<p>

<p>

	a.  Controls for general support systems.<p>

<p>

		1)	Assign Responsibility for Security.  Assign responsibility for security in each system to an
individual knowledgeable in the information technology used in the system and in providing  security
for such technology.<p>

<p>

		2)	<u>System Security Plan</u>.  Plan for adequate security of each general support system as part of the
organization's information resources management (IRM) planning process.  The security plan shall
be consistent with guidance issued by the National Institute of Standards and Technology (NIST). 
Independent advice and comment on the security plan shall be solicited prior to the plan's
implementation.  A summary of the security plans shall be incorporated into the strategic IRM plan
required by the Paperwork Reduction Act (44 U.S.C. Chapter 35) and Section 8(b) of this circular. 
Security plans shall include:<p>

<p>

			a)	<u>Rules of the System</u>.  Establish a set of rules of behavior concerning use of, security in, and
the acceptable level of risk for, the system.  The rules shall be based on the needs of the various
users of the system.  The security required by the rules shall be only as stringent as  necessary to
provide adequate security for information in the system.  Such rules shall clearly delineate
responsibilities and expected behavior of all individuals with access to the system.  They shall also
include appropriate limits on interconnections to other systems and shall define service provision
and restoration priorities.  Finally, they shall be clear about the consequences of behavior not
consistent with the rules.<p>

<p>

			b)	<u>Training</u>.  Ensure that all individuals are appropriately trained in how to fulfill their security
responsibilities before allowing them access to the system.  Such training shall assure that
employees are versed in the rules of the system, be consistent with guidance issued by NIST and
OPM, and apprise them about available assistance and technical security products and techniques. 
Behavior consistent with the rules of the system and periodic refresher training shall be required
for continued access to the system.<p>

<p>

			c)	<u>Personnel Controls</u>.  Screen individuals who are authorized to bypass significant technical and
operational security controls of the system commensurate with the risk and magnitude of harm
they could cause.  Such screening shall occur prior to an individual being authorized to bypass
controls and periodically thereafter.<p>

<p>

			d)	<u>Incident Response Capability</u>.  Ensure that there is a capability to provide help to users when
a security incident occurs in the system and to share information concerning common
vulnerabilities and threats.  This capability shall share information with other organizations,
consistent with NIST coordination, and should assist the agency in pursuing appropriate legal
action, consistent with Department of Justice guidance.<p>

<p>

			e)	<u>Continuity of Support</u>.  Establish and periodically test the capability to continue providing
service within a system based upon the needs and priorities of the participants of the system.<p>

<p>

			f)	<u>Technical Security</u>.  Ensure that cost-effective security products and techniques are
appropriately used within the system.<p>

<p>

			g)	<u>System Interconnection</u>.  Obtain written management authorization, based upon the acceptance
of risk to the system, prior to connecting with other systems.  Where connection is authorized,
controls shall be established which are consistent with the rules of the system and in accordance
with guidance from NIST.<p>

<p>

		3)	<u>Review of Security Controls</u>.  Review the security controls in each system when significant
modifications are made to the system, but at least every three years.  The scope and frequency of the
review should be commensurate with the acceptable level of risk for the system.  Depending on the
potential risk and magnitude of harm that could occur, consider identifying a deficiency pursuant to
OMB Circular No. A-123, "Management Accountability and Control" and the Federal Managers'
Financial Integrity Act (FMFIA), if there is no assignment of security responsibility, no security plan,
or no authorization to process for a system.<p>

<p>

		4)	<u>Authorize Processing</u>.  Ensure that a management official authorizes in writing the use of each
general support system based on implementation of its security plan before beginning or  significantly
changing processing in the system.  Use of the system shall be re-authorized at least every three years.<p>

<p>

	b.	Controls for Major Applications.<p>

<p>

		1)	<u>Assign Responsibility for Security</u>.  Assign responsibility for security of each major application
to a management official knowledgeable in the nature of the information and process  supported by
the application and in the management, personnel, operational, and technical controls used to protect
it.  This official shall assure that effective security products and techniques are appropriately used in
the application and shall be contacted when a security incident occurs concerning the application.<p>

<p>

		2)	<u>Application Security Plan</u>.  Plan for the adequate security each major application, taking into
account the security of all systems in which the application will operate.  The plan shall be consistent
with guidance issued by NIST.  Advice and comment on the plan shall be solicited from the official
responsible for security in the primary system in which the application will operate prior to the plan's
implementation.  A summary of the security plans shall be incorporated into the strategic IRM plan
required by the Paperwork Reduction Act.  Application security plans shall include:<p>

<p>

			a)	<u>Application Rules</u>.  Establish a set of rules concerning use of and behavior within the
application.  The rules shall be as stringent as necessary to provide adequate security for the
application and the information in it.  Such rules shall clearly delineate responsibilities and
expected behavior of all individuals with access to the application.  In addition, the rules shall be
clear about the consequences of behavior not consistent with the rules.<p>

<p>

			b)	<u>Specialized Training</u>.  Before allowing individuals access to the application, ensure that all
individuals receive specialized training focused on their responsibilities and the application rules. 
This may be in addition to the training required for access to a system.  Such training may vary
from a notification at the time of access (e.g., for members of the public using an information
retrieval application) to formal training (e.g., for an employee that works with a high-risk
application).<p>

<p>

			c)	<u>Personnel Security</u>.  Incorporate controls such as separation of duties, least privilege and
individual accountability into the application and application rules as appropriate.  In cases where
such controls cannot adequately protect the application or information in it, screen  individuals
commensurate with the risk and magnitude of the harm they could cause.  Such screening shall
be done prior to the individuals' being authorized to access the application and periodically
thereafter.<p>

<p>

			d)	<u>Contingency Planning</u>.  Establish and periodically test the capability to perform the agency
function supported by the application in the event of failure of its automated support.<p>

<p>

			e)	<u>Technical Controls</u>.  Ensure that appropriate security controls are specified, designed into,
tested, and accepted in the application in accordance with appropriate guidance issued by NIST.<p>

<p>

			f)	<u>Information Sharing</u>.  Ensure that information shared from the application is protected
appropriately, comparable to the protection provided when information is within the  application.<p>

<p>

			g)	<u>Public Access Controls</u>.  Where an agency's application promotes or permits public access,
additional security controls shall be added to protect the integrity of the application and the
confidence the public has in the application.  Such controls shall include segregating  information
made directly accessible to the public from official agency records.<p>

<p>

		3)	<u>Review of Application Controls</u>.  Perform an independent review or audit of the security controls
in each application at least every three years.  Consider identifying a deficiency pursuant to OMB
Circular No. A-123, "Management Accountability and Control" and the Federal Managers' Financial
Integrity Act if there is no assignment of responsibility for security, no security plan, or no
authorization to process for the application.<p>

<p>

		4)	<u>Authorize Processing</u>.  Ensure that a management official authorizes in writing use of the
application by confirming that its security plan as implemented adequately secures the application. 
Results of the most recent review or audit of controls shall be a factor in management authorizations. 
The application must be authorized prior to operating and re-authorized at least every three years
thereafter.  Management authorization implies accepting the risk of each system used by the
application.<p>

<p>

4.	<u>Assignment of Responsibilities</u><p>

<p>

	a.	<u>Department of Commerce</u>.  The Secretary of Commerce shall:<p>

<p>

		1)	Develop and issue appropriate standards and guidance for the security of sensitive information in
Federal computer systems.<p>

<p>

		2)	Review and update guidelines for training in computer security awareness and accepted computer
security practice, with assistance from OPM.<p>

<p>

		3)	Provide agencies guidance for security planning to assist in their development of application and
system security plans.<p>

<p>

		4)	Provide guidance and assistance, as appropriate, to agencies concerning cost-effective controls
when interconnecting with other systems.<p>

<p>

		5)	Coordinate agency incident response activities to promote sharing of incident response information
and related vulnerabilities.<p>

<p>

		6)	Evaluate new information technologies to assess their security vulnerabilities, with technical
assistance from the Department of Defense, and apprise Federal agencies of such vulnerabilities as 
soon as they are known.<p>

<p>

	b.	<u>Department of Defense</u>.  The Secretary of Defense shall:<p>

<p>

		1)	Provide appropriate technical advice and assistance (including work products) to the Department
of Commerce.<p>

<p>

		2)	Assist the Department of Commerce in evaluating the vulnerabilities of emerging information
technologies.<p>

<p>

	c.	<u>Department of Justice</u>.  The Attorney General shall:<p>

<p>

		1)	Provide appropriate guidance to agencies on legal remedies regarding security incidents and ways
to report and work with law enforcement concerning such incidents.<p>

<p>

		2)	Pursue appropriate legal actions when security incidents occur.<p>

<p>

	d.	<u>General Services Administration</u>.  The Administrator of General Services shall:<p>

<p>

		1)	Provide guidance to agencies on addressing security considerations when acquiring automated data
processing equipment (as defined in section 111(a)(2) of the Federal Property and Administrative
Services Act of 1949, as amended).<p>

<p>

		2)	Facilitate the development of contract vehicles for agencies to use in the acquisition of
cost-effective security products and services (e.g., back-up services).<p>

<p>

		3)	Provide appropriate security services to meet the needs of Federal agencies to the extent that such
services are cost-effective.<p>

<p>

	e.	<u>Office of Personnel Management</u>.  The Director of the Office of Personnel Management shall:<p>
<p>

		1)	Assure that its regulations concerning computer security training for Federal civilian employees
are effective.<p>

<p>

		2)	Assist the Department of Commerce in updating and maintaining guidelines for training in
computer security awareness and accepted computer security practice.<p>

<p>

	f.	<u>Security Policy Board</u>.  The Security Policy Board shall coordinate the activities of the Federal
government regarding the security of information technology that processes classified information in
accordance with applicable national security directives;<p>

<p>

5.	<u>Correction of Deficiencies and Reports</u><p>

<p>

	a.	<u>Correction of Deficiencies</u>.  Agencies shall correct deficiencies which are identified through the
reviews of security for systems and major applications described above.<p>

<p>

	b.	<u>Reports on Deficiencies</u>.  In accordance with OMB Circular No. A-123, "Management Accountability
and Control", if a deficiency in controls is judged by the agency head to be material when weighed against
other agency deficiencies, it shall be included in the annual FMFIA report.  Less significant deficiencies
shall be reported and progress on corrective actions tracked at the appropriate agency level.<p>

<p>

	c.	<u>Summaries of Security Plans</u>.  Agencies shall include a summary of their system security plans and
major application plans in the strategic plan required by the Paperwork Reduction Act (44 U.S.C. 3506).<p>

<p>

<b>B.	Descriptive Information.</b><p>

<p>

The following descriptive language is explanatory.  It is included to assist in understanding the requirements
of the Appendix.<p>

<p>

The Appendix re-orients the Federal computer security program to better respond to a rapidly changing
technological environment.  It establishes government-wide responsibilities for Federal computer security and
requires Federal agencies to adopt a minimum set of management controls.  These management controls are
directed at individual information technology users in order to reflect the distributed nature of today's
technology.<p>

<p>

For security to be most effective, the controls must be part of day-to-day operations.  This is best accomplished
by planning for security not as a separate activity, but as an integral part of overall planning.<p>

<p>

"Adequate security" is defined as "security commensurate with the risk and magnitude of harm resulting from
the loss, misuse, or unauthorized access to or modification of information."  This definition explicitly
emphasizes the risk-based policy for cost-effective security established by the Computer Security Act.<p>

<p>

The Appendix no longer requires the preparation of formal risk analyses.  In the past, substantial resources
have been expended doing complex analyses of specific risks to systems, with limited tangible benefit in terms
of improved security for the systems.  Rather than continue to try to precisely measure risk, security efforts
are better served by generally assessing risks and taking actions to manage them.  While formal risk analyses
need not be performed, the need to determine adequate security will require that a risk-based approach be
used.  This risk assessment approach should include a consideration of the major factors in risk management:
the value of the system or application, threats, vulnerabilities, and the effectiveness of current or proposed
safeguards.  Additional guidance on effective risk assessment is available in "An Introduction to Computer
Security:  The NIST Handbook" (March 16, 1995).<p>

<p>

<u>Discussion of the Appendix's Major Provisions</u>.  The following discussion is provided to aid reviewers in
understanding the changes in emphasis in the Appendix.<p>

<p>

<u>Automated Information Security Programs</u>.  Agencies are required to establish controls to assure adequate
security for all information processed, transmitted, or stored in Federal automated information systems.  This
Appendix emphasizes management controls affecting individual users of information technology.  Technical
and operational controls support management controls. To be effective, all must interrelate.  For example,
authentication of individual users is an important management control, for which password protection is a
technical control.  However, password protection will only be effective if both a strong technology is
employed, and it is managed to assure that it is used correctly.<p>

<p>

Four controls are set forth: assigning responsibility for security, security planning, periodic review of security
controls, and management authorization.  The Appendix requires that these management controls be applied
in two areas of management responsibility: one for general support systems and one for major applications.<p>

<p>

The terms "general support system" and "major application" were used in OMB Bulletins Nos. 88-16 and
90-08.  A general support system is "an interconnected set of information resources under the same direct
management control which shares common functionality."  Such a system can be, for example, a local area
network (LAN) including smart terminals that supports a branch office, an agency-wide backbone, a
communications network, a departmental data processing center including its operating system and utilities,
a tactical radio network, or a shared information processing service organization.  Normally, the purpose of
a general support system is to provide processing or communications support.<p>

<p>

A major application is a use of information and information technology to satisfy a specific set of user
requirements that requires special management attention to security due to the risk and magnitude of harm
resulting from the loss, misuse or unauthorized access to or modification of the information in the application. 
All applications require some level of security, and adequate security for most of them should be provided by
security of the general support systems in which they operate.  However, certain applications, because of the
nature of the information in them, require special management oversight and should be treated as major. 
Agencies are expected to exercise management judgement in determining which of their applications are
major.<p>

<p>

The focus of OMB Bulletins Nos. 88-16 and 90-08 was on identifying and securing both general support
systems and applications which contained sensitive information.  The Appendix requires the establishment of
security controls in all general support systems, under the presumption that all contain some sensitive
information, and focuses extra security controls on a limited number of particularly high-risk or major
applications.<p>

<p>

a.	<u>General Support Systems</u>.  The following controls are required in all general support systems:<p>

<p>

	1)	<u>Assign Responsibility for Security</u>.  For each system, an individual should be a focal point for assuring
there is adequate security within the system, including ways to prevent, detect, and recover from security
problems.  That responsibility should be assigned in writing to an individual trained in the technology used
in the system and in providing security for such technology, including the management of security controls
such as user identification and authentication.<p>

<p>

	2)	<u>Security Plan</u>.  The Computer Security Act requires that security plans be developed for all Federal
computer systems that contain sensitive information.  Given the expansion of distributed processing since
passage of the Act, the presumption in the Appendix is that all February 8, 1996 general support systems
contain some sensitive information which requires protection to assure its integrity, availability, or
confidentiality, and therefore all systems require security plans.<p>

<p>

	Previous guidance on security planning was contained in OMB Bulletin No. 90-08.  This Appendix
supersedes OMB Bulletin 90-08 and expands the coverage of security plans from Bulletin 90-08 to include
rules of individual behavior as well as technical security.  Consistent with OMB Bulletin 90-08, the
Appendix directs NIST to update and expand security planning guidance and issue it as a Federal
Information Processing Standard (FIPS).  In the interim, agencies should continue to use the Appendix of
OMB Bulletin No. 90-08 as guidance for the technical portion of their security plans.<p>

<p>

	The Appendix continues the requirement that independent advice and comment on the security plan for
each system be sought.  The intent of this requirement is to improve the plans, foster communication
between managers of different systems, and promote the sharing of security expertise.<p>

<p>

	This Appendix also continues the requirement from the Computer Security Act that summaries of security
plans be included in agency strategic information resources management plans.  OMB will provide
additional guidance about the contents of those strategic plans, pursuant to the Paperwork Reduction Act
of 1995.<p>

<p>

	The following specific security controls should be included in the security plan for a general support
system:<p>

<p>

		a)	<u>Rules</u>.  An important new requirement for security plans is the establishment of a set of rules of
behavior for individual users of each general support system.  These rules should clearly delineate
responsibilities of and expectations for all individuals with access to the system.  They should be
consistent with system-specific policy as described in "An Introduction to Computer Security:  The
NIST Handbook" (March 16, 1995).  In addition, they should state the consequences of
non-compliance.  The rules should be in writing and will form the basis for security awareness and
training.<p>

<p>

		The development of rules for a system must take into consideration the needs of all parties who use
the system.  Rules should be as stringent as necessary to provide adequate security.  Therefore, the
acceptable level of risk for the system must be established and should form the basis for determining
the rules.<p>

<p>

		Rules should cover such matters as work at home, dial-in access, connection to the Internet, use of
copyrighted works, unofficial use of government equipment, the assignment and limitation of system
privileges, and individual accountability.  Often rules should reflect technical security controls in the
system.  For example, rules regarding password use should be consistent with technical password
features in the system.  Rules may be enforced through administrative sanctions specifically related
to the system (e.g. loss of system privileges) or through more general sanctions as are imposed for
violating other rules of conduct.  In addition, the rules should specifically address restoration of service
as a concern of all users of the system.<p>

<p>

		b)	<u>Training</u>.  The Computer Security Act requires Federal agencies to provide for the mandatory
periodic training in computer security awareness and accepted computer security practice of all
employees who are involved with the management, use or operation of a Federal computer system
within or under the supervision of the Federal agency.  This includes contractors as well as employees
of the agency.  Access provided to members of the public should be constrained by controls in the
applications through which access is allowed, and training should be within the context of those
controls.  The Appendix enforces such mandatory training by requiring its completion prior to granting
access to the system.  Each new user of a general support system in some sense introduces a risk to
all other users. Therefore, each user should be versed in acceptable behavior -- the rules of the system
-- before being allowed to use the system.  Training should also inform the individual how to get help
in the event of difficulty with using or security of the system.<p>

<p>

		Training should be tailored to what a user needs to know to use the system securely, given the nature
of that use.  Training may be presented in stages, for example as more access is granted.  In some
cases, the training should be in the form of classroom instruction.  In other cases, interactive computer
sessions or well-written and understandable brochures may be sufficient, depending on the risk and
magnitude of harm.<p>

<p>

		Over time, attention to security tends to dissipate.  In addition, changes to a system may necessitate
a change in the rules or user procedures.  Therefore, individuals should periodically have refresher
training to assure that they continue to understand and abide by the applicable rules.<p>

<p>

		To assist agencies, the Appendix requires NIST, with assistance from the Office of Personnel
Management (OPM), to update its existing guidance.  It also proposes that OPM assure that its rules
for computer security training for Federal civilian employees are effective.<p>

<p>

		c)	<u>Personnel Controls</u>.  It has long been recognized that the greatest harm has come from authorized
individuals engaged in improper activities, whether intentional or accidental.  In every general support
system, a number of technical, operational, and management controls are used to prevent and detect
harm.  Such controls include individual accountability, "least privilege," and separation of duties.<p>

<p>

		Individual accountability consists of holding someone responsible for his or her actions.  In a general
support system, accountability is normally accomplished by identifying and authenticating users of the
system and subsequently tracing actions on the system to the user who initiated them.  This may be
done, for example, by looking for patterns of behavior by users.<p>

<p>

		Least privilege is the practice of restricting a user's access (to data files, to processing capability, or
to peripherals) or type of access (read, write, execute, delete) to the minimum necessary to perform
his or her job.<p>

<p>

		Separation of duties is the practice of dividing the steps in a critical function among different
individuals.  For example, one system programmer can create a critical piece of operating system
code, while another authorizes its implementation.  Such a control keeps a single individual from
subverting a critical process.  <p>

<p>

		Nevertheless, in some instances, individuals may be given the ability to bypass some significant
technical and operational controls in order to perform system administration and maintenance functions
(e.g., LAN administrators or systems programmers).<p>

<p>

		Screening such individuals in positions of trust will supplement technical, operational, and management
controls, particularly where the risk and magnitude of harm is high.<p>

<p>

		d)	<u>Incident Response Capability</u>.  Security incidents, whether caused by viruses, hackers, or software
bugs, are becoming more common.  When faced with a security incident, an agency should be able
to respond in a manner that both protects its own information and helps to protect the information of
others who might be affected by the incident.  To address this concern, agencies should establish
formal incident response mechanisms.  Awareness and training for individuals with access to the
system should include how to use the system's incident response capability.<p>

<p>

		To be fully effective, incident handling must also include sharing information concerning common
vulnerabilities and threats with those in other systems and other agencies.  The Appendix directs
agencies to effectuate such sharing, and tasks NIST to coordinate those agency activities
government-wide.<p>

<p>

		The Appendix also directs the Department of Justice to provide appropriate guidance on pursuing legal
remedies in the case of serious incidents.<p>

<p>

		e)	<u>Continuity of Support</u>.  Inevitably, there will be service interruptions.  Agency plans should assure
that there is an ability to recover and provide service sufficient to meet the minimal needs of users of
the system.  Manual procedures are generally NOT a viable back-up option.  When automated support
is not available, many functions of the organization will effectively cease.  Therefore, it is important
to take cost-effective steps to manage any disruption of service.  <p>

<p>

		Decisions on the level of service needed at any particular time and on priorities in service restoration
should be made in consultation with the users of the system and incorporated in the system rules. 
Experience has shown that recovery plans that are periodically tested are substantially more viable than
those that are not.  Moreover, untested plans may actually create a false sense of security.<p>

<p>

		f)	<u>Technical Security</u>.  Agencies should assure that each system appropriately uses effective security
products and techniques, consistent with standards and guidance from NIST.  Often such techniques
will correspond with system rules of behavior, such as in the proper use of password protection.<p>

<p>

		The Appendix directs NIST to continue to issue computer security guidance to assist agencies in
planning for and using technical security products and techniques.  Until such guidance is issued,
however, the planning guidance included in OMB Bulletin 90-08 can assist in determining techniques
for effective security in a system and in addressing technical controls in the security plan.<p>

<p>

		g)	<u>System Interconnection</u>.  In order for a community to effectively manage risk, it must control
access to and from other systems.  The degree of such control should be established in the rules of the
system and all participants should be made aware of any limitations on outside access.  Technical
controls to accomplish this should be put in place in accordance with guidance issued by NIST.<p>

<p>

		There are varying degrees of how connected a system is.  For example, some systems will choose to
isolate themselves, others will restrict access such as allowing only e-mail connections or remote
access only with sophisticated authentication, and others will be fully open.  The management decision
to interconnect should be based on the availability and use of technical and non- technical safeguards
and consistent with the acceptable level of risk defined in the system rules.<p>

<p>

	3)	<u>Review of Security Controls</u>.  The security of a system will degrade over time, as the technology
evolves and as people and procedures change.  Reviews should assure that management, operational,
personnel, and technical controls are functioning effectively.  Security controls may be reviewed by an
independent audit or a self review.  The type and rigor of review or audit should be commensurate with
the acceptable level of risk that is established in the rules for the system and the likelihood of learning
useful information to improve security.<p>

<p>

	Technical tools such as virus scanners, vulnerability assessment products (which look for known security
problems, configuration errors, and the installation of the latest patches), and penetration testing can assist
in the on-going review of different facets of systems.  However, these tools are no substitute for a formal
management review at least every three years.  Indeed, for some high-risk systems with rapidly changing
technology, three years will be too long.<p>

<p>

	Depending upon the risk and magnitude of harm that could result, weaknesses identified during the review
of security controls should be reported as deficiencies in accordance with OMB Circular No. A-123,
"Management Accountability and Control" and the Federal Managers' Financial Integrity Act.  In
particular, if a basic management control such as assignment of responsibility, a workable security plan,
or management authorization are missing, then consideration should be given to identifying a deficiency. <p>

<p>

	4)	<u>Authorize Processing</u>.  The authorization of a system to process information, granted by a management
official, provides an important quality control (some agencies refer to this authorization as accreditation). 
By authorizing processing in a system, a manager accepts the risk associated with it.  Authorization is not
a decision that should be made by the security staff.  <p>

<p>

	Both the security official and the authorizing management official have security responsibilities.  In
general, the security official is closer to the day-to-day operation of the system and will direct or perform
security tasks.  The authorizing official will normally have general responsibility for the organization
supported by the system.<p>

<p>

	Management authorization should be based on an assessment of management, operational, and technical
controls.  Since the security plan establishes the security controls, it should form the basis for the
authorization, supplemented by more specific studies as needed.  In addition, the periodic review of
controls should also contribute to future authorizations.  Some agencies perform "certification reviews"
of their systems periodically.  These formal technical evaluations lead to a management accreditation, or
"authorization to process."  Such certifications (such as those using the methodology in FIPS Pub 102
"Guideline for Computer Security Certification and Accreditation") can provide useful information to
assist management in authorizing a system, particularly when combined with a review of the broad
behavioral controls envisioned in the security plan required by the Appendix.<p>

<p>

	Re-authorization should occur prior to a significant change in processing, but at least every three years. 
It should be done more often where there is a high risk and potential magnitude of harm.<p>

<p>

b.	<u>Controls in Major Applications</u>.  Certain applications require special management attention due to the risk
and magnitude of harm that could occur.  For such applications, the controls of the support system(s) in which
they operate are likely to be insufficient.  Therefore, additional controls specific to the application are
required.  Since the function of applications is the direct manipulation and use of information, controls for
securing applications should emphasize protection of information and the way it is manipulated.<p>

<p>

	1)	<u>Assign Responsibility for Security</u>.  By definition, major applications are high risk and require special
management attention.  Major applications usually support a single agency function and often are supported
by more than one general support system.  It is important, therefore, that an individual be assigned
responsibility in writing to assure that the particular application has adequate security.  To be effective,
this individual should be knowledgeable in the information and process supported by the application and
in the management, personnel, operational, and technical controls used to protect the application.<p>

<p>

	2)	<u>Application Security Plans</u>.  Security for each major application should be addressed by a security plan
specific to the application.  The plan should include controls specific to protecting information and should
be developed from the application manager's perspective.  To assist in assuring its viability, the plan
should be provided to the manager of the primary support system which the application uses for advice
and comment.  This recognizes the critical dependence of the security of major applications on the
underlying support systems they use.  Summaries of application security plans should be included in
strategic information resource management plans in accordance with this Circular.<p>

<p>

		a)	<u>Application Rules</u>.  Rules of behavior should be established which delineate the responsibilities and
expected behavior of all individuals with access to the application.  The rules should state the
consequences of inconsistent behavior.  Often the rules will be associated with technical controls
implemented in the application.  Such rules should include, for example, limitations on changing data,
searching databases, or divulging information.  <p>

<p>

		b)	<u>Specialized Training</u>.  Training is required for all individuals given access to the application,
including members of the public.  It should vary depending on the type of access allowed and the risk
that access represents to the security of the application and information in it.  This training will be in
addition to that required for access to a support system.<p>

<p>

		c)	<u>Personnel Security</u>.  For most major applications, management controls such as individual
accountability requirements, separation of duties enforced by access controls, or limitations on the
processing privileges of individuals, are generally more cost-effective personnel security controls than
background screening.  Such controls should be implemented as both technical controls and as
application rules.  For example, technical controls to ensure individual accountability, such as looking
for patterns of user behavior, are most effective if users are aware that there is such a technical
control.  If adequate audit or access controls (through both technical and non-technical methods)
cannot be established, then it may be cost-effective to screen personnel, commensurate with the risk
and magnitude of harm they could cause.  The change in emphasis on screening in the Appendix
should not affect background screening deemed necessary because of other duties that an individual
may perform.<p>

<p>

		d)	<u>Contingency Planning</u>.  Normally the Federal mission supported by a major application is critically
dependent on the application.  Manual processing is generally NOT a viable back-up option. 
Managers should plan for how they will perform their mission and/or recover from the loss of existing
application support, whether the loss is due to the inability of the application to function or a general
support system failure.  Experience has demonstrated that testing a contingency plan significantly
improves its viability.  Indeed, untested plans or plans not tested for a long period of time may create
a false sense of ability to recover in a timely manner.<p>

<p>

		e)	<u>Technical Controls</u>.  Technical security controls, for example tests to filter invalid entries, should
be built into each application.  Often these controls will correspond with the rules of behavior for the
application.  Under the previous Appendix, application security was focused on the process by which
sensitive, custom applications were developed.  While that process is not addressed in detail in this
Appendix, it remains an effective method for assuring that security controls are built into applications. 
Additionally, the technical security controls defined in OMB Bulletin No. 90-08 will continue, until
that guidance is replaced by NIST's security planning guidance.<p>

<p>

		f)	<u>Information Sharing</u>.  Assure that information which is shared with Federal organizations, State
and local governments, and the private sector is appropriately protected comparable to the protection
provided when the information is within the application.  Controls on the information may stay the
same or vary when the information is shared with another entity.  For example, the primary user of
the information may require a high level of availability while the secondary user does not, and can
therefore relax some of the controls designed to maintain the availability of the information.  At the
same time, however, the information shared may require a level of confidentiality that should be
extended to the secondary user.  This normally requires notification and agreement to protect the
information prior to its being shared.<p>

<p>

		g)	<u>Public Access Controls</u>.  Permitting public access to a Federal application is an important method
of improving information exchange with the public.  At the same time, it introduces risks to the
Federal application.  To mitigate these risks, additional controls should be in place as appropriate. 
These controls are in addition to controls such as "firewalls" that are put in place for security of the
general support system.<p>

<p>

		In general, it is more difficult to apply conventional controls to public access systems, because many
of the users of the system may not be subject to individual accountability policies.  In addition, public
access systems may be a target for mischief because of their higher visibility and published access
methods.<p>

<p>

		Official records need to be protected against loss or alteration.  Official records in electronic form are
particularly susceptible since they can be relatively easy to change or destroy.  Therefore, official
records should be segregated from information made directly accessible to the public.  There are
different ways to segregate records.  Some agencies and organizations are creating dedicated
information dissemination systems (such as bulletin boards or World Wide Web servers) to support
this function.  These systems can be on the outside of secure gateways which protect internal agency
records from outside access.  <p>

<p>

		In order to secure applications that allow direct public access, conventional techniques such as least
privilege (limiting the processing capability as well as access to data) and integrity assurances (such
as checking for viruses, clearly labeling the age of data, or periodically spot checking data) should also
be used.  Additional guidance on securing public access systems is available from NIST Computer
Systems Laboratory Bulletin "Security Issues in Public Access Systems" (May, 1993).<p>

<p>

	3)	<u>Review of Application Controls</u>.  At least every three years, an independent review or audit of the
security controls for each major application should be performed.  Because of the higher risk involved in
major applications, the review or audit should be independent of the manager responsible for the
application.  Such reviews should verify that responsibility for the security of the application has been
assigned, that a viable security plan for the application is in place, and that a manager has authorized the
processing of the application.  A deficiency in any of these controls should be considered a deficiency
pursuant to the Federal Manager's Financial Integrity Act and OMB Circular No. A-123, "Management
Accountability and Control."<p>

<p>

	The review envisioned here is different from the system test and certification process required in the
current Appendix.  That process, however, remains useful for assuring that technical security features are
built into custom-developed software applications.  While the controls in that process are not specifically
called for in this Appendix, they remain in Bulletin No. 90-08, and are recommended in appropriate
circumstances as technical controls.<p>

<p>

	4)	<u>Authorize Processing</u>.  A major application should be authorized by the management official
responsible for the function supported by the application at least every three years, but more often where
the risk and magnitude of harm is high.  The intent of this requirement is to assure that the senior official
whose mission will be adversely affected by security weaknesses in the application periodically assesses
and accepts the risk of operating the application.  The authorization should be based on the application
security plan and any review(s) performed on the application.  It should also take into account the risks
from the general support systems used by the application.<p>

<p>

4.	<u>Assignment of Responsibilities</u>.  The Appendix assigns government-wide responsibilities to agencies that
are consistent with their missions and the Computer Security Act.<p>

<p>

	a.	<u>Department of Commerce</u>.  The Department of Commerce, through NIST, is assigned the following
responsibilities consistent with the Computer Security Act.<p>

<p>

		1)	Develop and issue security standards and guidance.<p>

<p>

		2)	Review and update, with assistance from OPM, the guidelines for security training issued in 1988
pursuant to the Computer Security Act to assure they are effective.<p>

<p>

		3)	Replace and update the technical planning guidance in the appendix to OMB Bulletin 90-08  This
should include guidance on effective risk-based security absent a formal risk analysis.<p>

<p>

		4)	Provide agencies with guidance and assistance concerning effective controls for systems when
interconnecting with other systems, including the Internet.  Such guidance on, for example, so-called
"firewalls" is becoming widely available and is critical to agencies as they consider how to
interconnect their communications capabilities.<p>

<p>

		5)	Coordinate agency incident response activities. Coordination of agency incident response activities
should address both threats and vulnerabilities as well as improve the ability of the Federal government
for rapid and effective cooperation in response to serious security breaches. <p>

<p>

		6)	Assess security vulnerabilities in new information technologies and apprise Federal agencies of
such vulnerabilities.  The intent of this new requirement is to help agencies understand the security
implications of technology before they purchase and field it.  In the past, there have been too many
instances where agencies have acquired and implemented technology, then found out about
vulnerabilities in the technology and had to retrofit security measures.  This activity is intended to help
avoid such difficulties in the future.<p>

<p>

	b.	<u>Department of Defense</u>.  The Department, through the National Security Agency, should provide
technical advice and assistance to NIST, including work products such as technical security guidelines,
which NIST can draw upon for developing standards and guidelines for protecting sensitive information
in Federal computers.<p>

<p>

	Also, the Department, through the National Security Agency, should assist NIST in evaluating
vulnerabilities in emerging technologies.  Such vulnerabilities may present a risk to national security
information as well as to unclassified information.<p>

<p>

	c.	<u>Department of Justice</u>.  The Department of Justice should provide appropriate guidance to Federal
agencies on legal remedies available to them when serious security incidents occur.  Such guidance should
include ways to report incidents and cooperate with law enforcement.<p>

<p>

	In addition, the Department should pursue appropriate legal actions on behalf of the Federal government
when serious security incidents occur.<p>

<p>

	d.	<u>General Services Administration</u>.  The General Services Administration should provide agencies
guidance for addressing security considerations when acquiring information technology products or
services.  This continues the current requirement.<p>

<p>

	In addition, where cost-effective to do so, GSA should establish government-wide contract vehicles for
agencies to use to acquire certain security services.  Such vehicles already exist for providing system
back-up support and conducting security analyses.<p>

<p>

	GSA should also provide appropriate security services to assist Federal agencies to the extent that provision
of such services is cost- effective.  This includes providing, in conjunction with the Department of Defense
and the Department of Commerce, appropriate services which support Federal use of the National
Information Infrastructure (e.g., use of digital signature technology).<p>

<p>

	e.	<u>Office of Personnel Management</u>.  In accordance with the Computer Security Act, OPM should review
its regulations concerning computer security training and assure that they are effective.<p>

<p>

	In addition, OPM should assist the Department of Commerce in the review and update of its computer
security awareness and training guidelines.  OPM worked closely with NIST in developing the current
guidelines and should work with NIST in revising those guidelines.<p>

<p>

	f.	<u>Security Policy Board</u>.  The Security Policy Board is assigned responsibility for national security
policy coordination in accordance with the appropriate Presidential directive.  This includes policy for the
security of information technology used to process classified information.<p>

<p>

	Circular A-130 and this Appendix do not apply to information technology that supports certain critical
national security missions, as defined in 44 U.S.C. 3502(9) and 10 U.S.C. 2315.  Policy and procedural
requirements for the security of national security systems (telecommunications and information systems
that contain classified information or that support those critical national security missions (44 U.S.C.
3502(9) and 10 U.S.C. 2315)) is assigned to the Department of Defense pursuant to Presidential directive. 
The Circular clarifies that information classified for national security purposes should also be handled in
accordance with appropriate national security directives.  Where classified information is required to be
protected by more stringent security requirements, those requirements should be followed rather than the
requirements of this Appendix.<p>

<p>

5.	<u>Reports</u>.  The Appendix requires agencies to provide two reports to OMB:<p>

<p>

The first is a requirement that agencies report security deficiencies and material weaknesses within their
FMFIA reporting mechanisms as defined by OMB Circular No. A-123, "Management Accountability and
Control," and take corrective actions in accordance with that directive.<p>

<p>

The second, defined by the Computer Security Act, requires that a summary of agency security plans be
included in the information resources management plan required by the Paperwork Reduction Act.<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<p>

<center>(This Page Intentionally Left Blank)</center>
<p>
INDEX<br>

<IMG SRC="images/bar1.gif">
<PRE>

31 U.S.C. 3512............................G-7, G-9, G-14, G-15
31 U.S.C. 9106............................G-16
88-16.................................... G-22, G-23
90-08.....................................Bib-6, G-22, G-23, G-26, G-28-G-30
Accreditation.............................1-6, 2-4, 2-6-2-9, 3-1, 3-2, 3-6-3-10,
                                          3-12, 4-1, 4-2, 4-6, 4-9-4-11, Glos-1,
                                          Glos-2,	Glos-5, Glos-9, Glos-18, Glos-19,
                                          Glos-21, Bib-2, Bib-7, D-3, G-27
Acquisition...............................2-4, 2-8, 2-10, 3-1, 3-2, 3-12, Bib-9,
                                          D-3, G-11, G-12, G-21
Adequate Security.........................1-1-1-3, Glos-2, Glos-15, B-3, G-17-G-19,
                                          G-22-G-24, G-27
AIS Owner.................................2-7, 3-1, Glos-2
Application...............................1-2, 1-3, 2-5, 2-6, 2-8, 3-4, 3-6, 3-7, 
                                          3-11, 3-12, 4-8, 4-12, Glos-2, Glos-3,
                                          Glos-11, Glos-15, Glos-18, Glos-19, 
                                          D-2-E-4, G-17, G-19, G-20, G-22, G-23,
                                          G-27-G-29
Application Owner.........................Glos-2, Glos-3, Glos-19
Approval..................................3-4, 3-7-3-9, 3-12, 4-3, 4-12, 4-13, 
                                          Glos-1, Glos-4
Audit.....................................2-8, 4-4, 4-7, Glos-3, C-1, E-4, F-2, G-3,
                                          G-10, G-12, G-14, G-20, G-26, G-28, G-29
Authority.................................2-1-2-3, 2-5, 2-10-2-12, 3-1, 3-11, 4-10,
                                          4-12, Glos-1-Glos-3, Glos-8, Glos-9, Glos-18,
                                          Glos-19, A-1, A-2, E-1-G-3, G-7, G-9, G-11
Availability..............................1-2, 3-4, Glos-2, Glos-4, Glos-6-Glos-8, B-2,
                                          C-1, D-2, G-17, G-23, G-26, G-28
Awareness.................................2-2, 2-3, 3-1, 3-10, 3-11, Bib-6, D-3, E-1-E-3,
                                          G-20, G-21, G-24, G-25, G-31
A-123.....................................Bib-2, Bib-7, G-1, G-7, G-17, G-19-G-21, G-26, G-29, G-31
A-127.....................................Bib-6, G-12, G-15
A-130.....................................1-1, 3-10, Glos-2, Glos-12, Glos-15, Glos-20,
                                          G-13, G-16, G-17, G-31
Back-up...................................G-21, G-25, G-28, G-30
Bacteria..................................Glos-4, Glos-15, Glos-25
Business Impact Analysis..................3-4
C2........................................2-3, 2-6, 2-9, 2-10, 4-3, 4-4, 4-6, 4-7, Glos-5,
                                          Glos-7, Glos-8, Glos-10, Glos-16, Glos-17,
                                          Glos-22-Glos-24, C-1, C-2, F-1, F-2
Certification.............................1-4, 2-7, 2-8, 3-1, 3-2, 3-6-3-8, 3-12, 4-6, 
                                          4-10, 4-11, Glos-1, Glos-5, Glos-20, Bib-2,
                                          Bib-7, D-3, G-27, G-29
CFO.......................................G-3, G-11, G-15
Chief Financial Officers (CFOs) Act.......G-2
Classification............................1-3, 4-10, 4-11, Glos-5-Glos-7, Glos-15, Glos-24,
                                          F-1
Classified................................1-3, 1-6, 3-8, 4-3, 4-11, 5-1, Glos-6, Glos-7, 
                                          Glos-10, Glos-15, Glos-22, Bib-1, Bib-3,	Bib-9,
                                          C-1, G-12, G-21, G-31
Clear.....................................4-4, G-10, G-12, G-18, G-19
Clearing..................................4-10, Glos-6, C-1, C-2
Commercial................................1-2, 3-7, 4-6, 4-13, Glos-2, Glos-3, Glos-6,
                                          Glos-7, Glos-23, Bib-7, A-1, E-2
Commissioner..............................III, 2-1, 2-3, 2-5, 2-6, Bib-8
Computer Security Act.....................3-10, Glos-5, Glos-6, Glos-19, Glos-22, Bib-2,
                                          Bib-8, E-1, G-13, G-17, G-22-G-24, G-29-G-31
Computer Security Incident Response.......Bib-9
COMSEC....................................1-5, 4-14, Glos-6, Bib-3, A-1, E-2
Confidentiality...........................1-2, Glos-2, Glos-6, Glos-7, Glos-16, C-1-D-3,
                                          G-17, G-23, G-28
Configuration Management..................2-8, 3-9, 3-11, 4-6, 4-9, Glos-7, D-3
Contingency...............................1-4, 2-5, 2-7, 3-1, Glos-7, Glos-8, Glos-10,
                                          Bib-6, D-3, G-19, G-28
Contingency Plan..........................4-11, Glos-7, Glos-10, G-28
Continuity of Operations..................3-4, 4-2, Glos-7, E-4
Continuity of Support.....................G-18, G-25
Contracting Officer.......................3-12
Copyright.................................4-9, Glos-13
COTR......................................3-12
COTS......................................3-7, 4-6, 4-13, Glos-6, Glos-7, A-1
CSIRC.....................................2-7, Bib-9
Customs Process...........................2-6, 3-1
Data Base.................................1-5, Glos-5
Data Encryption Standard..................Glos-9, A-1, C-3
Dedicated Security Mode...................3-7, 3-8, 4-12, Glos-9, Glos-23
Deficiencies..............................3-7, 3-9, G-3-G-6, G-10, G-12-G-15, G-21,
                                          G-26, G-31
Department of Justice.....................Bib-6, G-18, G-21, G-25, G-30
Diagnostic................................4-10
Dial-up...................................3-5, 4-10, C-1, C-3
Director..................................1-1, 2-3, 3-10, 4-13, E-1, G-2, G-6, G-7,
                                          G-15, G-16, G-21
Disaster..................................1-4, 2-5, 3-1-3-4, 3-11, 4-2, Glos-4, 
                                          Glos-7, Glos-8, Glos-10, Glos-19, Glos-23
Discretionary Access Control..............4-4, Glos-8, Glos-10, C-2
Distribution..............................III, 2-8, Glos-14, Glos-16, Glos-21, Bib-5,
                                          Bib-8, B-3, G-5, G-15
Education.................................2-2, 2-3, 3-1, 3-10
Emergency.................................2-7, 2-9, 3-2-3-4, Glos-7, Glos-10, Glos-11,
                                          Glos-19, Glos-20, Glos-25, D-3
Encryption................................2-10-2-12, 4-4, 4-7, Glos-5-Glos-9, Glos-11,
                                          Glos-12, Glos-14, Glos-16, Glos-20,
                                          Glos-22, Bib-6, Bib-7, A-1-C-3
Environmental.............................3-11, 4-1, 4-2, B-1, D-3
EPL.......................................4-6, Glos-11, Glos-25
Evaluated Products List...................4-6, Glos-11, Glos-25
Executive Order...........................Glos-21, A-1, G-10
Exemption.................................3-10, C-1
Facility..................................1-5, 2-4, 2-8, 2-9, 3-4-3-6, 3-9, 3-12, 4-1,
                                          4-2, 4-7, Glos-19, Bib-6, Bib-7, Bib-9
Facsimile.................................4-13
FAX.......................................4-13, G-1
Federal Bureau of Investigation...........III, Bib-6, A-1
Federal Managers' Financial Integrity Act.G-1, G-5, G-7, G-9, G-19, G-20, G-26
Firewalls.................................Bib-1, Bib-3, G-28, G-30
FMFIA.....................................Bib-6, G-1, G-6, G-9, G-19, G-21, G-31
FOIA......................................1-3, 1-5, 4-9, Bib-3, Bib-9, A-1
Freedom of Information....................1-3, 1-5, 4-9, Glos-22, Bib-2, Bib-3, Bib-9, A-1
General Accounting Office.................A-1, G-3, G-11
General Support System....................3-4, 3-10, Glos-12, D-2, G-17-G-19, G-22-G-25, G-27, G-28
Government Corporation and Control Act....G-16
Government Performance and Results Act....G-2, G-9, G-13
IG........................................G-2, G-3, G-5, G-11-G-15
Incident Response Capability..............Bib-9, G-18, G-25
Individual Accountability.................G-19, G-24, G-25, G-28, G-29
Information Sharing.......................G-20, G-28
Inspector General.........................G-2, G-10
Internal Affairs..........................2-5, 2-7, 5-1
Internal Controls.........................G-3, G-7, G-10, G-11, G-13
Internet..................................III, 4-13, Glos-14, Glos-26, Bib-1-Bib-3, G-1, G-8, G-24, G-30
IRM.......................................1-3-2-5, 3-9, 3-10, 3-12, Bib-3, A-1, G-13, G-18, G-19
Labels....................................4-11
Least Privilege...........................4-4, Glos-15, G-19, G-25, G-29
License...................................4-9, 4-13
Life-Cycle................................1-3, 2-8, 3-12, 4-6, Glos-7, Glos-10, Glos-13, Glos-20
Maintenance...............................1-3, 2-8, 3-3, 3-11, 4-3, 4-9-Glos-11, Glos-13, G-25
Major Application.........................2-5, 3-7, Glos-2, Glos-15, D-2, G-17, G-19, G-22, G-23, G-27-G-29
Malicious Code............................4-9, 5-1, Glos-4, Glos-15, Glos-24-Glos-26, B-3
Manual procedures.........................G-25
Material Weakness.........................G-4, G-13, G-14
MISSI.....................................4-4-Glos-6, Glos-11, Glos-12, Glos-16
Monitoring................................4-5, 4-7, G-4, G-12, G-14
MOU.......................................2-11, 4-10, 4-13, A-1
National Information Infrastructure.......4-12, 4-13, A-2, G-30
National Security Agency..................III, Glos-16, Glos-25, A-2, G-30
Networks..................................1-1, 2-1-3-3, 3-8, 4-4, 4-5, 4-12, 4-13,
                                          5-1, Glos-12, Glos-16, Glos-22, C-1
NIST Handbook.............................Bib-5, G-22, G-24
Non-Customs...............................1-1, 4-3, 4-5, 4-11-4-13, 5-1
Object Reuse..............................4-4, Glos-6, Glos-7, Glos-17, Glos-19, Bib-5, C-2
Office of Management and Budget...........III, 1-1, 1-6, 3-5, A-2, G-1, G-7, G-16, G-17
Office of Personnel Management............III, 1-1, Bib-8, A-2, E-1, G-17, G-21, G-24, G-31
OPM.......................................1-1, Bib-8, A-2, E-1, G-17, G-18, G-20, G-24, G-30, G-31
Orange Book...............................Glos-10, Glos-17, Glos-23, Glos-24, Bib-3, A-2
Oversight.................................III, 1-2-1-4, 2-2, 2-3, 2-5, 3-1, 3-11, 3-12,
                                          Glos-15, Bib-7, G-12, G-15, G-17, G-23
PAA.......................................2-3, 2-5, 4-10, 4-12, Glos-2, Glos-8, Glos-9, Glos-18, A-2
Paperwork Reduction Act...................Bib-7, G-16, G-18, G-19, G-22, G-23, G-31
Password..................................4-4, 4-7, Glos-18, Bib-5, Bib-7, B-2, B-4, C-1,
                                          C-2, G-22, G-24, G-26
PBX.......................................4-14, Glos-18, A-2-B-4
Personally-owned..........................4-12, Glos-18, Bib-9
Physical Security.........................2-9, 3-4, 4-1, Glos-18, Bib-5, Bib-8
Portable..................................4-10, B-1
Principal Accrediting Authority...........2-3, 2-5, 4-10, 4-12, Glos-2, Glos-18, A-2
Privacy Act...............................1-3, 1-5, 2-6, 4-9, 5-1, Glos-18, Glos-21-Glos-23,
                                          Bib-2, Bib-3, Bib-5, Bib-6, A-2
Private Branch Exchange...................Glos-18, A-2, B-3
Process Owner.............................2-5, 3-1, 4-3, Glos-2, Glos-3, Glos-19
Public Access.............................G-20, G-28, G-29
Recovery..................................1-4, 2-5, 3-1-3-4, 3-11, Glos-4, Glos-7,
                                          Glos-10, Glos-19, Glos-23, Bib-5, G-26
Red Book..................................Bib-1
Remanence.................................Glos-6, Glos-17, Glos-19, Bib-1, C-2
Reports...................................Glos-3, B-3-G-6, G-12-G-15, G-21, G-31
Residual Data.............................4-4, 4-10, Glos-17, C-1
Residual Risk.............................2-4, 3-5, 3-9, 3-10, Glos-19
Reuse.....................................4-4, Glos-6, Glos-7, Glos-17, Glos-19, Bib-5, C-2
Risk Analysis.............................3-4-3-6, 4-1, 4-2, 4-4, 4-11, Glos-4, Glos-20, C-2, D-3, G-30
Risk Assessment...........................3-5, Glos-20, Bib-3, C-1-F-2, G-22
Risk Management...........................2-1, 2-4, 3-1, 3-2, 3-4, 3-5, Glos-20, E-3, E-4, F-2, G-22
Rules of Behavior.........................3-11, G-18, G-24, G-26-G-28
Rules of the System.......................3-10, G-18, G-24, G-26
SBU.......................................1-2, 3-8, 4-11, 4-12, Glos-7, Glos-15-Glos-17,
                                          Glos-21, Glos-22, A-2, C-1, C-3, E-2, F-1
SDLC......................................1-5, 2-5-4-6, A-2
Security Controls.........................1-2, 2-10, 4-1, 4-7, 4-9, 4-11, Glos-10, 
                                          Glos-21, B-3, G-18, G-20, G-22-G-24, G-26-G-29
Security Features User's Guide............4-7, A-2
Security Incidents........................2-5, 2-7, 2-9, 5-1, G-21, G-25, G-30
Security Mode.............................3-7-3-9, 4-12, Glos-1, Glos-9, Glos-23
Security Plan.............................2-2, 2-5, 2-9, 3-2, 3-3, 3-9, 3-10, 4-4-4-9,
                                          4-11, D-1, D-2, G-18-G-20, G-23, G-24,
                                          G-26, G-27, G-29
Security Practices........................4-14, B-1, E-5
Security Programs Division................1-5, 2-4, 3-9, 4-1-A-2
Security Staff............................G-27
Sensitive But Unclassified................1-2, 4-11, 4-12, Glos-5, Glos-15, Glos-17,
                                          Glos-21, Glos-22, A-2, F-1
Separation of Duties......................G-3, G-4, G-12, G-19, G-25, G-28
SFUG......................................4-7, A-2
Site......................................2-8, 2-9, 3-4, 4-1, 4-9, 4-10, Glos-22, Bib-3
Skipjack..................................Glos-5, Glos-6, Glos-9, Glos-10, Glos-12, Glos-20, Glos-22
SPD.......................................1-5, 2-4, 3-9, 3-10, 3-12, 4-1-A-2
Steering Committee........................1-3, 2-3, 3-1, 3-11
Strategic IRM Plan........................Bib-3, G-18, G-19
System High Security Mode.................Glos-9, Glos-23
Systems Development Life Cycle............1-5, Bib-2, Bib-3
TCB.......................................Glos-24, F-2
TCSEC.....................................4-3-Glos-5, Glos-7, Glos-8, Glos-10, Glos-17, 
                                          Glos-19, Glos-22-Glos-24, Bib-3, Bib-7, A-2
Telecommunications........................1-3, 1-6, 4-3, 4-12-4-14, Glos-1, Glos-6, Glos-16,
                                          Bib-2, Bib-3, Bib-6, Bib-9, A-2, B-3, C-1, G-31
Tempest...................................1-6, Glos-11, Glos-24
Testing...................................1-3, 3-1, 3-4, 3-7, 3-8, 4-6, Bib-5, C-2-G-4, 
                                          G-26, G-28
TFM.......................................4-7, A-2
Trade Community...........................III, 1-1, 1-2, 1-4, 2-11, 2-12, 4-3, 4-8, Glos-3
Training..................................1-4, 2-2, 2-3, 2-7, 2-10-2-12, 3-1, 3-10-3-12, 4-3,
                                          Bib-2, Bib-6, Bib-8, D-3, E-1-E-3, G-18-	G-21, 
                                          G-24, G-25, G-28, G-30, G-31
Trojan Horse..............................Glos-4, Glos-15, Glos-24
Trusted Computer Base.....................Glos-24, F-2
Trusted Computer System
   Evaluation Criteria....................4-3, 4-4, Glos-10, Glos-17, Glos-19, Glos-23,
                                          Bib-3, Bib-6-Bib-8, A-2
Trusted Facility Manual...................4-7
Vendor....................................4-5, 4-6, B-2
Violations................................1-2, 2-5, 5-1, E-3, E-5, F-1
Virus.....................................2-5, 2-7, 4-9, 5-1, Glos-4, Glos-15,
                                          Glos-25, Bib-8, Bib-9, B-3, G-26
Vital Records.............................Glos-11, Glos-20, Glos-25
Voice.....................................1-3-4-4, 4-14, B-3, B-4
Waiver....................................3-10, 4-1, 4-3, 4-12
Warning Banner............................4-4, 4-5
Work at Home..............................4-11, G-24
World Wide Web............................III, Glos-26, A-2, G-1, G-8, G-29
Worm......................................Glos-4, Glos-15, Glos-26

</PRE>
<p>

Reader's Comment Form<p>

<IMG SRC="images/bar1.gif">
<p>

<p>

Title:		<b>AUTOMATED INFORMATION SYSTEMS SECURITY POLICY MANUAL</b><p>

			CIS HB 1400-04<p>

			U.S. Customs Service<p>

			Office of Information and Technology<p>

			Automated Information Systems Security Division<p>

			
<p>

Attention:	Mr. Tom Bovasso or AIS Security Administration.<p>

<p>

<p>

Dear Reader:<p>

<p>

You may use this form to communicate your comments about this publication, its organization, or subject
matter with the understanding that the U.S. Customs Service may use or distribute whatever information you
supply in any way it believes appropriate without incurring any obligation to you.  Thank you for your
cooperation.
<P>
<! End: Contents >


</BODY>
</HTML>

